{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import copy\n",
    "import math\n",
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "from math import sqrt\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changenet(net, layer_name, layer_new_weight, layer_new_bias):\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "            self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "            self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "            self.fc1 = nn.Linear(16 * 4 * 4, len(net.state_dict()[\"fc1.weight\"]))\n",
    "            self.fc2 = nn.Linear(len(net.state_dict()[\"fc2.weight\"][0]), len(net.state_dict()[\"fc2.weight\"]))\n",
    "            self.fc3 = nn.Linear(len(net.state_dict()[\"fc3.weight\"][0]), 10)\n",
    "            if(layer_name == \"fc1\"):\n",
    "                self.fc1 = nn.Linear(16 * 4 * 4, len(layer_new_weight))\n",
    "            elif(layer_name == \"fc2\"):\n",
    "                self.fc2 = nn.Linear(len(layer_new_weight[0]), len(layer_new_weight))\n",
    "            else:\n",
    "                self.fc3 = nn.Linear(len(layer_new_weight[0]), 10)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.pool(F.relu(self.conv1(x)))\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            x = x.view(-1, 16 * 4 * 4)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return F.log_softmax(x, dim=1)\n",
    "\n",
    "    net1 = Net()\n",
    "    \n",
    "    for param_tensor in net.state_dict():\n",
    "        if(layer_name not in param_tensor):\n",
    "            if(net.state_dict()[param_tensor].dim()== 1):\n",
    "                net1.state_dict()[param_tensor]=copy.deepcopy(net.state_dict()[param_tensor])\n",
    "            elif(net.state_dict()[param_tensor].dim()== 2):\n",
    "                for i in range(len(net.state_dict()[param_tensor])):\n",
    "                    net1.state_dict()[param_tensor][i]=copy.deepcopy(net.state_dict()[param_tensor][i])\n",
    "            else:\n",
    "                for i in range(len(net.state_dict()[param_tensor])):\n",
    "                    for j in range(len(net.state_dict()[param_tensor][i])):\n",
    "                        for k in range(len(net.state_dict()[param_tensor][i][j])):\n",
    "                            net1.state_dict()[param_tensor][i][j][k]=copy.deepcopy(net.state_dict()[param_tensor][i][j][k])\n",
    "        else:\n",
    "            if(\"weight\" in param_tensor):\n",
    "                for i in range(len(net1.state_dict()[param_tensor])):\n",
    "                    net1.state_dict()[param_tensor][i]=copy.deepcopy(layer_new_weight[i])\n",
    "            else:\n",
    "                net1.state_dict()[param_tensor]=copy.deepcopy(layer_new_bias)\n",
    "    return net1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.1307,), (0.3081,))])\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=200,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the Euclidean distance between two vectors\n",
    "def euclidean_distance(row1, row2):\n",
    "\tdistance = 0.0\n",
    "\tfor i in range(len(row1)):\n",
    "\t\tdistance += (row1[i] - row2[i])**2\n",
    "\treturn sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findsets(dlen, nodes, distances):\n",
    "    cntn=True\n",
    "    dlen = dlen\n",
    "    print(\"desired len=\",dlen)\n",
    "    cut_off=distances[(len(distances)//2)]\n",
    "    cmax=distances[-1]\n",
    "    cmin=distances[0]\n",
    "    diff=0\n",
    "    itr=0\n",
    "    chng=0.001*cut_off\n",
    "    #print(\"chng=\",chng)\n",
    "    while(cntn):\n",
    "        itr+=1\n",
    "        print(\"cut_off=\",cut_off)\n",
    "        cluster=defaultdict(bool)\n",
    "        setpoints=defaultdict(set)\n",
    "        for i in nodes.keys():\n",
    "            cluster[i]=False\n",
    "            setpoints[i]={i}\n",
    "        \n",
    "        for i in nodes.keys():\n",
    "            for j in nodes.keys():\n",
    "                if(i!=j and j>i and cluster[i]==False and cluster[j]==False):\n",
    "\n",
    "                    #########################################################################################\n",
    "                    #########################################################################################\n",
    "                    #########################################################################################\n",
    "                    #########   The percentage of reduction in size depends on the cutoff chosen here ######\n",
    "                    #########  The higher cut off will result in higher compression  ########################\n",
    "\n",
    "\n",
    "                    if(euclidean_distance(nodes[i], nodes[j])<cut_off):\n",
    "                        setpoints[i].add(j)\n",
    "                        del setpoints[j]\n",
    "                        cluster[j]=True\n",
    "            cluster[i]=True\n",
    "        \n",
    "        \n",
    "        if(len(setpoints)==dlen or itr==1000):\n",
    "            cntn=False\n",
    "        else:\n",
    "            diff=len(setpoints)-dlen\n",
    "            #print(\"diff=\",diff)\n",
    "            if(diff<0):\n",
    "                if(cut_off<cmax):\n",
    "                    cmax=cut_off\n",
    "                #print(\"cmax=\",cmax)\n",
    "            else:\n",
    "                if(cut_off>cmin):\n",
    "                    cmin=cut_off\n",
    "                #print(\"cmin=\",cmin)\n",
    "            #print(\"cmax=\",cmax,\" cmin=\",cmin,\" cut_off becomes=\",(cut_off+(diff*chng)))\n",
    "            while(((cut_off+(diff*chng))>=cmax) or ((cut_off+(diff*chng))<=cmin)):\n",
    "                chng*=0.9\n",
    "                #print(\"chng=\",chng)\n",
    "                #print(\"cmax=\",cmax,\" cmin=\",cmin,\" cut_off could became=\",(cut_off+(diff*chng)))\n",
    "            cut_off=cut_off+(diff*chng)\n",
    "            \n",
    "            #chng*=0.8\n",
    "        \n",
    "        print(\"iteration=\",itr,\" length=\",len(setpoints),\" difference=\",diff,\" change rate=\",chng)\n",
    "            \n",
    "            \n",
    "    return setpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 300)\n",
    "        self.fc2 = nn.Linear(300, 100)\n",
    "        self.fc3 = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(\"LeNET_300_100_MNIST_Model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device=torch.device(\"cpu\")\n",
    "model=Net().to(device)\n",
    "summary(model, input_size=(1, 28, 28), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can not prune the layer with 256 nodes. We have to prune the layer with 300 nodes. So, that depends on the outgoing edges weights from the layer with 256 nodes, means fc1 (or the incoming weights to the layer with 300 nodes). The similar kind of weights going on to a group of nodes of the next layer means, those weights are kind of looking for similar kind of patterns. \n",
    "\n",
    "Example: Suppose node1 has incoming weights i1 from previous layer, and outgoing weights o1. And node2 have similar incoming  weights i2 from same previous layer and outgoing weights o2. Then if we club them up, the net effect will be some function of f(i1, i2) * (o1+o2). assuming i1 and i2 are very similar. Here f(i1, i2) is some function of i1 and i2. Here we have taken the average of i1 and i2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(net.state_dict()[\"fc1.weight\"]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After changing the dimension of the layer with 300 nodes, to somehting less than 300. We also have to assign the outgoing edges. Here we have set it as the sum of the outgoing nodes of same cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((net.state_dict()[\"fc2.weight\"]).shape)\n",
    "print(type(net.state_dict()[\"fc2.weight\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to form the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "nodes=defaultdict(list)\n",
    "for j in range(len(net.state_dict()[\"fc1.weight\"])):  #Means j is a node of next layer, L2. Fc1 is connecting L1 and L2 layer.\n",
    "    nodes[j]=net.state_dict()[\"fc1.weight\"][j]\n",
    "\n",
    "print(len(nodes), \" \", len(nodes[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(nodes[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have nodes as a dictionary, where key is the node id, and values are the incoming edge weights form the previous layer. So, now we have to find such node_ids who are having almost similar incoming edge weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "distances=[]\n",
    "for i in nodes.keys():\n",
    "    for j in nodes.keys():\n",
    "        if(i!=j and j>i):\n",
    "            distances.append(euclidean_distance(nodes[i], nodes[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(distances[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances.sort()\n",
    "print(len(distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt \n",
    "# # plt.plot([x for x in range(len(distances))], distances) \n",
    "# # plt.ylabel(\"Distances\")\n",
    "# # plt.show() \n",
    "# x=[k for k in range(len(distances))]\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111)\n",
    "# ax.plot(x, distances)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster=defaultdict(bool)\n",
    "# setpoints=defaultdict(set)\n",
    "# for i in nodes.keys():\n",
    "#     cluster[i]=False\n",
    "#     setpoints[i]={i}\n",
    "    \n",
    "# # print(cluster)\n",
    "\n",
    "# for i in nodes.keys():\n",
    "#     for j in nodes.keys():\n",
    "#         if(i!=j and j>i and cluster[i]==False and cluster[j]==False):\n",
    "            \n",
    "#             #########################################################################################\n",
    "#             #########################################################################################\n",
    "#             #########################################################################################\n",
    "#             #########   The percentage of reduction in size depends on the cutoff chosen here ######\n",
    "#             #########  The higher cut off will result in higher compression  ########################\n",
    "            \n",
    "#             cut_off=0.73\n",
    "            \n",
    "#             if(euclidean_distance(nodes[i], nodes[j])<cut_off):\n",
    "#                 setpoints[i].add(j)\n",
    "#                 del setpoints[j]\n",
    "#                 cluster[j]=True\n",
    "#     cluster[i]=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in setpoints.keys():\n",
    "#     print(key,\" -> \",setpoints[key], \"->\", len(setpoints[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(setpoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(distances[0],\" \",distances[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dlen=math.ceil(len(nodes)*90/100)\n",
    "setpoints=findsets(270, nodes, distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will take the average of the same points in the same cluster and assign it as a new bucket, and delete all the other nodes. For FC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "temp_weights=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(net.state_dict()[\"fc1.weight\"][0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=net.state_dict()[\"fc1.weight\"][points]\n",
    "    row=row/len(setpoints[key])\n",
    "    temp_weights.append(row)\n",
    "print(len(temp_weights), temp_weights[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will adjust the bias in the similar way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net.state_dict()[\"fc1.bias\"].shape)\n",
    "temp_bias=torch.zeros(len(temp_weights), dtype=torch.float)\n",
    "i=0\n",
    "for key in setpoints.keys():\n",
    "    for points in setpoints[key]:\n",
    "        temp_bias[i]+=net.state_dict()[\"fc1.bias\"][points]\n",
    "    temp_bias[i]/=len(setpoints[key])\n",
    "    i+=1\n",
    "print(temp_bias.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_1 = changenet(net, \"fc1\", temp_weights, temp_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net.state_dict()[\"fc1.bias\"].shape, \" -> \", net_1.state_dict()[\"fc1.bias\"].shape)\n",
    "print(net.state_dict()[\"fc1.weight\"].shape, \" -> \", net_1.state_dict()[\"fc1.weight\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=copy.deepcopy(net_1)\n",
    "print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "print(net.state_dict()[\"fc1.bias\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just to check if the copy has been done correctly\n",
    "print(temp_weights[0],\"\\n\\n\",net.state_dict()[\"fc1.weight\"][0])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we have to change FC2 accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net.state_dict()[\"fc2.weight\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat=net.state_dict()[\"fc2.weight\"].t()\n",
    "print(mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_weight=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(mat[0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=mat[points]\n",
    "    temp_weight.append(row)\n",
    "print(len(temp_weight), temp_weight[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmat=torch.stack(temp_weight, dim=0)\n",
    "newmat=newmat.t()\n",
    "print(newmat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net.state_dict()[\"fc2.bias\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_2 = changenet(net, \"fc2\", newmat, net.state_dict()[\"fc2.bias\"])\n",
    "net=copy.deepcopy(net_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "print(net.state_dict()[\"fc2.bias\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "print(net.state_dict()[\"fc3.weight\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, len(net.state_dict()[\"fc1.weight\"]))\n",
    "        self.fc2 = nn.Linear(len(net.state_dict()[\"fc2.weight\"][0]), 100)\n",
    "        self.fc3 = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "device=torch.device(\"cpu\")\n",
    "model=Net().to(device)\n",
    "summary(model, input_size=(1, 28, 28), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's prune the next layer which consists of 100 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(net.state_dict()[\"fc2.weight\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(net.state_dict()[\"fc3.weight\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "nodes=defaultdict(list)\n",
    "for j in range(len(net.state_dict()[\"fc2.weight\"])):  #Means j is a node of next layer, L2.\n",
    "    nodes[j]=net.state_dict()[\"fc2.weight\"][j]\n",
    "\n",
    "print(len(nodes), \" \", len(nodes[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "distances=[]\n",
    "for i in nodes.keys():\n",
    "    for j in nodes.keys():\n",
    "        if(i!=j and j>i):\n",
    "            distances.append(euclidean_distance(nodes[i], nodes[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances.sort()\n",
    "print(len(distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt \n",
    "\n",
    "# x=[k for k in range(len(distances))]\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111)\n",
    "# ax.plot(x, distances)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster=defaultdict(bool)\n",
    "# setpoints=defaultdict(set)\n",
    "# for i in nodes.keys():\n",
    "#     cluster[i]=False\n",
    "#     setpoints[i]={i}\n",
    "    \n",
    "# # print(cluster)\n",
    "\n",
    "# for i in nodes.keys():\n",
    "#     for j in nodes.keys():\n",
    "#         if(i!=j and j>i and cluster[i]==False and cluster[j]==False):\n",
    "            \n",
    "#             #########################################################################################\n",
    "#             #########################################################################################\n",
    "#             #########################################################################################\n",
    "#             #########   The percentage of reduction in size depends on the cutoff chossen here ######\n",
    "#             #########  The higher cut off will result in higher compression  ########################\n",
    "            \n",
    "#             cut_off=0.7704\n",
    "#             if(euclidean_distance(nodes[i], nodes[j])<cut_off):\n",
    "#                 setpoints[i].add(j)\n",
    "#                 del setpoints[j]\n",
    "#                 cluster[j]=True\n",
    "#     cluster[i]=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in setpoints.keys():\n",
    "#     print(key,\" -> \",setpoints[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setpoints=findsets(90, nodes, distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have i many nodes in place of 100. Now, we will first fix the incoming weights this i many nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "temp_weight=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(net.state_dict()[\"fc2.weight\"][0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=net.state_dict()[\"fc2.weight\"][points]\n",
    "    row=row/len(setpoints[key])\n",
    "    temp_weight.append(row)\n",
    "print(len(temp_weight), temp_weight[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net.state_dict()[\"fc2.bias\"].shape)\n",
    "temp_bias=torch.zeros(len(temp_weight), dtype=torch.float)\n",
    "i=0\n",
    "for key in setpoints.keys():\n",
    "    for points in setpoints[key]:\n",
    "        temp_bias[i]+=net.state_dict()[\"fc2.bias\"][points]\n",
    "    temp_bias[i]/=len(setpoints[key])\n",
    "    i+=1\n",
    "print(temp_bias.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_3 = changenet(net, \"fc2\", temp_weight, temp_bias)\n",
    "net=copy.deepcopy(net_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "print(net.state_dict()[\"fc2.bias\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we have to change FC3 accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net.state_dict()[\"fc3.weight\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat=net.state_dict()[\"fc3.weight\"].t()\n",
    "print(mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_weight=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(mat[0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=mat[points]\n",
    "    temp_weight.append(row)\n",
    "print(len(temp_weight), temp_weight[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmat=torch.stack(temp_weight, dim=0)\n",
    "newmat=newmat.t()\n",
    "print(newmat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(net.state_dict()[\"fc3.weight\"].shape)\n",
    "# net.state_dict()[\"fc3.weight\"].resize_(len(newmat), len(newmat[0]))\n",
    "# print(net.state_dict()[\"fc3.weight\"][1][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(newmat)):\n",
    "#     net.state_dict()[\"fc3.weight\"][i]=newmat[i]\n",
    "# print(net.state_dict()[\"fc3.weight\"].shape)\n",
    "# print(net.state_dict()[\"fc3.weight\"][1][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net.state_dict()[\"fc3.bias\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_4 = changenet(net, \"fc3\", newmat, net.state_dict()[\"fc3.bias\"])\n",
    "net=copy.deepcopy(net_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "print(net.state_dict()[\"fc3.weight\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, len(net.state_dict()[\"fc1.weight\"]))\n",
    "        self.fc2 = nn.Linear(len(net.state_dict()[\"fc2.weight\"][0]), len(net.state_dict()[\"fc2.weight\"]))\n",
    "        self.fc3 = nn.Linear(len(net.state_dict()[\"fc3.weight\"][0]), 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the accuracy actually come up to 76.5, the actual accuracy without any pruning was 89.7. Let's try to freeze the previous layers, and do a fine_tuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for parameter in net.parameters():\n",
    "    i+=1\n",
    "    if(i<5):\n",
    "        parameter.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.1307,), (0.3081,))])\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=200,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=200,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('0', '1', '2', '3',\n",
    "           '4', '5', '6', '7', '8', '9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for parameter in net.parameters():\n",
    "    i+=1\n",
    "    print(i,\" \",parameter.shape,\"\\n \",parameter,\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        # print(inputs.shape)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    # print every 2000 mini-batches\n",
    "            print(\"[{}, {}] loss: {}\".format\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Reraining')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"LeNET_270_90_MNIST_Model_My_Exiperiment_4_Fine_Tuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.fc1 = nn.Linear(16 * 4 * 4, len(net.state_dict()[\"fc1.weight\"]))\n",
    "#         self.fc2 = nn.Linear(len(net.state_dict()[\"fc2.weight\"][0]), len(net.state_dict()[\"fc2.weight\"]))\n",
    "#         self.fc3 = nn.Linear(len(net.state_dict()[\"fc3.weight\"][0]), 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(F.relu(self.conv1(x)))\n",
    "#         x = self.pool(F.relu(self.conv2(x)))\n",
    "#         x = x.view(-1, 16 * 4 * 4)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "#         return F.log_softmax(x, dim=1)\n",
    "    \n",
    "# net = Net()\n",
    "# net.load_state_dict(torch.load(\"LeNET_270_90_MNIST_Model_My_Exiperiment_4_Fine_Tuned\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 270)\n",
    "        self.fc2 = nn.Linear(270, 90)\n",
    "        self.fc3 = nn.Linear(90, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(\"LeNET_270_90_MNIST_Model_My_Exiperiment_4_Fine_Tuned\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 24, 24]             156\n",
      "         MaxPool2d-2            [-1, 6, 12, 12]               0\n",
      "            Conv2d-3             [-1, 16, 8, 8]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 4, 4]               0\n",
      "            Linear-5                  [-1, 270]          69,390\n",
      "            Linear-6                   [-1, 90]          24,390\n",
      "            Linear-7                   [-1, 10]             910\n",
      "================================================================\n",
      "Total params: 97,262\n",
      "Trainable params: 97,262\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.05\n",
      "Params size (MB): 0.37\n",
      "Estimated Total Size (MB): 0.42\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "device=torch.device(\"cpu\")\n",
    "model=Net().to(device)\n",
    "summary(model, input_size=(1, 28, 28), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, number of parametes reduced down to 86k from 110 k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 98.360000 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning fc1.................\n",
      "Finding clusters of nodes.................\n",
      "desired len= 240\n",
      "cut_off= 0.8459521625151378\n",
      "iteration= 1  length= 25  difference= -215  change rate= 0.0008459521625151378\n",
      "cut_off= 0.6640724475743832\n",
      "iteration= 2  length= 247  difference= 7  change rate= 0.0008459521625151378\n",
      "cut_off= 0.6699941127119892\n",
      "iteration= 3  length= 246  difference= 6  change rate= 0.0008459521625151378\n",
      "cut_off= 0.67506982568708\n",
      "iteration= 4  length= 244  difference= 4  change rate= 0.0008459521625151378\n",
      "cut_off= 0.6784536343371406\n",
      "iteration= 5  length= 243  difference= 3  change rate= 0.0008459521625151378\n",
      "cut_off= 0.680991490824686\n",
      "iteration= 6  length= 242  difference= 2  change rate= 0.0008459521625151378\n",
      "cut_off= 0.6826833951497163\n",
      "iteration= 7  length= 242  difference= 2  change rate= 0.0008459521625151378\n",
      "cut_off= 0.6843752994747466\n",
      "iteration= 8  length= 242  difference= 2  change rate= 0.0008459521625151378\n",
      "cut_off= 0.6860672037997769\n",
      "iteration= 9  length= 242  difference= 2  change rate= 0.0008459521625151378\n",
      "cut_off= 0.6877591081248072\n",
      "iteration= 10  length= 242  difference= 2  change rate= 0.0008459521625151378\n",
      "cut_off= 0.6894510124498375\n",
      "iteration= 11  length= 242  difference= 2  change rate= 0.0008459521625151378\n",
      "cut_off= 0.6911429167748678\n",
      "iteration= 12  length= 241  difference= 1  change rate= 0.0008459521625151378\n",
      "cut_off= 0.691988868937383\n",
      "iteration= 13  length= 240  difference= 1  change rate= 0.0008459521625151378\n",
      "Updating fc1.................\n",
      "torch.Size([270])  ->  torch.Size([240])\n",
      "torch.Size([270, 256])  ->  torch.Size([240, 256])\n",
      "Adjusting fc2 accordingly.................\n",
      "torch.Size([240, 256])\n",
      "torch.Size([90, 240])\n",
      "torch.Size([10, 90])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 24, 24]             156\n",
      "         MaxPool2d-2            [-1, 6, 12, 12]               0\n",
      "            Conv2d-3             [-1, 16, 8, 8]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 4, 4]               0\n",
      "            Linear-5                  [-1, 240]          61,680\n",
      "            Linear-6                   [-1, 90]          21,690\n",
      "            Linear-7                   [-1, 10]             910\n",
      "================================================================\n",
      "Total params: 86,852\n",
      "Trainable params: 86,852\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.05\n",
      "Params size (MB): 0.33\n",
      "Estimated Total Size (MB): 0.38\n",
      "----------------------------------------------------------------\n",
      "Accuracy of the network on the test images: 97.270000 %\n",
      "Pruning fc2.................\n",
      "Finding clusters of nodes.................\n",
      "desired len= 80\n",
      "cut_off= 0.8923282732696001\n",
      "iteration= 1  length= 9  difference= -71  change rate= 0.0008923282732696\n",
      "cut_off= 0.8289729658674585\n",
      "iteration= 2  length= 25  difference= -55  change rate= 0.0008923282732696\n",
      "cut_off= 0.7798949108376305\n",
      "iteration= 3  length= 33  difference= -47  change rate= 0.0008923282732696\n",
      "cut_off= 0.7379554819939593\n",
      "iteration= 4  length= 55  difference= -25  change rate= 0.0008923282732696\n",
      "cut_off= 0.7156472751622194\n",
      "iteration= 5  length= 65  difference= -15  change rate= 0.0008923282732696\n",
      "cut_off= 0.7022623510631754\n",
      "iteration= 6  length= 72  difference= -8  change rate= 0.0008923282732696\n",
      "cut_off= 0.6951237248770186\n",
      "iteration= 7  length= 76  difference= -4  change rate= 0.0008923282732696\n",
      "cut_off= 0.6915544117839402\n",
      "iteration= 8  length= 76  difference= -4  change rate= 0.0008923282732696\n",
      "cut_off= 0.6879850986908618\n",
      "iteration= 9  length= 77  difference= -3  change rate= 0.0008923282732696\n",
      "cut_off= 0.685308113871053\n",
      "iteration= 10  length= 79  difference= -1  change rate= 0.0008923282732696\n",
      "cut_off= 0.6844157855977834\n",
      "iteration= 11  length= 80  difference= -1  change rate= 0.0008923282732696\n",
      "Updating fc2.................\n",
      "Adjusting fc3 accordingly.................\n",
      "torch.Size([240, 256])\n",
      "torch.Size([80, 240])\n",
      "torch.Size([10, 80])\n",
      "Accuracy of the network on the test images: 95.190000 %\n",
      "[1, 20] loss: 0.0007303135823458433\n",
      "[1, 40] loss: 0.0003900716700591147\n",
      "[1, 60] loss: 0.00041416458738967776\n",
      "[1, 80] loss: 0.0004888563482090831\n",
      "[1, 100] loss: 0.0005270487945526839\n",
      "[1, 120] loss: 0.0004107941882684827\n",
      "[1, 140] loss: 0.000423765791580081\n",
      "[1, 160] loss: 0.00042622673977166416\n",
      "[1, 180] loss: 0.0004551456905901432\n",
      "[1, 200] loss: 0.0004910483220592142\n",
      "[1, 220] loss: 0.00037250759499147536\n",
      "[1, 240] loss: 0.0003568046614527702\n",
      "[1, 260] loss: 0.0003584422068670392\n",
      "[1, 280] loss: 0.00046800675243139267\n",
      "[1, 300] loss: 0.00042148503474891184\n",
      "[2, 20] loss: 0.0004001659089699388\n",
      "[2, 40] loss: 0.000355074733030051\n",
      "[2, 60] loss: 0.00044050814770162105\n",
      "[2, 80] loss: 0.0004659305908717215\n",
      "[2, 100] loss: 0.0004316757880151272\n",
      "[2, 120] loss: 0.0004468445871025324\n",
      "[2, 140] loss: 0.00042853256594389675\n",
      "[2, 160] loss: 0.00034649996366351845\n",
      "[2, 180] loss: 0.00036401177011430265\n",
      "[2, 200] loss: 0.00042137714568525554\n",
      "[2, 220] loss: 0.0004561468590982258\n",
      "[2, 240] loss: 0.0004506956436671317\n",
      "[2, 260] loss: 0.00041515172738581895\n",
      "[2, 280] loss: 0.00042877775151282547\n",
      "[2, 300] loss: 0.00032533297291956843\n",
      "[3, 20] loss: 0.0004782691542059183\n",
      "[3, 40] loss: 0.00040813041385263205\n",
      "[3, 60] loss: 0.0004134146571159363\n",
      "[3, 80] loss: 0.0004762671780772507\n",
      "[3, 100] loss: 0.000415209005586803\n",
      "[3, 120] loss: 0.0004383282596245408\n",
      "[3, 140] loss: 0.0003456141073256731\n",
      "[3, 160] loss: 0.0003934988575056195\n",
      "[3, 180] loss: 0.00023769659805111587\n",
      "[3, 200] loss: 0.0003870605716947466\n",
      "[3, 220] loss: 0.0004007371608167887\n",
      "[3, 240] loss: 0.0004766055862419307\n",
      "[3, 260] loss: 0.00043450125819072125\n",
      "[3, 280] loss: 0.0004670226057060063\n",
      "[3, 300] loss: 0.00036287154210731386\n",
      "[4, 20] loss: 0.00039643683563917874\n",
      "[4, 40] loss: 0.0003922783089801669\n",
      "[4, 60] loss: 0.00037548361998051405\n",
      "[4, 80] loss: 0.0003938145199790597\n",
      "[4, 100] loss: 0.00039179391879588365\n",
      "[4, 120] loss: 0.0004374205907806754\n",
      "[4, 140] loss: 0.0003477183105424047\n",
      "[4, 160] loss: 0.00047157311625778674\n",
      "[4, 180] loss: 0.00037513781990855934\n",
      "[4, 200] loss: 0.00038684887764975427\n",
      "[4, 220] loss: 0.00037412291672080756\n",
      "[4, 240] loss: 0.00045633603865280747\n",
      "[4, 260] loss: 0.00039836336951702835\n",
      "[4, 280] loss: 0.00037186446832492947\n",
      "[4, 300] loss: 0.00032445138785988095\n",
      "[5, 20] loss: 0.0003769040727056563\n",
      "[5, 40] loss: 0.0003085387940518558\n",
      "[5, 60] loss: 0.00038535762438550594\n",
      "[5, 80] loss: 0.0003723170910961926\n",
      "[5, 100] loss: 0.00038347623171284796\n",
      "[5, 120] loss: 0.0003411166537553072\n",
      "[5, 140] loss: 0.00037767401291057467\n",
      "[5, 160] loss: 0.0005727644958533346\n",
      "[5, 180] loss: 0.00043763982132077216\n",
      "[5, 200] loss: 0.0003114913501776755\n",
      "[5, 220] loss: 0.0003563990422990173\n",
      "[5, 240] loss: 0.00035132590495049956\n",
      "[5, 260] loss: 0.00039628633297979834\n",
      "[5, 280] loss: 0.0003952089580707252\n",
      "[5, 300] loss: 0.00032401516661047935\n",
      "[6, 20] loss: 0.0003636983511969447\n",
      "[6, 40] loss: 0.00035388691257685423\n",
      "[6, 60] loss: 0.00036530073545873166\n",
      "[6, 80] loss: 0.0003881538212299347\n",
      "[6, 100] loss: 0.00039112398913130166\n",
      "[6, 120] loss: 0.0003118249718099833\n",
      "[6, 140] loss: 0.0003324548709206283\n",
      "[6, 160] loss: 0.000446907346136868\n",
      "[6, 180] loss: 0.0004342176453210413\n",
      "[6, 200] loss: 0.0004333160454407334\n",
      "[6, 220] loss: 0.00032810483127832413\n",
      "[6, 240] loss: 0.00041803765995427966\n",
      "[6, 260] loss: 0.0004170509185642004\n",
      "[6, 280] loss: 0.0003200785778462887\n",
      "[6, 300] loss: 0.00042131868191063403\n",
      "[7, 20] loss: 0.00033897839300334453\n",
      "[7, 40] loss: 0.00035875623812898995\n",
      "[7, 60] loss: 0.00034747710870578884\n",
      "[7, 80] loss: 0.00035617833584547043\n",
      "[7, 100] loss: 0.0003437404865399003\n",
      "[7, 120] loss: 0.0003005477446131408\n",
      "[7, 140] loss: 0.0004297821717336774\n",
      "[7, 160] loss: 0.0004039061162620783\n",
      "[7, 180] loss: 0.0003535837815143168\n",
      "[7, 200] loss: 0.00042204066552221773\n",
      "[7, 220] loss: 0.0004287282447330654\n",
      "[7, 240] loss: 0.00031623581843450663\n",
      "[7, 260] loss: 0.0004295270503498614\n",
      "[7, 280] loss: 0.00035738711711019277\n",
      "[7, 300] loss: 0.0003223403445445001\n",
      "[8, 20] loss: 0.0004663770729675889\n",
      "[8, 40] loss: 0.00033703907253220677\n",
      "[8, 60] loss: 0.000388148495927453\n",
      "[8, 80] loss: 0.0002729029399342835\n",
      "[8, 100] loss: 0.00045779583603143694\n",
      "[8, 120] loss: 0.00044604277424514294\n",
      "[8, 140] loss: 0.00034272304736077786\n",
      "[8, 160] loss: 0.0003799227806739509\n",
      "[8, 180] loss: 0.000273842157330364\n",
      "[8, 200] loss: 0.00030998210981488227\n",
      "[8, 220] loss: 0.000367933617439121\n",
      "[8, 240] loss: 0.0003412204724736512\n",
      "[8, 260] loss: 0.00033187539130449296\n",
      "[8, 280] loss: 0.00029392931470647454\n",
      "[8, 300] loss: 0.0003302633054554462\n",
      "[9, 20] loss: 0.0003531852231826633\n",
      "[9, 40] loss: 0.0002982905409298837\n",
      "[9, 60] loss: 0.0004045334309339523\n",
      "[9, 80] loss: 0.000358761053532362\n",
      "[9, 100] loss: 0.00033476517861709\n",
      "[9, 120] loss: 0.00043098053662106396\n",
      "[9, 140] loss: 0.0004074016781523824\n",
      "[9, 160] loss: 0.00041777085792273283\n",
      "[9, 180] loss: 0.0003959773420356214\n",
      "[9, 200] loss: 0.00035206747893244027\n",
      "[9, 220] loss: 0.0003121083141304553\n",
      "[9, 240] loss: 0.00031370069133117794\n",
      "[9, 260] loss: 0.0003224091944284737\n",
      "[9, 280] loss: 0.000261038470081985\n",
      "[9, 300] loss: 0.00034410451678559183\n",
      "[10, 20] loss: 0.00037115434464067223\n",
      "[10, 40] loss: 0.00033786746114492416\n",
      "[10, 60] loss: 0.00031851968634873627\n",
      "[10, 80] loss: 0.0003481938051991165\n",
      "[10, 100] loss: 0.00029601192381232974\n",
      "[10, 120] loss: 0.00029021170502528546\n",
      "[10, 140] loss: 0.00039230057131499054\n",
      "[10, 160] loss: 0.00035485535440966487\n",
      "[10, 180] loss: 0.0004193498729728162\n",
      "[10, 200] loss: 0.00042854025680571795\n",
      "[10, 220] loss: 0.0003709460678510368\n",
      "[10, 240] loss: 0.00034425020590424536\n",
      "[10, 260] loss: 0.00029295406257733703\n",
      "[10, 280] loss: 0.00035140027571469546\n",
      "[10, 300] loss: 0.0003080952977761626\n",
      "[11, 20] loss: 0.0003022278668358922\n",
      "[11, 40] loss: 0.00033182568615302443\n",
      "[11, 60] loss: 0.0002872224822640419\n",
      "[11, 80] loss: 0.00025271035893820225\n",
      "[11, 100] loss: 0.0003159121233038604\n",
      "[11, 120] loss: 0.00033040284691378475\n",
      "[11, 140] loss: 0.0002770073423162103\n",
      "[11, 160] loss: 0.0003525541857816279\n",
      "[11, 180] loss: 0.0004082272509112954\n",
      "[11, 200] loss: 0.00027549805492162703\n",
      "[11, 220] loss: 0.0003921280652284622\n",
      "[11, 240] loss: 0.0004066553823649883\n",
      "[11, 260] loss: 0.0003552948632277548\n",
      "[11, 280] loss: 0.00044907448440790175\n",
      "[11, 300] loss: 0.0003794478252530098\n",
      "[12, 20] loss: 0.0003219120595604181\n",
      "[12, 40] loss: 0.00031201525358483197\n",
      "[12, 60] loss: 0.00033931676484644414\n",
      "[12, 80] loss: 0.0003444531308487058\n",
      "[12, 100] loss: 0.00028564065787941217\n",
      "[12, 120] loss: 0.00034450448304414747\n",
      "[12, 140] loss: 0.0003931739372201264\n",
      "[12, 160] loss: 0.0002817155667580664\n",
      "[12, 180] loss: 0.000368909755256027\n",
      "[12, 200] loss: 0.00037988943606615064\n",
      "[12, 220] loss: 0.0003459368068724871\n",
      "[12, 240] loss: 0.000381299729924649\n",
      "[12, 260] loss: 0.0002997695538215339\n",
      "[12, 280] loss: 0.0003595039127394557\n",
      "[12, 300] loss: 0.0002901209443807602\n",
      "[13, 20] loss: 0.0002727018678560853\n",
      "[13, 40] loss: 0.00025347581785172224\n",
      "[13, 60] loss: 0.0003018463416956365\n",
      "[13, 80] loss: 0.00030038560228422284\n",
      "[13, 100] loss: 0.0003739924666006118\n",
      "[13, 120] loss: 0.0003350414209999144\n",
      "[13, 140] loss: 0.00037996118841692806\n",
      "[13, 160] loss: 0.0002912619253620505\n",
      "[13, 180] loss: 0.0002954343508463353\n",
      "[13, 200] loss: 0.00042804148234426977\n",
      "[13, 220] loss: 0.00032775126304477453\n",
      "[13, 240] loss: 0.0003180066451895982\n",
      "[13, 260] loss: 0.0003410854786634445\n",
      "[13, 280] loss: 0.00039229144994169476\n",
      "[13, 300] loss: 0.00031038083345629277\n",
      "[14, 20] loss: 0.0003162781521677971\n",
      "[14, 40] loss: 0.0003220088356174529\n",
      "[14, 60] loss: 0.00030127454036846756\n",
      "[14, 80] loss: 0.00037585907289758324\n",
      "[14, 100] loss: 0.0003359745191410184\n",
      "[14, 120] loss: 0.0002662015287205577\n",
      "[14, 140] loss: 0.00026610088208690283\n",
      "[14, 160] loss: 0.0003236229168251157\n",
      "[14, 180] loss: 0.00034901805501431226\n",
      "[14, 200] loss: 0.00040643367823213337\n",
      "[14, 220] loss: 0.00041406102292239664\n",
      "[14, 240] loss: 0.00032697754772379996\n",
      "[14, 260] loss: 0.0003407824323512614\n",
      "[14, 280] loss: 0.0003215587195008993\n",
      "[14, 300] loss: 0.00038069175416603686\n",
      "[15, 20] loss: 0.0003114755670540035\n",
      "[15, 40] loss: 0.0002570407025050372\n",
      "[15, 60] loss: 0.0002832544003613293\n",
      "[15, 80] loss: 0.0002811938924714923\n",
      "[15, 100] loss: 0.0003076543021015823\n",
      "[15, 120] loss: 0.00030757631873711943\n",
      "[15, 140] loss: 0.0004205847871489823\n",
      "[15, 160] loss: 0.00038527714367955925\n",
      "[15, 180] loss: 0.00036139745777472856\n",
      "[15, 200] loss: 0.0002762895571067929\n",
      "[15, 220] loss: 0.00032546123955398795\n",
      "[15, 240] loss: 0.00027582367020659147\n",
      "[15, 260] loss: 0.0002824787152931094\n",
      "[15, 280] loss: 0.00034214397519826887\n",
      "[15, 300] loss: 0.00035668553970754144\n",
      "[16, 20] loss: 0.0003389569183345884\n",
      "[16, 40] loss: 0.0003140024705789983\n",
      "[16, 60] loss: 0.0002308444876689464\n",
      "[16, 80] loss: 0.00029476348729804157\n",
      "[16, 100] loss: 0.00029339036857709287\n",
      "[16, 120] loss: 0.00029303172416985035\n",
      "[16, 140] loss: 0.00034281088411808016\n",
      "[16, 160] loss: 0.0003466576086357236\n",
      "[16, 180] loss: 0.00033350639324635265\n",
      "[16, 200] loss: 0.0003604644853621721\n",
      "[16, 220] loss: 0.00040735634323209525\n",
      "[16, 240] loss: 0.0002672252585180104\n",
      "[16, 260] loss: 0.0003368644551374018\n",
      "[16, 280] loss: 0.0003086802791804075\n",
      "[16, 300] loss: 0.00033066168986260893\n",
      "[17, 20] loss: 0.0002930308887735009\n",
      "[17, 40] loss: 0.00034010670939460394\n",
      "[17, 60] loss: 0.0002834030711092055\n",
      "[17, 80] loss: 0.0003362027686089277\n",
      "[17, 100] loss: 0.00036808214103803037\n",
      "[17, 120] loss: 0.0002462042917031795\n",
      "[17, 140] loss: 0.0003436937197111547\n",
      "[17, 160] loss: 0.0002890430521219969\n",
      "[17, 180] loss: 0.0002777474606409669\n",
      "[17, 200] loss: 0.00033360236324369907\n",
      "[17, 220] loss: 0.0003543231096118689\n",
      "[17, 240] loss: 0.00024342040088959037\n",
      "[17, 260] loss: 0.00029635352501645686\n",
      "[17, 280] loss: 0.000337011837400496\n",
      "[17, 300] loss: 0.000317082358058542\n",
      "[18, 20] loss: 0.0003464285023510456\n",
      "[18, 40] loss: 0.0002477670966181904\n",
      "[18, 60] loss: 0.0002859118371270597\n",
      "[18, 80] loss: 0.0003421433963812888\n",
      "[18, 100] loss: 0.00029719058657065036\n",
      "[18, 120] loss: 0.00023448500293307006\n",
      "[18, 140] loss: 0.0002785049777012318\n",
      "[18, 160] loss: 0.0002873682982753962\n",
      "[18, 180] loss: 0.000287974304985255\n",
      "[18, 200] loss: 0.00039980225544422864\n",
      "[18, 220] loss: 0.00029383196355775\n",
      "[18, 240] loss: 0.00031905656633898614\n",
      "[18, 260] loss: 0.00034885974670760333\n",
      "[18, 280] loss: 0.0002923520253971219\n",
      "[18, 300] loss: 0.0003104623518884182\n",
      "[19, 20] loss: 0.0003488676524721086\n",
      "[19, 40] loss: 0.00027686406206339596\n",
      "[19, 60] loss: 0.0002835676544345915\n",
      "[19, 80] loss: 0.00031335874856449665\n",
      "[19, 100] loss: 0.0002876197185833007\n",
      "[19, 120] loss: 0.0002991612977348268\n",
      "[19, 140] loss: 0.00030075291986577215\n",
      "[19, 160] loss: 0.00027513699582777917\n",
      "[19, 180] loss: 0.0002969375476241112\n",
      "[19, 200] loss: 0.0003267503958195448\n",
      "[19, 220] loss: 0.0003770246272906661\n",
      "[19, 240] loss: 0.00027699450915679336\n",
      "[19, 260] loss: 0.0002527337290812284\n",
      "[19, 280] loss: 0.000343640623614192\n",
      "[19, 300] loss: 0.0002552033741958439\n",
      "[20, 20] loss: 0.0003065452795708552\n",
      "[20, 40] loss: 0.00029871732369065283\n",
      "[20, 60] loss: 0.0003336697965860367\n",
      "[20, 80] loss: 0.00031259844917804\n",
      "[20, 100] loss: 0.00030684288032352923\n",
      "[20, 120] loss: 0.0002631199168972671\n",
      "[20, 140] loss: 0.0003095343401655555\n",
      "[20, 160] loss: 0.00026712502888403834\n",
      "[20, 180] loss: 0.000282297347439453\n",
      "[20, 200] loss: 0.0002675282163545489\n",
      "[20, 220] loss: 0.0003008536444976926\n",
      "[20, 240] loss: 0.0002414419357664883\n",
      "[20, 260] loss: 0.00036322294175624846\n",
      "[20, 280] loss: 0.0003444972820580006\n",
      "[20, 300] loss: 0.00037335679843090476\n",
      "Finished Reraining\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 24, 24]             156\n",
      "         MaxPool2d-2            [-1, 6, 12, 12]               0\n",
      "            Conv2d-3             [-1, 16, 8, 8]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 4, 4]               0\n",
      "            Linear-5                  [-1, 240]          61,680\n",
      "            Linear-6                   [-1, 80]          19,280\n",
      "            Linear-7                   [-1, 10]             810\n",
      "================================================================\n",
      "Total params: 84,342\n",
      "Trainable params: 84,342\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.05\n",
      "Params size (MB): 0.32\n",
      "Estimated Total Size (MB): 0.37\n",
      "----------------------------------------------------------------\n",
      "Accuracy of the network on the test images: 98.550000 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Pruning fc1.................\")\n",
    "\n",
    "nodes=defaultdict(list)\n",
    "for j in range(len(net.state_dict()[\"fc1.weight\"])):  #Means j is a node of next layer, L2. Fc1 is connecting L1 and L2 layer.\n",
    "    nodes[j]=net.state_dict()[\"fc1.weight\"][j]\n",
    "\n",
    "# print(len(nodes), \" \", len(nodes[0]))\n",
    "\n",
    "# from math import sqrt\n",
    "distances=[]\n",
    "for i in nodes.keys():\n",
    "    for j in nodes.keys():\n",
    "        if(i!=j and j>i):\n",
    "            distances.append(euclidean_distance(nodes[i], nodes[j]))\n",
    "\n",
    "distances.sort()\n",
    "            \n",
    "print(\"Finding clusters of nodes.................\")\n",
    "setpoints=findsets(240, nodes, distances)\n",
    "\n",
    "# print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "temp_weights=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(net.state_dict()[\"fc1.weight\"][0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=net.state_dict()[\"fc1.weight\"][points]\n",
    "    row=row/len(setpoints[key])\n",
    "    temp_weights.append(row)\n",
    "# print(len(temp_weights), temp_weights[0].shape)\n",
    "\n",
    "# print(net.state_dict()[\"fc1.bias\"].shape)\n",
    "temp_bias=torch.zeros(len(temp_weights), dtype=torch.float)\n",
    "i=0\n",
    "for key in setpoints.keys():\n",
    "    for points in setpoints[key]:\n",
    "        temp_bias[i]+=net.state_dict()[\"fc1.bias\"][points]\n",
    "    temp_bias[i]/=len(setpoints[key])\n",
    "    i+=1\n",
    "# print(temp_bias.shape)\n",
    "\n",
    "print(\"Updating fc1.................\")\n",
    "net_1 = changenet(net, \"fc1\", temp_weights, temp_bias)\n",
    "\n",
    "print(net.state_dict()[\"fc1.bias\"].shape, \" -> \", net_1.state_dict()[\"fc1.bias\"].shape)\n",
    "print(net.state_dict()[\"fc1.weight\"].shape, \" -> \", net_1.state_dict()[\"fc1.weight\"].shape)\n",
    "\n",
    "net=copy.deepcopy(net_1)\n",
    "# print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "# print(net.state_dict()[\"fc1.bias\"].shape)\n",
    "\n",
    "#just to check if the copy has been done correctly\n",
    "# print(temp_weights[0],\"\\n\\n\",net.state_dict()[\"fc1.weight\"][0])    \n",
    "\n",
    "\n",
    "### Now, we have to change FC2 accordingly:\n",
    "# print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "print(\"Adjusting fc2 accordingly.................\")\n",
    "mat=net.state_dict()[\"fc2.weight\"].t()\n",
    "# print(mat.shape)\n",
    "\n",
    "temp_weight=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(mat[0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=mat[points]\n",
    "    temp_weight.append(row)\n",
    "# print(len(temp_weight), temp_weight[0].shape)\n",
    "\n",
    "newmat=torch.stack(temp_weight, dim=0)\n",
    "newmat=newmat.t()\n",
    "# print(newmat.shape)\n",
    "\n",
    "# print(net.state_dict()[\"fc2.bias\"].shape)\n",
    "\n",
    "net_2 = changenet(net, \"fc2\", newmat, net.state_dict()[\"fc2.bias\"])\n",
    "net=copy.deepcopy(net_2)\n",
    "\n",
    "print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "print(net.state_dict()[\"fc3.weight\"].shape)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, len(net.state_dict()[\"fc1.weight\"]))\n",
    "        self.fc2 = nn.Linear(len(net.state_dict()[\"fc2.weight\"][0]), len(net.state_dict()[\"fc2.weight\"]))\n",
    "        self.fc3 = nn.Linear(len(net.state_dict()[\"fc3.weight\"][0]), 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    \n",
    "from torchsummary import summary\n",
    "device=torch.device(\"cpu\")\n",
    "model=Net().to(device)\n",
    "summary(model, input_size=(1, 28, 28), device=\"cpu\")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "\n",
    "print(\"Pruning fc2.................\")\n",
    "from collections import defaultdict\n",
    "nodes=defaultdict(list)\n",
    "for j in range(len(net.state_dict()[\"fc2.weight\"])):  #Means j is a node of next layer, L2.\n",
    "    nodes[j]=net.state_dict()[\"fc2.weight\"][j]\n",
    "\n",
    "# print(len(nodes), \" \", len(nodes[0]))\n",
    "\n",
    "\n",
    "distances=[]\n",
    "for i in nodes.keys():\n",
    "    for j in nodes.keys():\n",
    "        if(i!=j and j>i):\n",
    "            distances.append(euclidean_distance(nodes[i], nodes[j]))\n",
    "            \n",
    "distances.sort()\n",
    "# print(len(distances))\n",
    "\n",
    "print(\"Finding clusters of nodes.................\")\n",
    "setpoints=findsets(80, nodes, distances)\n",
    "\n",
    "# print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "temp_weight=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(net.state_dict()[\"fc2.weight\"][0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=net.state_dict()[\"fc2.weight\"][points]\n",
    "    row=row/len(setpoints[key])\n",
    "    temp_weight.append(row)\n",
    "# print(len(temp_weight), temp_weight[0].shape)\n",
    "\n",
    "# print(net.state_dict()[\"fc2.bias\"].shape)\n",
    "temp_bias=torch.zeros(len(temp_weight), dtype=torch.float)\n",
    "i=0\n",
    "for key in setpoints.keys():\n",
    "    for points in setpoints[key]:\n",
    "        temp_bias[i]+=net.state_dict()[\"fc2.bias\"][points]\n",
    "    temp_bias[i]/=len(setpoints[key])\n",
    "    i+=1\n",
    "# print(temp_bias.shape)\n",
    "\n",
    "print(\"Updating fc2.................\")\n",
    "net_3 = changenet(net, \"fc2\", temp_weight, temp_bias)\n",
    "net=copy.deepcopy(net_3)\n",
    "\n",
    "mat=net.state_dict()[\"fc3.weight\"].t()\n",
    "# print(mat.shape)\n",
    "\n",
    "temp_weight=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(mat[0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=mat[points]\n",
    "    temp_weight.append(row)\n",
    "# print(len(temp_weight), temp_weight[0].shape)\n",
    "\n",
    "newmat=torch.stack(temp_weight, dim=0)\n",
    "newmat=newmat.t()\n",
    "# print(newmat.shape)\n",
    "\n",
    "print(\"Adjusting fc3 accordingly.................\")\n",
    "net_4 = changenet(net, \"fc3\", newmat, net.state_dict()[\"fc3.bias\"])\n",
    "net=copy.deepcopy(net_4)\n",
    "\n",
    "print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "print(net.state_dict()[\"fc3.weight\"].shape)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, len(net.state_dict()[\"fc1.weight\"]))\n",
    "        self.fc2 = nn.Linear(len(net.state_dict()[\"fc2.weight\"][0]), len(net.state_dict()[\"fc2.weight\"]))\n",
    "        self.fc3 = nn.Linear(len(net.state_dict()[\"fc3.weight\"][0]), 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "i=0\n",
    "for parameter in net.parameters():\n",
    "    i+=1\n",
    "    if(i<5):\n",
    "        parameter.requires_grad=False\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.1307,), (0.3081,))])\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=200,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=200,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('0', '1', '2', '3',\n",
    "           '4', '5', '6', '7', '8', '9')\n",
    "\n",
    "# import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        # print(inputs.shape)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    # print every 2000 mini-batches\n",
    "            print(\"[{}, {}] loss: {}\".format\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Reraining')\n",
    "\n",
    "\n",
    "from torchsummary import summary\n",
    "device=torch.device(\"cpu\")\n",
    "model=Net().to(device)\n",
    "summary(model, input_size=(1, 28, 28), device=\"cpu\")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"LeNET_240_80_MNIST_Model_My_Exiperiment_4_Fine_Tuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 240)\n",
    "        self.fc2 = nn.Linear(240, 80)\n",
    "        self.fc3 = nn.Linear(80, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(\"LeNET_240_80_MNIST_Model_My_Exiperiment_4_Fine_Tuned\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning fc1.................\n",
      "Finding clusters of nodes.................\n",
      "desired len= 210\n",
      "cut_off= 0.8683952650168648\n",
      "iteration= 1  length= 17  difference= -193  change rate= 0.0008683952650168648\n",
      "cut_off= 0.7007949788686099\n",
      "iteration= 2  length= 30  difference= -180  change rate= 0.0008683952650168648\n",
      "cut_off= 0.5444838311655742\n",
      "iteration= 3  length= 239  difference= 29  change rate= 0.0008683952650168648\n",
      "cut_off= 0.5696672938510633\n",
      "iteration= 4  length= 239  difference= 29  change rate= 0.0008683952650168648\n",
      "cut_off= 0.5948507565365524\n",
      "iteration= 5  length= 237  difference= 27  change rate= 0.0008683952650168648\n",
      "cut_off= 0.6182974286920078\n",
      "iteration= 6  length= 211  difference= 1  change rate= 0.0008683952650168648\n",
      "cut_off= 0.6191658239570247\n",
      "iteration= 7  length= 211  difference= 1  change rate= 0.0008683952650168648\n",
      "cut_off= 0.6200342192220416\n",
      "iteration= 8  length= 209  difference= -1  change rate= 0.0007815557385151783\n",
      "cut_off= 0.6192526634835265\n",
      "iteration= 9  length= 211  difference= 1  change rate= 0.0007034001646636605\n",
      "cut_off= 0.6199560636481901\n",
      "iteration= 10  length= 210  difference= 1  change rate= 0.0007034001646636605\n",
      "Updating fc1.................\n",
      "torch.Size([240])  ->  torch.Size([210])\n",
      "torch.Size([240, 256])  ->  torch.Size([210, 256])\n",
      "Adjusting fc2 accordingly.................\n",
      "torch.Size([210, 256])\n",
      "torch.Size([80, 210])\n",
      "torch.Size([10, 80])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 24, 24]             156\n",
      "         MaxPool2d-2            [-1, 6, 12, 12]               0\n",
      "            Conv2d-3             [-1, 16, 8, 8]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 4, 4]               0\n",
      "            Linear-5                  [-1, 210]          53,970\n",
      "            Linear-6                   [-1, 80]          16,880\n",
      "            Linear-7                   [-1, 10]             810\n",
      "================================================================\n",
      "Total params: 74,232\n",
      "Trainable params: 74,232\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.05\n",
      "Params size (MB): 0.28\n",
      "Estimated Total Size (MB): 0.33\n",
      "----------------------------------------------------------------\n",
      "Accuracy of the network on the test images: 98.200000 %\n",
      "Pruning fc2.................\n",
      "Finding clusters of nodes.................\n",
      "desired len= 70\n",
      "cut_off= 0.8951998548229737\n",
      "iteration= 1  length= 6  difference= -64  change rate= 0.0008951998548229738\n",
      "cut_off= 0.8379070641143034\n",
      "iteration= 2  length= 9  difference= -61  change rate= 0.0008951998548229738\n",
      "cut_off= 0.783299872970102\n",
      "iteration= 3  length= 18  difference= -52  change rate= 0.0008951998548229738\n",
      "cut_off= 0.7367494805193073\n",
      "iteration= 4  length= 37  difference= -33  change rate= 0.0008951998548229738\n",
      "cut_off= 0.7072078853101492\n",
      "iteration= 5  length= 53  difference= -17  change rate= 0.0008951998548229738\n",
      "cut_off= 0.6919894877781587\n",
      "iteration= 6  length= 55  difference= -15  change rate= 0.0008951998548229738\n",
      "cut_off= 0.6785614899558141\n",
      "iteration= 7  length= 57  difference= -13  change rate= 0.0008951998548229738\n",
      "cut_off= 0.6669238918431154\n",
      "iteration= 8  length= 61  difference= -9  change rate= 0.0008951998548229738\n",
      "cut_off= 0.6588670931497086\n",
      "iteration= 9  length= 63  difference= -7  change rate= 0.0008951998548229738\n",
      "cut_off= 0.6526006941659478\n",
      "iteration= 10  length= 66  difference= -4  change rate= 0.0008951998548229738\n",
      "cut_off= 0.6490198947466559\n",
      "iteration= 11  length= 67  difference= -3  change rate= 0.0008951998548229738\n",
      "cut_off= 0.646334295182187\n",
      "iteration= 12  length= 67  difference= -3  change rate= 0.0008951998548229738\n",
      "cut_off= 0.6436486956177181\n",
      "iteration= 13  length= 67  difference= -3  change rate= 0.0008951998548229738\n",
      "cut_off= 0.6409630960532492\n",
      "iteration= 14  length= 68  difference= -2  change rate= 0.0008951998548229738\n",
      "cut_off= 0.6391726963436033\n",
      "iteration= 15  length= 69  difference= -1  change rate= 0.0008951998548229738\n",
      "cut_off= 0.6382774964887803\n",
      "iteration= 16  length= 69  difference= -1  change rate= 0.0008951998548229738\n",
      "cut_off= 0.6373822966339573\n",
      "iteration= 17  length= 69  difference= -1  change rate= 0.0008951998548229738\n",
      "cut_off= 0.6364870967791343\n",
      "iteration= 18  length= 69  difference= -1  change rate= 0.0008951998548229738\n",
      "cut_off= 0.6355918969243113\n",
      "iteration= 19  length= 69  difference= -1  change rate= 0.0008951998548229738\n",
      "cut_off= 0.6346966970694883\n",
      "iteration= 20  length= 69  difference= -1  change rate= 0.0008951998548229738\n",
      "cut_off= 0.6338014972146653\n",
      "iteration= 21  length= 69  difference= -1  change rate= 0.0008951998548229738\n",
      "cut_off= 0.6329062973598423\n",
      "iteration= 22  length= 69  difference= -1  change rate= 0.0008951998548229738\n",
      "cut_off= 0.6320110975050193\n",
      "iteration= 23  length= 69  difference= -1  change rate= 0.0008951998548229738\n",
      "cut_off= 0.6311158976501963\n",
      "iteration= 24  length= 70  difference= -1  change rate= 0.0008951998548229738\n",
      "Updating fc2.................\n",
      "Adjusting fc3 accordingly.................\n",
      "torch.Size([210, 256])\n",
      "torch.Size([70, 210])\n",
      "torch.Size([10, 70])\n",
      "Accuracy of the network on the test images: 97.760000 %\n",
      "[1, 20] loss: 0.00044546697568148373\n",
      "[1, 40] loss: 0.0003201858289539814\n",
      "[1, 60] loss: 0.00037648923555389045\n",
      "[1, 80] loss: 0.0002498096199706197\n",
      "[1, 100] loss: 0.0003196739626582712\n",
      "[1, 120] loss: 0.000349674831610173\n",
      "[1, 140] loss: 0.0003475240576080978\n",
      "[1, 160] loss: 0.000296269522048533\n",
      "[1, 180] loss: 0.0003635768587701023\n",
      "[1, 200] loss: 0.00023948373179882764\n",
      "[1, 220] loss: 0.00041044384613633155\n",
      "[1, 240] loss: 0.0003947570975869894\n",
      "[1, 260] loss: 0.000264972563367337\n",
      "[1, 280] loss: 0.000433558173943311\n",
      "[1, 300] loss: 0.00025288033345714214\n",
      "[2, 20] loss: 0.0002444199244491756\n",
      "[2, 40] loss: 0.00033409497421234844\n",
      "[2, 60] loss: 0.0002575149517506361\n",
      "[2, 80] loss: 0.00030230653239414094\n",
      "[2, 100] loss: 0.00034314580773934725\n",
      "[2, 120] loss: 0.00027533419989049436\n",
      "[2, 140] loss: 0.0003329210253432393\n",
      "[2, 160] loss: 0.00038553758198395374\n",
      "[2, 180] loss: 0.00035660125920549036\n",
      "[2, 200] loss: 0.00028632090101018547\n",
      "[2, 220] loss: 0.00032203523116186263\n",
      "[2, 240] loss: 0.0003577270251698792\n",
      "[2, 260] loss: 0.00033113930327817795\n",
      "[2, 280] loss: 0.00025265346001833677\n",
      "[2, 300] loss: 0.00036223842855542896\n",
      "[3, 20] loss: 0.0002833307543769479\n",
      "[3, 40] loss: 0.00022654918441548943\n",
      "[3, 60] loss: 0.0002791035138070583\n",
      "[3, 80] loss: 0.0003221562586259097\n",
      "[3, 100] loss: 0.0003178765689954162\n",
      "[3, 120] loss: 0.00032908331509679553\n",
      "[3, 140] loss: 0.0003342298879288137\n",
      "[3, 160] loss: 0.00029416359355673193\n",
      "[3, 180] loss: 0.0003449227516539395\n",
      "[3, 200] loss: 0.0003774468679912388\n",
      "[3, 220] loss: 0.0002973276507109404\n",
      "[3, 240] loss: 0.00031810515141114594\n",
      "[3, 260] loss: 0.0003085462311282754\n",
      "[3, 280] loss: 0.00026599416229873893\n",
      "[3, 300] loss: 0.0003003985257819295\n",
      "[4, 20] loss: 0.00029164676647633315\n",
      "[4, 40] loss: 0.0003466434511356056\n",
      "[4, 60] loss: 0.0003721839338541031\n",
      "[4, 80] loss: 0.0002337563936598599\n",
      "[4, 100] loss: 0.0003130569595377892\n",
      "[4, 120] loss: 0.0003044310011900961\n",
      "[4, 140] loss: 0.00023170638433657586\n",
      "[4, 160] loss: 0.00028837255761027334\n",
      "[4, 180] loss: 0.0003796321977861226\n",
      "[4, 200] loss: 0.0002905465424992144\n",
      "[4, 220] loss: 0.00030100294947624207\n",
      "[4, 240] loss: 0.00031845335476100444\n",
      "[4, 260] loss: 0.00029957273043692114\n",
      "[4, 280] loss: 0.00028773953625932337\n",
      "[4, 300] loss: 0.00027662989450618627\n",
      "[5, 20] loss: 0.00027001049276441336\n",
      "[5, 40] loss: 0.00026039821188896895\n",
      "[5, 60] loss: 0.0003240488083101809\n",
      "[5, 80] loss: 0.0003200452239252627\n",
      "[5, 100] loss: 0.00030762955150566993\n",
      "[5, 120] loss: 0.0003648390294983983\n",
      "[5, 140] loss: 0.0003033758299425244\n",
      "[5, 160] loss: 0.00029500257899053395\n",
      "[5, 180] loss: 0.0003068139292299747\n",
      "[5, 200] loss: 0.00030512188142165544\n",
      "[5, 220] loss: 0.0002975860112346709\n",
      "[5, 240] loss: 0.00024616858549416065\n",
      "[5, 260] loss: 0.00029728585481643676\n",
      "[5, 280] loss: 0.00031912006763741373\n",
      "[5, 300] loss: 0.00025415138457901776\n",
      "[6, 20] loss: 0.00032568173203617335\n",
      "[6, 40] loss: 0.00032451652409508825\n",
      "[6, 60] loss: 0.0003691254290752113\n",
      "[6, 80] loss: 0.0003053348413668573\n",
      "[6, 100] loss: 0.00025053245108574626\n",
      "[6, 120] loss: 0.0002765765667427331\n",
      "[6, 140] loss: 0.00023349105613306164\n",
      "[6, 160] loss: 0.00027806572429835797\n",
      "[6, 180] loss: 0.00023006212338805198\n",
      "[6, 200] loss: 0.0003157469262368977\n",
      "[6, 220] loss: 0.0002552045008633286\n",
      "[6, 240] loss: 0.00030167287914082406\n",
      "[6, 260] loss: 0.000307560644345358\n",
      "[6, 280] loss: 0.00035125832911580803\n",
      "[6, 300] loss: 0.00033751775417476893\n",
      "[7, 20] loss: 0.00033407525811344384\n",
      "[7, 40] loss: 0.00019767397979740054\n",
      "[7, 60] loss: 0.0002497282926924527\n",
      "[7, 80] loss: 0.00031928297295235095\n",
      "[7, 100] loss: 0.00033768692053854466\n",
      "[7, 120] loss: 0.00031276030465960503\n",
      "[7, 140] loss: 0.00031846979120746255\n",
      "[7, 160] loss: 0.0002588869798928499\n",
      "[7, 180] loss: 0.0002572518880479038\n",
      "[7, 200] loss: 0.00030204584961757066\n",
      "[7, 220] loss: 0.0002822226448915899\n",
      "[7, 240] loss: 0.0003192180930636823\n",
      "[7, 260] loss: 0.0002688109341543168\n",
      "[7, 280] loss: 0.000271364679094404\n",
      "[7, 300] loss: 0.0003365416107699275\n",
      "[8, 20] loss: 0.00022817786480300127\n",
      "[8, 40] loss: 0.0002748942649923265\n",
      "[8, 60] loss: 0.0002601729463785887\n",
      "[8, 80] loss: 0.00022681573289446533\n",
      "[8, 100] loss: 0.00032213621539995074\n",
      "[8, 120] loss: 0.0002808997510001063\n",
      "[8, 140] loss: 0.0002538744630292058\n",
      "[8, 160] loss: 0.00026686894707381723\n",
      "[8, 180] loss: 0.0002934026301372796\n",
      "[8, 200] loss: 0.00029603900853544476\n",
      "[8, 220] loss: 0.00027181063126772645\n",
      "[8, 240] loss: 0.0002718550809659064\n",
      "[8, 260] loss: 0.0003455114085227251\n",
      "[8, 280] loss: 0.00030781525187194346\n",
      "[8, 300] loss: 0.00034819162962958217\n",
      "[9, 20] loss: 0.00032989391963928936\n",
      "[9, 40] loss: 0.0002693737503141165\n",
      "[9, 60] loss: 0.0002474760401528329\n",
      "[9, 80] loss: 0.0002941188665572554\n",
      "[9, 100] loss: 0.00027723561925813557\n",
      "[9, 120] loss: 0.00023404164449311794\n",
      "[9, 140] loss: 0.00024622224760241805\n",
      "[9, 160] loss: 0.0002908025779761374\n",
      "[9, 180] loss: 0.0002900371588766575\n",
      "[9, 200] loss: 0.00029542482737451793\n",
      "[9, 220] loss: 0.0003121536346152425\n",
      "[9, 240] loss: 0.0002969287564046681\n",
      "[9, 260] loss: 0.000290339850820601\n",
      "[9, 280] loss: 0.0002774616368114948\n",
      "[9, 300] loss: 0.00027099025389179586\n",
      "[10, 20] loss: 0.000248419463634491\n",
      "[10, 40] loss: 0.00023177838884294033\n",
      "[10, 60] loss: 0.0003268438286613673\n",
      "[10, 80] loss: 0.0003286898089572787\n",
      "[10, 100] loss: 0.00027440210385248063\n",
      "[10, 120] loss: 0.0002186764804646373\n",
      "[10, 140] loss: 0.00030329541908577084\n",
      "[10, 160] loss: 0.00026438522967509926\n",
      "[10, 180] loss: 0.0002555414449889213\n",
      "[10, 200] loss: 0.00024469051766209303\n",
      "[10, 220] loss: 0.00028947903867810964\n",
      "[10, 240] loss: 0.00028570445720106364\n",
      "[10, 260] loss: 0.000299971163040027\n",
      "[10, 280] loss: 0.00026182399690151214\n",
      "[10, 300] loss: 0.0003115345505066216\n",
      "[11, 20] loss: 0.00022725165379233658\n",
      "[11, 40] loss: 0.00027402881812304256\n",
      "[11, 60] loss: 0.00030174688110128046\n",
      "[11, 80] loss: 0.00028246355522423984\n",
      "[11, 100] loss: 0.0002671826026635244\n",
      "[11, 120] loss: 0.00034296598052605985\n",
      "[11, 140] loss: 0.00027329880767501893\n",
      "[11, 160] loss: 0.00026501895720139145\n",
      "[11, 180] loss: 0.00028149162628687916\n",
      "[11, 200] loss: 0.00026381490053609016\n",
      "[11, 220] loss: 0.00022534322016872467\n",
      "[11, 240] loss: 0.0002502660102909431\n",
      "[11, 260] loss: 0.0003347403546795249\n",
      "[11, 280] loss: 0.00024080975446850062\n",
      "[11, 300] loss: 0.0002853056329768151\n",
      "[12, 20] loss: 0.00028255420317873357\n",
      "[12, 40] loss: 0.00025215338892303405\n",
      "[12, 60] loss: 0.0002255914518609643\n",
      "[12, 80] loss: 0.00024751627049408853\n",
      "[12, 100] loss: 0.0002645538793876767\n",
      "[12, 120] loss: 0.00022809035587124525\n",
      "[12, 140] loss: 0.000255980275105685\n",
      "[12, 160] loss: 0.00025242927856743337\n",
      "[12, 180] loss: 0.00028499430511146783\n",
      "[12, 200] loss: 0.00021960370987653732\n",
      "[12, 220] loss: 0.0002777307932265103\n",
      "[12, 240] loss: 0.00025963039277121427\n",
      "[12, 260] loss: 0.00034244768554344776\n",
      "[12, 280] loss: 0.00026887749275192617\n",
      "[12, 300] loss: 0.00032185458298772575\n",
      "[13, 20] loss: 0.0003089991540182382\n",
      "[13, 40] loss: 0.00026583123253658413\n",
      "[13, 60] loss: 0.0002675547229591757\n",
      "[13, 80] loss: 0.00022894043009728194\n",
      "[13, 100] loss: 0.0002958765458315611\n",
      "[13, 120] loss: 0.00023659152118489147\n",
      "[13, 140] loss: 0.00027576485415920616\n",
      "[13, 160] loss: 0.00023830691701732577\n",
      "[13, 180] loss: 0.00027507589338347316\n",
      "[13, 200] loss: 0.00025169358868151905\n",
      "[13, 220] loss: 0.00021634962409734727\n",
      "[13, 240] loss: 0.00022006164235062898\n",
      "[13, 260] loss: 0.00028406024258583785\n",
      "[13, 280] loss: 0.0002265240764245391\n",
      "[13, 300] loss: 0.00031353447306901216\n",
      "[14, 20] loss: 0.0002431206493638456\n",
      "[14, 40] loss: 0.0002461523558013141\n",
      "[14, 60] loss: 0.00019764227117411793\n",
      "[14, 80] loss: 0.000269216634798795\n",
      "[14, 100] loss: 0.000265380616299808\n",
      "[14, 120] loss: 0.00026808233233168723\n",
      "[14, 140] loss: 0.00027093635499477386\n",
      "[14, 160] loss: 0.00021285626059398054\n",
      "[14, 180] loss: 0.00026320323394611475\n",
      "[14, 200] loss: 0.0002489815065637231\n",
      "[14, 220] loss: 0.0002878388809040189\n",
      "[14, 240] loss: 0.00029186316253617403\n",
      "[14, 260] loss: 0.0002612188134808093\n",
      "[14, 280] loss: 0.0002570794024504721\n",
      "[14, 300] loss: 0.0002605264219455421\n",
      "[15, 20] loss: 0.00024753445433452724\n",
      "[15, 40] loss: 0.00030734473513439295\n",
      "[15, 60] loss: 0.00021290560578927396\n",
      "[15, 80] loss: 0.00022257348825223744\n",
      "[15, 100] loss: 0.00024570516124367714\n",
      "[15, 120] loss: 0.00025112055661156773\n",
      "[15, 140] loss: 0.0002543891714885831\n",
      "[15, 160] loss: 0.00021496860997285695\n",
      "[15, 180] loss: 0.00023608001135289668\n",
      "[15, 200] loss: 0.000285131991840899\n",
      "[15, 220] loss: 0.00023453250620514155\n",
      "[15, 240] loss: 0.00023811266897246243\n",
      "[15, 260] loss: 0.0002705472609959543\n",
      "[15, 280] loss: 0.00030020422430243344\n",
      "[15, 300] loss: 0.00021530226292088627\n",
      "[16, 20] loss: 0.0003240971507038921\n",
      "[16, 40] loss: 0.00022800878691487016\n",
      "[16, 60] loss: 0.0002815267494879663\n",
      "[16, 80] loss: 0.00026353859063237906\n",
      "[16, 100] loss: 0.00021818142058327794\n",
      "[16, 120] loss: 0.0002229312458075583\n",
      "[16, 140] loss: 0.00019615439767949283\n",
      "[16, 160] loss: 0.00024302318203262984\n",
      "[16, 180] loss: 0.00023878421215340495\n",
      "[16, 200] loss: 0.0002206153238657862\n",
      "[16, 220] loss: 0.00029702746076509356\n",
      "[16, 240] loss: 0.00027694957330822947\n",
      "[16, 260] loss: 0.00028491711197420956\n",
      "[16, 280] loss: 0.00021304758731275798\n",
      "[16, 300] loss: 0.0002511112985666841\n",
      "[17, 20] loss: 0.0002831549416296184\n",
      "[17, 40] loss: 0.0002555994698777795\n",
      "[17, 60] loss: 0.0002497589709237218\n",
      "[17, 80] loss: 0.00021117924060672522\n",
      "[17, 100] loss: 0.0002034313650801778\n",
      "[17, 120] loss: 0.0002718711113557219\n",
      "[17, 140] loss: 0.00021954366890713573\n",
      "[17, 160] loss: 0.00021171166142448783\n",
      "[17, 180] loss: 0.000270634226500988\n",
      "[17, 200] loss: 0.0002159592016832903\n",
      "[17, 220] loss: 0.00024387722183018924\n",
      "[17, 240] loss: 0.0002669956600293517\n",
      "[17, 260] loss: 0.00028983448492363097\n",
      "[17, 280] loss: 0.0002481974707916379\n",
      "[17, 300] loss: 0.0002541709158103913\n",
      "[18, 20] loss: 0.00023805347084999084\n",
      "[18, 40] loss: 0.0002487858817912638\n",
      "[18, 60] loss: 0.00027356753149069846\n",
      "[18, 80] loss: 0.0002465956013184041\n",
      "[18, 100] loss: 0.00022887579002417625\n",
      "[18, 120] loss: 0.00022102606669068337\n",
      "[18, 140] loss: 0.00033266339311376216\n",
      "[18, 160] loss: 0.00021124749851878733\n",
      "[18, 180] loss: 0.00028905401728115975\n",
      "[18, 200] loss: 0.0002055806200951338\n",
      "[18, 220] loss: 0.00021054083807393908\n",
      "[18, 240] loss: 0.00029969400726258754\n",
      "[18, 260] loss: 0.00026065931958146394\n",
      "[18, 280] loss: 0.0002620402742177248\n",
      "[18, 300] loss: 0.00018222730583511293\n",
      "[19, 20] loss: 0.00028315510181710124\n",
      "[19, 40] loss: 0.0002706694060470909\n",
      "[19, 60] loss: 0.00022480236273258924\n",
      "[19, 80] loss: 0.0001539461447391659\n",
      "[19, 100] loss: 0.0002051220601424575\n",
      "[19, 120] loss: 0.00022709013964049518\n",
      "[19, 140] loss: 0.0002715531592257321\n",
      "[19, 160] loss: 0.0002455199249088764\n",
      "[19, 180] loss: 0.0002662360421381891\n",
      "[19, 200] loss: 0.0002307446259073913\n",
      "[19, 220] loss: 0.0002267841852735728\n",
      "[19, 240] loss: 0.0002583977305330336\n",
      "[19, 260] loss: 0.00023598482250235974\n",
      "[19, 280] loss: 0.0002547260099090636\n",
      "[19, 300] loss: 0.00022305996296927334\n",
      "[20, 20] loss: 0.00026918687857687475\n",
      "[20, 40] loss: 0.00015242831059731544\n",
      "[20, 60] loss: 0.00021072858502157034\n",
      "[20, 80] loss: 0.0002329307277686894\n",
      "[20, 100] loss: 0.00017876053205691277\n",
      "[20, 120] loss: 0.0002551388838328421\n",
      "[20, 140] loss: 0.00023916448513045907\n",
      "[20, 160] loss: 0.00035969644412398336\n",
      "[20, 180] loss: 0.00023858817713335155\n",
      "[20, 200] loss: 0.0002377537530846894\n",
      "[20, 220] loss: 0.00025505473883822563\n",
      "[20, 240] loss: 0.000259412401355803\n",
      "[20, 260] loss: 0.0002399854944087565\n",
      "[20, 280] loss: 0.0002449225052259862\n",
      "[20, 300] loss: 0.0001763074027840048\n",
      "Finished Reraining\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 24, 24]             156\n",
      "         MaxPool2d-2            [-1, 6, 12, 12]               0\n",
      "            Conv2d-3             [-1, 16, 8, 8]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 4, 4]               0\n",
      "            Linear-5                  [-1, 210]          53,970\n",
      "            Linear-6                   [-1, 70]          14,770\n",
      "            Linear-7                   [-1, 10]             710\n",
      "================================================================\n",
      "Total params: 72,022\n",
      "Trainable params: 72,022\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 0.27\n",
      "Estimated Total Size (MB): 0.32\n",
      "----------------------------------------------------------------\n",
      "Accuracy of the network on the test images: 98.650000 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Pruning fc1.................\")\n",
    "\n",
    "nodes=defaultdict(list)\n",
    "for j in range(len(net.state_dict()[\"fc1.weight\"])):  #Means j is a node of next layer, L2. Fc1 is connecting L1 and L2 layer.\n",
    "    nodes[j]=net.state_dict()[\"fc1.weight\"][j]\n",
    "\n",
    "# print(len(nodes), \" \", len(nodes[0]))\n",
    "\n",
    "# from math import sqrt\n",
    "distances=[]\n",
    "for i in nodes.keys():\n",
    "    for j in nodes.keys():\n",
    "        if(i!=j and j>i):\n",
    "            distances.append(euclidean_distance(nodes[i], nodes[j]))\n",
    "\n",
    "distances.sort()\n",
    "            \n",
    "print(\"Finding clusters of nodes.................\")\n",
    "setpoints=findsets(210, nodes, distances)\n",
    "\n",
    "# print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "temp_weights=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(net.state_dict()[\"fc1.weight\"][0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=net.state_dict()[\"fc1.weight\"][points]\n",
    "    row=row/len(setpoints[key])\n",
    "    temp_weights.append(row)\n",
    "# print(len(temp_weights), temp_weights[0].shape)\n",
    "\n",
    "# print(net.state_dict()[\"fc1.bias\"].shape)\n",
    "temp_bias=torch.zeros(len(temp_weights), dtype=torch.float)\n",
    "i=0\n",
    "for key in setpoints.keys():\n",
    "    for points in setpoints[key]:\n",
    "        temp_bias[i]+=net.state_dict()[\"fc1.bias\"][points]\n",
    "    temp_bias[i]/=len(setpoints[key])\n",
    "    i+=1\n",
    "# print(temp_bias.shape)\n",
    "\n",
    "print(\"Updating fc1.................\")\n",
    "net_1 = changenet(net, \"fc1\", temp_weights, temp_bias)\n",
    "\n",
    "print(net.state_dict()[\"fc1.bias\"].shape, \" -> \", net_1.state_dict()[\"fc1.bias\"].shape)\n",
    "print(net.state_dict()[\"fc1.weight\"].shape, \" -> \", net_1.state_dict()[\"fc1.weight\"].shape)\n",
    "\n",
    "net=copy.deepcopy(net_1)\n",
    "# print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "# print(net.state_dict()[\"fc1.bias\"].shape)\n",
    "\n",
    "#just to check if the copy has been done correctly\n",
    "# print(temp_weights[0],\"\\n\\n\",net.state_dict()[\"fc1.weight\"][0])    \n",
    "\n",
    "\n",
    "### Now, we have to change FC2 accordingly:\n",
    "# print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "print(\"Adjusting fc2 accordingly.................\")\n",
    "mat=net.state_dict()[\"fc2.weight\"].t()\n",
    "# print(mat.shape)\n",
    "\n",
    "temp_weight=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(mat[0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=mat[points]\n",
    "    temp_weight.append(row)\n",
    "# print(len(temp_weight), temp_weight[0].shape)\n",
    "\n",
    "newmat=torch.stack(temp_weight, dim=0)\n",
    "newmat=newmat.t()\n",
    "# print(newmat.shape)\n",
    "\n",
    "# print(net.state_dict()[\"fc2.bias\"].shape)\n",
    "\n",
    "net_2 = changenet(net, \"fc2\", newmat, net.state_dict()[\"fc2.bias\"])\n",
    "net=copy.deepcopy(net_2)\n",
    "\n",
    "print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "print(net.state_dict()[\"fc3.weight\"].shape)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, len(net.state_dict()[\"fc1.weight\"]))\n",
    "        self.fc2 = nn.Linear(len(net.state_dict()[\"fc2.weight\"][0]), len(net.state_dict()[\"fc2.weight\"]))\n",
    "        self.fc3 = nn.Linear(len(net.state_dict()[\"fc3.weight\"][0]), 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    \n",
    "from torchsummary import summary\n",
    "device=torch.device(\"cpu\")\n",
    "model=Net().to(device)\n",
    "summary(model, input_size=(1, 28, 28), device=\"cpu\")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "\n",
    "print(\"Pruning fc2.................\")\n",
    "from collections import defaultdict\n",
    "nodes=defaultdict(list)\n",
    "for j in range(len(net.state_dict()[\"fc2.weight\"])):  #Means j is a node of next layer, L2.\n",
    "    nodes[j]=net.state_dict()[\"fc2.weight\"][j]\n",
    "\n",
    "# print(len(nodes), \" \", len(nodes[0]))\n",
    "\n",
    "\n",
    "distances=[]\n",
    "for i in nodes.keys():\n",
    "    for j in nodes.keys():\n",
    "        if(i!=j and j>i):\n",
    "            distances.append(euclidean_distance(nodes[i], nodes[j]))\n",
    "            \n",
    "distances.sort()\n",
    "# print(len(distances))\n",
    "\n",
    "print(\"Finding clusters of nodes.................\")\n",
    "setpoints=findsets(70, nodes, distances)\n",
    "\n",
    "# print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "temp_weight=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(net.state_dict()[\"fc2.weight\"][0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=net.state_dict()[\"fc2.weight\"][points]\n",
    "    row=row/len(setpoints[key])\n",
    "    temp_weight.append(row)\n",
    "# print(len(temp_weight), temp_weight[0].shape)\n",
    "\n",
    "# print(net.state_dict()[\"fc2.bias\"].shape)\n",
    "temp_bias=torch.zeros(len(temp_weight), dtype=torch.float)\n",
    "i=0\n",
    "for key in setpoints.keys():\n",
    "    for points in setpoints[key]:\n",
    "        temp_bias[i]+=net.state_dict()[\"fc2.bias\"][points]\n",
    "    temp_bias[i]/=len(setpoints[key])\n",
    "    i+=1\n",
    "# print(temp_bias.shape)\n",
    "\n",
    "print(\"Updating fc2.................\")\n",
    "net_3 = changenet(net, \"fc2\", temp_weight, temp_bias)\n",
    "net=copy.deepcopy(net_3)\n",
    "\n",
    "mat=net.state_dict()[\"fc3.weight\"].t()\n",
    "# print(mat.shape)\n",
    "\n",
    "temp_weight=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(mat[0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=mat[points]\n",
    "    temp_weight.append(row)\n",
    "# print(len(temp_weight), temp_weight[0].shape)\n",
    "\n",
    "newmat=torch.stack(temp_weight, dim=0)\n",
    "newmat=newmat.t()\n",
    "# print(newmat.shape)\n",
    "\n",
    "print(\"Adjusting fc3 accordingly.................\")\n",
    "net_4 = changenet(net, \"fc3\", newmat, net.state_dict()[\"fc3.bias\"])\n",
    "net=copy.deepcopy(net_4)\n",
    "\n",
    "print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "print(net.state_dict()[\"fc3.weight\"].shape)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, len(net.state_dict()[\"fc1.weight\"]))\n",
    "        self.fc2 = nn.Linear(len(net.state_dict()[\"fc2.weight\"][0]), len(net.state_dict()[\"fc2.weight\"]))\n",
    "        self.fc3 = nn.Linear(len(net.state_dict()[\"fc3.weight\"][0]), 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "i=0\n",
    "for parameter in net.parameters():\n",
    "    i+=1\n",
    "    if(i<5):\n",
    "        parameter.requires_grad=False\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.1307,), (0.3081,))])\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=200,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=200,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('0', '1', '2', '3',\n",
    "           '4', '5', '6', '7', '8', '9')\n",
    "\n",
    "# import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        # print(inputs.shape)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    # print every 2000 mini-batches\n",
    "            print(\"[{}, {}] loss: {}\".format\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Reraining')\n",
    "\n",
    "\n",
    "from torchsummary import summary\n",
    "device=torch.device(\"cpu\")\n",
    "model=Net().to(device)\n",
    "summary(model, input_size=(1, 28, 28), device=\"cpu\")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"LeNET_210_70_MNIST_Model_My_Exiperiment_4_Fine_Tuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning fc1.................\n",
      "Finding clusters of nodes.................\n",
      "desired len= 180\n",
      "cut_off= 0.8881022881134663\n",
      "iteration= 1  length= 16  difference= -164  change rate= 0.0008881022881134662\n",
      "cut_off= 0.7424535128628578\n",
      "iteration= 2  length= 208  difference= 28  change rate= 0.0008881022881134662\n",
      "cut_off= 0.7673203769300349\n",
      "iteration= 3  length= 194  difference= 14  change rate= 0.0008881022881134662\n",
      "cut_off= 0.7797538089636233\n",
      "iteration= 4  length= 174  difference= -6  change rate= 0.0008881022881134662\n",
      "cut_off= 0.7744251952349426\n",
      "iteration= 5  length= 182  difference= 2  change rate= 0.0008881022881134662\n",
      "cut_off= 0.7762013998111695\n",
      "iteration= 6  length= 176  difference= -4  change rate= 0.00042477657128757776\n",
      "cut_off= 0.7745022935260192\n",
      "iteration= 7  length= 182  difference= 2  change rate= 0.00042477657128757776\n",
      "cut_off= 0.7753518466685944\n",
      "iteration= 8  length= 180  difference= 2  change rate= 0.00042477657128757776\n",
      "Updating fc1.................\n",
      "torch.Size([210])  ->  torch.Size([180])\n",
      "torch.Size([210, 256])  ->  torch.Size([180, 256])\n",
      "Adjusting fc2 accordingly.................\n",
      "torch.Size([180, 256])\n",
      "torch.Size([70, 180])\n",
      "torch.Size([10, 70])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 24, 24]             156\n",
      "         MaxPool2d-2            [-1, 6, 12, 12]               0\n",
      "            Conv2d-3             [-1, 16, 8, 8]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 4, 4]               0\n",
      "            Linear-5                  [-1, 180]          46,260\n",
      "            Linear-6                   [-1, 70]          12,670\n",
      "            Linear-7                   [-1, 10]             710\n",
      "================================================================\n",
      "Total params: 62,212\n",
      "Trainable params: 62,212\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 0.24\n",
      "Estimated Total Size (MB): 0.29\n",
      "----------------------------------------------------------------\n",
      "Accuracy of the network on the test images: 98.480000 %\n",
      "Pruning fc2.................\n",
      "Finding clusters of nodes.................\n",
      "desired len= 60\n",
      "cut_off= 0.9457816859076816\n",
      "iteration= 1  length= 2  difference= -58  change rate= 0.0009457816859076817\n",
      "cut_off= 0.8909263481250361\n",
      "iteration= 2  length= 6  difference= -54  change rate= 0.0009457816859076817\n",
      "cut_off= 0.8398541370860213\n",
      "iteration= 3  length= 10  difference= -50  change rate= 0.0009457816859076817\n",
      "cut_off= 0.7925650527906372\n",
      "iteration= 4  length= 21  difference= -39  change rate= 0.0009457816859076817\n",
      "cut_off= 0.7556795670402375\n",
      "iteration= 5  length= 28  difference= -32  change rate= 0.0009457816859076817\n",
      "cut_off= 0.7254145530911917\n",
      "iteration= 6  length= 37  difference= -23  change rate= 0.0009457816859076817\n",
      "cut_off= 0.7036615743153151\n",
      "iteration= 7  length= 45  difference= -15  change rate= 0.0009457816859076817\n",
      "cut_off= 0.6894748490266999\n",
      "iteration= 8  length= 51  difference= -9  change rate= 0.0009457816859076817\n",
      "cut_off= 0.6809628138535307\n",
      "iteration= 9  length= 54  difference= -6  change rate= 0.0009457816859076817\n",
      "cut_off= 0.6752881237380847\n",
      "iteration= 10  length= 55  difference= -5  change rate= 0.0009457816859076817\n",
      "cut_off= 0.6705592153085462\n",
      "iteration= 11  length= 55  difference= -5  change rate= 0.0009457816859076817\n",
      "cut_off= 0.6658303068790078\n",
      "iteration= 12  length= 55  difference= -5  change rate= 0.0009457816859076817\n",
      "cut_off= 0.6611013984494694\n",
      "iteration= 13  length= 56  difference= -4  change rate= 0.0009457816859076817\n",
      "cut_off= 0.6573182717058387\n",
      "iteration= 14  length= 56  difference= -4  change rate= 0.0009457816859076817\n",
      "cut_off= 0.653535144962208\n",
      "iteration= 15  length= 57  difference= -3  change rate= 0.0009457816859076817\n",
      "cut_off= 0.650697799904485\n",
      "iteration= 16  length= 57  difference= -3  change rate= 0.0009457816859076817\n",
      "cut_off= 0.6478604548467619\n",
      "iteration= 17  length= 57  difference= -3  change rate= 0.0009457816859076817\n",
      "cut_off= 0.6450231097890389\n",
      "iteration= 18  length= 58  difference= -2  change rate= 0.0009457816859076817\n",
      "cut_off= 0.6431315464172235\n",
      "iteration= 19  length= 59  difference= -1  change rate= 0.0009457816859076817\n",
      "cut_off= 0.6421857647313158\n",
      "iteration= 20  length= 59  difference= -1  change rate= 0.0009457816859076817\n",
      "cut_off= 0.6412399830454082\n",
      "iteration= 21  length= 59  difference= -1  change rate= 0.0009457816859076817\n",
      "cut_off= 0.6402942013595005\n",
      "iteration= 22  length= 59  difference= -1  change rate= 0.0009457816859076817\n",
      "cut_off= 0.6393484196735929\n",
      "iteration= 23  length= 59  difference= -1  change rate= 0.0009457816859076817\n",
      "cut_off= 0.6384026379876853\n",
      "iteration= 24  length= 61  difference= 1  change rate= 0.0008512035173169135\n",
      "cut_off= 0.6392538415050022\n",
      "iteration= 25  length= 59  difference= -1  change rate= 0.0007660831655852222\n",
      "cut_off= 0.638487758339417\n",
      "iteration= 26  length= 61  difference= 1  change rate= 0.0006894748490267\n",
      "cut_off= 0.6391772331884437\n",
      "iteration= 27  length= 60  difference= 1  change rate= 0.0006894748490267\n",
      "Updating fc2.................\n",
      "Adjusting fc3 accordingly.................\n",
      "torch.Size([180, 256])\n",
      "torch.Size([60, 180])\n",
      "torch.Size([10, 60])\n",
      "Accuracy of the network on the test images: 98.080000 %\n",
      "[1, 20] loss: 0.0003499448182992637\n",
      "[1, 40] loss: 0.00029348668875172734\n",
      "[1, 60] loss: 0.00031974266516044737\n",
      "[1, 80] loss: 0.0002994513129815459\n",
      "[1, 100] loss: 0.00028181137656792997\n",
      "[1, 120] loss: 0.0003018262991681695\n",
      "[1, 140] loss: 0.0003165593796875328\n",
      "[1, 160] loss: 0.0002761358884163201\n",
      "[1, 180] loss: 0.00029985819151625036\n",
      "[1, 200] loss: 0.0002988238474354148\n",
      "[1, 220] loss: 0.0003039874243550003\n",
      "[1, 240] loss: 0.00032882340950891376\n",
      "[1, 260] loss: 0.0002869564569555223\n",
      "[1, 280] loss: 0.00031036923918873073\n",
      "[1, 300] loss: 0.0002559516648761928\n",
      "[2, 20] loss: 0.0002544610574841499\n",
      "[2, 40] loss: 0.00028113106871023775\n",
      "[2, 60] loss: 0.0002740276146214455\n",
      "[2, 80] loss: 0.00022436334379017354\n",
      "[2, 100] loss: 0.00024378148070536553\n",
      "[2, 120] loss: 0.0003708941703662276\n",
      "[2, 140] loss: 0.00023025764804333448\n",
      "[2, 160] loss: 0.0003013763404451311\n",
      "[2, 180] loss: 0.00026664331322535874\n",
      "[2, 200] loss: 0.00021069624437950553\n",
      "[2, 220] loss: 0.00031101752538234\n",
      "[2, 240] loss: 0.0002607651851139963\n",
      "[2, 260] loss: 0.0002988876225426793\n",
      "[2, 280] loss: 0.0002837597671896219\n",
      "[2, 300] loss: 0.00034645194560289385\n",
      "[3, 20] loss: 0.00023570614168420435\n",
      "[3, 40] loss: 0.000211552647408098\n",
      "[3, 60] loss: 0.0002685292530804873\n",
      "[3, 80] loss: 0.0002847186126746237\n",
      "[3, 100] loss: 0.0002890274925157428\n",
      "[3, 120] loss: 0.0002410315671004355\n",
      "[3, 140] loss: 0.00030350676644593476\n",
      "[3, 160] loss: 0.00030022730119526385\n",
      "[3, 180] loss: 0.0003473078282549977\n",
      "[3, 200] loss: 0.00024151308555155993\n",
      "[3, 220] loss: 0.00022272831667214632\n",
      "[3, 240] loss: 0.00033355836407281456\n",
      "[3, 260] loss: 0.0002440256024710834\n",
      "[3, 280] loss: 0.0002246864610351622\n",
      "[3, 300] loss: 0.0002872311766259372\n",
      "[4, 20] loss: 0.00022315292106941343\n",
      "[4, 40] loss: 0.00026145580504089593\n",
      "[4, 60] loss: 0.00024818977317772806\n",
      "[4, 80] loss: 0.0002607196145690978\n",
      "[4, 100] loss: 0.00033074663346633313\n",
      "[4, 120] loss: 0.00027058246545493605\n",
      "[4, 140] loss: 0.0001990691975224763\n",
      "[4, 160] loss: 0.0001849647406488657\n",
      "[4, 180] loss: 0.00023481547180563211\n",
      "[4, 200] loss: 0.00028320586145855485\n",
      "[4, 220] loss: 0.00031219619256444273\n",
      "[4, 240] loss: 0.00029531087167561056\n",
      "[4, 260] loss: 0.00027297117840498685\n",
      "[4, 280] loss: 0.0002599637322127819\n",
      "[4, 300] loss: 0.0002641010330989957\n",
      "[5, 20] loss: 0.0002472359868697822\n",
      "[5, 40] loss: 0.0002798986453562975\n",
      "[5, 60] loss: 0.00024185473565012218\n",
      "[5, 80] loss: 0.00023591843573376537\n",
      "[5, 100] loss: 0.0002669559963978827\n",
      "[5, 120] loss: 0.0002875351277180016\n",
      "[5, 140] loss: 0.00026026374427601695\n",
      "[5, 160] loss: 0.0002600600039586425\n",
      "[5, 180] loss: 0.0002940666729118675\n",
      "[5, 200] loss: 0.00025123145431280134\n",
      "[5, 220] loss: 0.00019157529738731682\n",
      "[5, 240] loss: 0.0002931803655810654\n",
      "[5, 260] loss: 0.00026717290421947835\n",
      "[5, 280] loss: 0.00030669282516464593\n",
      "[5, 300] loss: 0.00025024284049868586\n",
      "[6, 20] loss: 0.0002747930334880948\n",
      "[6, 40] loss: 0.00020950167789123952\n",
      "[6, 60] loss: 0.000254716866184026\n",
      "[6, 80] loss: 0.0002797066504135728\n",
      "[6, 100] loss: 0.0002604504533810541\n",
      "[6, 120] loss: 0.00017867289413698017\n",
      "[6, 140] loss: 0.00017794457636773588\n",
      "[6, 160] loss: 0.000216657709563151\n",
      "[6, 180] loss: 0.0003533826977945864\n",
      "[6, 200] loss: 0.00029098693886771797\n",
      "[6, 220] loss: 0.0002551026386208832\n",
      "[6, 240] loss: 0.00022280496126040816\n",
      "[6, 260] loss: 0.000254823780618608\n",
      "[6, 280] loss: 0.0003769716960377991\n",
      "[6, 300] loss: 0.00028593306010589003\n",
      "[7, 20] loss: 0.000287480067461729\n",
      "[7, 40] loss: 0.00025827682856470344\n",
      "[7, 60] loss: 0.00029895992297679185\n",
      "[7, 80] loss: 0.00019710951927118004\n",
      "[7, 100] loss: 0.0002375439484603703\n",
      "[7, 120] loss: 0.0003089746355544776\n",
      "[7, 140] loss: 0.00023375634779222308\n",
      "[7, 160] loss: 0.0002148584658280015\n",
      "[7, 180] loss: 0.0001657135784626007\n",
      "[7, 200] loss: 0.0002540911245159805\n",
      "[7, 220] loss: 0.0002515240823850036\n",
      "[7, 240] loss: 0.000247846054378897\n",
      "[7, 260] loss: 0.0002741858079098165\n",
      "[7, 280] loss: 0.00021727900533005594\n",
      "[7, 300] loss: 0.0002229221153538674\n",
      "[8, 20] loss: 0.0002522630421444774\n",
      "[8, 40] loss: 0.00020691921631805599\n",
      "[8, 60] loss: 0.00029286241927184165\n",
      "[8, 80] loss: 0.000263527057133615\n",
      "[8, 100] loss: 0.00025739223370328546\n",
      "[8, 120] loss: 0.00023887847550213337\n",
      "[8, 140] loss: 0.00023537140991538764\n",
      "[8, 160] loss: 0.0003176381103694439\n",
      "[8, 180] loss: 0.00028305681282654404\n",
      "[8, 200] loss: 0.00023564091906882822\n",
      "[8, 220] loss: 0.00020736302016302944\n",
      "[8, 240] loss: 0.00022398677095770837\n",
      "[8, 260] loss: 0.00023390469967853278\n",
      "[8, 280] loss: 0.00026905357895884663\n",
      "[8, 300] loss: 0.0002411822595167905\n",
      "[9, 20] loss: 0.0002041064822115004\n",
      "[9, 40] loss: 0.0002486573630012572\n",
      "[9, 60] loss: 0.00020452097756788135\n",
      "[9, 80] loss: 0.0002362297778017819\n",
      "[9, 100] loss: 0.0002982014333829284\n",
      "[9, 120] loss: 0.00023849383741617202\n",
      "[9, 140] loss: 0.00023300436278805137\n",
      "[9, 160] loss: 0.0002530236667953432\n",
      "[9, 180] loss: 0.0002456315711606294\n",
      "[9, 200] loss: 0.00018868848867714406\n",
      "[9, 220] loss: 0.00020610884670168163\n",
      "[9, 240] loss: 0.00026161349518224596\n",
      "[9, 260] loss: 0.0002163332304917276\n",
      "[9, 280] loss: 0.0002610752428881824\n",
      "[9, 300] loss: 0.00031709218118339776\n",
      "[10, 20] loss: 0.00027512843883596363\n",
      "[10, 40] loss: 0.00025384491449221967\n",
      "[10, 60] loss: 0.0002518601207993925\n",
      "[10, 80] loss: 0.00018177663465030491\n",
      "[10, 100] loss: 0.00021237958827987315\n",
      "[10, 120] loss: 0.00025910578144248573\n",
      "[10, 140] loss: 0.00029870749171823264\n",
      "[10, 160] loss: 0.00021840577630791814\n",
      "[10, 180] loss: 0.00017896163347177208\n",
      "[10, 200] loss: 0.00017668551695533097\n",
      "[10, 220] loss: 0.00025470795622095464\n",
      "[10, 240] loss: 0.00026154634589329364\n",
      "[10, 260] loss: 0.00027858974132686853\n",
      "[10, 280] loss: 0.00019835932622663677\n",
      "[10, 300] loss: 0.00019142047432251275\n",
      "[11, 20] loss: 0.00025477388594299553\n",
      "[11, 40] loss: 0.0002129861561115831\n",
      "[11, 60] loss: 0.0002526027355343103\n",
      "[11, 80] loss: 0.00018127428134903311\n",
      "[11, 100] loss: 0.00022382670640945434\n",
      "[11, 120] loss: 0.0002481377781368792\n",
      "[11, 140] loss: 0.00023970654513686895\n",
      "[11, 160] loss: 0.00020971817895770072\n",
      "[11, 180] loss: 0.00018335572304204107\n",
      "[11, 200] loss: 0.0002702241619117558\n",
      "[11, 220] loss: 0.00022520068916492163\n",
      "[11, 240] loss: 0.00021340887970291078\n",
      "[11, 260] loss: 0.00027279744460247454\n",
      "[11, 280] loss: 0.0002322083639446646\n",
      "[11, 300] loss: 0.000278792726341635\n",
      "[12, 20] loss: 0.0002489336561411619\n",
      "[12, 40] loss: 0.00022393198614008725\n",
      "[12, 60] loss: 0.0002092280825600028\n",
      "[12, 80] loss: 0.00023503007600083947\n",
      "[12, 100] loss: 0.00020385603932663798\n",
      "[12, 120] loss: 0.00023167896526865662\n",
      "[12, 140] loss: 0.00024232671887148172\n",
      "[12, 160] loss: 0.00026030840049497784\n",
      "[12, 180] loss: 0.00020463897986337543\n",
      "[12, 200] loss: 0.00020659708464518188\n",
      "[12, 220] loss: 0.00019753300002776087\n",
      "[12, 240] loss: 0.0003004612002987415\n",
      "[12, 260] loss: 0.00021591201261617245\n",
      "[12, 280] loss: 0.0002352990536019206\n",
      "[12, 300] loss: 0.00022701589367352427\n",
      "[13, 20] loss: 0.00019117034832015633\n",
      "[13, 40] loss: 0.00022124871076084672\n",
      "[13, 60] loss: 0.00019582594092935323\n",
      "[13, 80] loss: 0.0002069380630273372\n",
      "[13, 100] loss: 0.00017924966220743955\n",
      "[13, 120] loss: 0.0002296824052464217\n",
      "[13, 140] loss: 0.00022087803669273854\n",
      "[13, 160] loss: 0.00022141915699467062\n",
      "[13, 180] loss: 0.00019501767260953783\n",
      "[13, 200] loss: 0.00024484260659664867\n",
      "[13, 220] loss: 0.00026697684684768316\n",
      "[13, 240] loss: 0.00022543274937197565\n",
      "[13, 260] loss: 0.00023920926591381432\n",
      "[13, 280] loss: 0.00023881959333084524\n",
      "[13, 300] loss: 0.00024385343678295611\n",
      "[14, 20] loss: 0.00017611409584060311\n",
      "[14, 40] loss: 0.00015649438090622426\n",
      "[14, 60] loss: 0.0002746542983222753\n",
      "[14, 80] loss: 0.00021375571843236684\n",
      "[14, 100] loss: 0.00018981609540060163\n",
      "[14, 120] loss: 0.00020111166802234948\n",
      "[14, 140] loss: 0.0002042654063552618\n",
      "[14, 160] loss: 0.00021263059624470772\n",
      "[14, 180] loss: 0.0002829700540751219\n",
      "[14, 200] loss: 0.000230965047609061\n",
      "[14, 220] loss: 0.0002288601470645517\n",
      "[14, 240] loss: 0.0001761677502654493\n",
      "[14, 260] loss: 0.00022814115043729544\n",
      "[14, 280] loss: 0.00025640632724389435\n",
      "[14, 300] loss: 0.00018552797986194492\n",
      "[15, 20] loss: 0.00018173707276582718\n",
      "[15, 40] loss: 0.0002029919440392405\n",
      "[15, 60] loss: 0.00021694740699604155\n",
      "[15, 80] loss: 0.00019588730693794788\n",
      "[15, 100] loss: 0.00017263790068682282\n",
      "[15, 120] loss: 0.0002435134435072541\n",
      "[15, 140] loss: 0.00022481205128133298\n",
      "[15, 160] loss: 0.00027065809397026897\n",
      "[15, 180] loss: 0.00019310692371800542\n",
      "[15, 200] loss: 0.00020246086723636837\n",
      "[15, 220] loss: 0.00021905406937003136\n",
      "[15, 240] loss: 0.00018772193952463568\n",
      "[15, 260] loss: 0.00022272034455090762\n",
      "[15, 280] loss: 0.00023057571984827518\n",
      "[15, 300] loss: 0.0002700463887304068\n",
      "[16, 20] loss: 0.0002145719847176224\n",
      "[16, 40] loss: 0.00021662002988159657\n",
      "[16, 60] loss: 0.00022816775739192962\n",
      "[16, 80] loss: 0.00020229719136841595\n",
      "[16, 100] loss: 0.0002611876328010112\n",
      "[16, 120] loss: 0.00019476205995306372\n",
      "[16, 140] loss: 0.00017573728994466363\n",
      "[16, 160] loss: 0.00024216819577850402\n",
      "[16, 180] loss: 0.00020215666643343865\n",
      "[16, 200] loss: 0.00019487283751368523\n",
      "[16, 220] loss: 0.00015462318016216158\n",
      "[16, 240] loss: 0.00023175135953351855\n",
      "[16, 260] loss: 0.0002686417864169925\n",
      "[16, 280] loss: 0.0002598087298683822\n",
      "[16, 300] loss: 0.0001999847509432584\n",
      "[17, 20] loss: 0.0001634055022150278\n",
      "[17, 40] loss: 0.00018381957383826374\n",
      "[17, 60] loss: 0.00015904088714160025\n",
      "[17, 80] loss: 0.00019326740491669626\n",
      "[17, 100] loss: 0.00026502629998140036\n",
      "[17, 120] loss: 0.00019176679174415768\n",
      "[17, 140] loss: 0.0002537949439138174\n",
      "[17, 160] loss: 0.00015423564915545285\n",
      "[17, 180] loss: 0.00020086039509624242\n",
      "[17, 200] loss: 0.00024075597967021167\n",
      "[17, 220] loss: 0.00021919192280620337\n",
      "[17, 240] loss: 0.00021446624444797636\n",
      "[17, 260] loss: 0.0002818728573620319\n",
      "[17, 280] loss: 0.00023079155571758747\n",
      "[17, 300] loss: 0.00020439978456124664\n",
      "[18, 20] loss: 0.0002441553552635014\n",
      "[18, 40] loss: 0.00016916002240031957\n",
      "[18, 60] loss: 0.00018754963530227543\n",
      "[18, 80] loss: 0.00021060322178527712\n",
      "[18, 100] loss: 0.00020675155613571406\n",
      "[18, 120] loss: 0.0002646957659162581\n",
      "[18, 140] loss: 0.00021435093972831963\n",
      "[18, 160] loss: 0.0001627291499171406\n",
      "[18, 180] loss: 0.0002019776916131377\n",
      "[18, 200] loss: 0.00021099826670251787\n",
      "[18, 220] loss: 0.000190113092539832\n",
      "[18, 240] loss: 0.0001910059885121882\n",
      "[18, 260] loss: 0.00023967863013967872\n",
      "[18, 280] loss: 0.00022989951411727817\n",
      "[18, 300] loss: 0.0002290085768327117\n",
      "[19, 20] loss: 0.0001950917700305581\n",
      "[19, 40] loss: 0.00021914860419929027\n",
      "[19, 60] loss: 0.00020269378321245314\n",
      "[19, 80] loss: 0.00019339448981918394\n",
      "[19, 100] loss: 0.000226184667320922\n",
      "[19, 120] loss: 0.0002452520467340946\n",
      "[19, 140] loss: 0.00020628865039907395\n",
      "[19, 160] loss: 0.00021060213586315512\n",
      "[19, 180] loss: 0.00021459491760469974\n",
      "[19, 200] loss: 0.00018829762213863431\n",
      "[19, 220] loss: 0.0002548505414742976\n",
      "[19, 240] loss: 0.00018630411033518612\n",
      "[19, 260] loss: 0.00017632134607993067\n",
      "[19, 280] loss: 0.0002531414667610079\n",
      "[19, 300] loss: 0.00020609475928358735\n",
      "[20, 20] loss: 0.00021111159073188902\n",
      "[20, 40] loss: 0.0002309598030988127\n",
      "[20, 60] loss: 0.0001825725268572569\n",
      "[20, 80] loss: 0.00018207669211551546\n",
      "[20, 100] loss: 0.0001611254292074591\n",
      "[20, 120] loss: 0.00020949716528411954\n",
      "[20, 140] loss: 0.0002301781491842121\n",
      "[20, 160] loss: 0.0001745882935356349\n",
      "[20, 180] loss: 0.00029194433288648724\n",
      "[20, 200] loss: 0.00017579466197639704\n",
      "[20, 220] loss: 0.00015740566235035658\n",
      "[20, 240] loss: 0.00016393835050985218\n",
      "[20, 260] loss: 0.00017222158168442547\n",
      "[20, 280] loss: 0.00018950516846962274\n",
      "[20, 300] loss: 0.0002765065124258399\n",
      "Finished Reraining\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 24, 24]             156\n",
      "         MaxPool2d-2            [-1, 6, 12, 12]               0\n",
      "            Conv2d-3             [-1, 16, 8, 8]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 4, 4]               0\n",
      "            Linear-5                  [-1, 180]          46,260\n",
      "            Linear-6                   [-1, 60]          10,860\n",
      "            Linear-7                   [-1, 10]             610\n",
      "================================================================\n",
      "Total params: 60,302\n",
      "Trainable params: 60,302\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 0.23\n",
      "Estimated Total Size (MB): 0.28\n",
      "----------------------------------------------------------------\n",
      "Accuracy of the network on the test images: 98.520000 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Pruning fc1.................\")\n",
    "\n",
    "nodes=defaultdict(list)\n",
    "for j in range(len(net.state_dict()[\"fc1.weight\"])):  #Means j is a node of next layer, L2. Fc1 is connecting L1 and L2 layer.\n",
    "    nodes[j]=net.state_dict()[\"fc1.weight\"][j]\n",
    "\n",
    "# print(len(nodes), \" \", len(nodes[0]))\n",
    "\n",
    "# from math import sqrt\n",
    "distances=[]\n",
    "for i in nodes.keys():\n",
    "    for j in nodes.keys():\n",
    "        if(i!=j and j>i):\n",
    "            distances.append(euclidean_distance(nodes[i], nodes[j]))\n",
    "\n",
    "distances.sort()\n",
    "            \n",
    "print(\"Finding clusters of nodes.................\")\n",
    "setpoints=findsets(180, nodes, distances)\n",
    "\n",
    "# print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "temp_weights=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(net.state_dict()[\"fc1.weight\"][0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=net.state_dict()[\"fc1.weight\"][points]\n",
    "    row=row/len(setpoints[key])\n",
    "    temp_weights.append(row)\n",
    "# print(len(temp_weights), temp_weights[0].shape)\n",
    "\n",
    "# print(net.state_dict()[\"fc1.bias\"].shape)\n",
    "temp_bias=torch.zeros(len(temp_weights), dtype=torch.float)\n",
    "i=0\n",
    "for key in setpoints.keys():\n",
    "    for points in setpoints[key]:\n",
    "        temp_bias[i]+=net.state_dict()[\"fc1.bias\"][points]\n",
    "    temp_bias[i]/=len(setpoints[key])\n",
    "    i+=1\n",
    "# print(temp_bias.shape)\n",
    "\n",
    "print(\"Updating fc1.................\")\n",
    "net_1 = changenet(net, \"fc1\", temp_weights, temp_bias)\n",
    "\n",
    "print(net.state_dict()[\"fc1.bias\"].shape, \" -> \", net_1.state_dict()[\"fc1.bias\"].shape)\n",
    "print(net.state_dict()[\"fc1.weight\"].shape, \" -> \", net_1.state_dict()[\"fc1.weight\"].shape)\n",
    "\n",
    "net=copy.deepcopy(net_1)\n",
    "# print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "# print(net.state_dict()[\"fc1.bias\"].shape)\n",
    "\n",
    "#just to check if the copy has been done correctly\n",
    "# print(temp_weights[0],\"\\n\\n\",net.state_dict()[\"fc1.weight\"][0])    \n",
    "\n",
    "\n",
    "### Now, we have to change FC2 accordingly:\n",
    "# print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "print(\"Adjusting fc2 accordingly.................\")\n",
    "mat=net.state_dict()[\"fc2.weight\"].t()\n",
    "# print(mat.shape)\n",
    "\n",
    "temp_weight=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(mat[0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=mat[points]\n",
    "    temp_weight.append(row)\n",
    "# print(len(temp_weight), temp_weight[0].shape)\n",
    "\n",
    "newmat=torch.stack(temp_weight, dim=0)\n",
    "newmat=newmat.t()\n",
    "# print(newmat.shape)\n",
    "\n",
    "# print(net.state_dict()[\"fc2.bias\"].shape)\n",
    "\n",
    "net_2 = changenet(net, \"fc2\", newmat, net.state_dict()[\"fc2.bias\"])\n",
    "net=copy.deepcopy(net_2)\n",
    "\n",
    "print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "print(net.state_dict()[\"fc3.weight\"].shape)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, len(net.state_dict()[\"fc1.weight\"]))\n",
    "        self.fc2 = nn.Linear(len(net.state_dict()[\"fc2.weight\"][0]), len(net.state_dict()[\"fc2.weight\"]))\n",
    "        self.fc3 = nn.Linear(len(net.state_dict()[\"fc3.weight\"][0]), 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    \n",
    "from torchsummary import summary\n",
    "device=torch.device(\"cpu\")\n",
    "model=Net().to(device)\n",
    "summary(model, input_size=(1, 28, 28), device=\"cpu\")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "\n",
    "print(\"Pruning fc2.................\")\n",
    "from collections import defaultdict\n",
    "nodes=defaultdict(list)\n",
    "for j in range(len(net.state_dict()[\"fc2.weight\"])):  #Means j is a node of next layer, L2.\n",
    "    nodes[j]=net.state_dict()[\"fc2.weight\"][j]\n",
    "\n",
    "# print(len(nodes), \" \", len(nodes[0]))\n",
    "\n",
    "\n",
    "distances=[]\n",
    "for i in nodes.keys():\n",
    "    for j in nodes.keys():\n",
    "        if(i!=j and j>i):\n",
    "            distances.append(euclidean_distance(nodes[i], nodes[j]))\n",
    "            \n",
    "distances.sort()\n",
    "# print(len(distances))\n",
    "\n",
    "print(\"Finding clusters of nodes.................\")\n",
    "setpoints=findsets(60, nodes, distances)\n",
    "\n",
    "# print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "temp_weight=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(net.state_dict()[\"fc2.weight\"][0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=net.state_dict()[\"fc2.weight\"][points]\n",
    "    row=row/len(setpoints[key])\n",
    "    temp_weight.append(row)\n",
    "# print(len(temp_weight), temp_weight[0].shape)\n",
    "\n",
    "# print(net.state_dict()[\"fc2.bias\"].shape)\n",
    "temp_bias=torch.zeros(len(temp_weight), dtype=torch.float)\n",
    "i=0\n",
    "for key in setpoints.keys():\n",
    "    for points in setpoints[key]:\n",
    "        temp_bias[i]+=net.state_dict()[\"fc2.bias\"][points]\n",
    "    temp_bias[i]/=len(setpoints[key])\n",
    "    i+=1\n",
    "# print(temp_bias.shape)\n",
    "\n",
    "print(\"Updating fc2.................\")\n",
    "net_3 = changenet(net, \"fc2\", temp_weight, temp_bias)\n",
    "net=copy.deepcopy(net_3)\n",
    "\n",
    "mat=net.state_dict()[\"fc3.weight\"].t()\n",
    "# print(mat.shape)\n",
    "\n",
    "temp_weight=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(mat[0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=mat[points]\n",
    "    temp_weight.append(row)\n",
    "# print(len(temp_weight), temp_weight[0].shape)\n",
    "\n",
    "newmat=torch.stack(temp_weight, dim=0)\n",
    "newmat=newmat.t()\n",
    "# print(newmat.shape)\n",
    "\n",
    "print(\"Adjusting fc3 accordingly.................\")\n",
    "net_4 = changenet(net, \"fc3\", newmat, net.state_dict()[\"fc3.bias\"])\n",
    "net=copy.deepcopy(net_4)\n",
    "\n",
    "print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "print(net.state_dict()[\"fc3.weight\"].shape)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, len(net.state_dict()[\"fc1.weight\"]))\n",
    "        self.fc2 = nn.Linear(len(net.state_dict()[\"fc2.weight\"][0]), len(net.state_dict()[\"fc2.weight\"]))\n",
    "        self.fc3 = nn.Linear(len(net.state_dict()[\"fc3.weight\"][0]), 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "i=0\n",
    "for parameter in net.parameters():\n",
    "    i+=1\n",
    "    if(i<5):\n",
    "        parameter.requires_grad=False\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.1307,), (0.3081,))])\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=200,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=200,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('0', '1', '2', '3',\n",
    "           '4', '5', '6', '7', '8', '9')\n",
    "\n",
    "# import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        # print(inputs.shape)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    # print every 2000 mini-batches\n",
    "            print(\"[{}, {}] loss: {}\".format\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Reraining')\n",
    "\n",
    "\n",
    "from torchsummary import summary\n",
    "device=torch.device(\"cpu\")\n",
    "model=Net().to(device)\n",
    "summary(model, input_size=(1, 28, 28), device=\"cpu\")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"LeNET_180_60_MNIST_Model_My_Exiperiment_4_Fine_Tuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning fc1.................\n",
      "Finding clusters of nodes.................\n",
      "desired len= 150\n",
      "cut_off= 0.9020356482103368\n",
      "iteration= 1  length= 1  difference= -149  change rate= 0.0009020356482103368\n",
      "cut_off= 0.7676323366269966\n",
      "iteration= 2  length= 26  difference= -124  change rate= 0.0009020356482103368\n",
      "cut_off= 0.6557799162489149\n",
      "iteration= 3  length= 159  difference= 9  change rate= 0.0009020356482103368\n",
      "cut_off= 0.6638982370828079\n",
      "iteration= 4  length= 157  difference= 7  change rate= 0.0009020356482103368\n",
      "cut_off= 0.6702124866202803\n",
      "iteration= 5  length= 154  difference= 4  change rate= 0.0009020356482103368\n",
      "cut_off= 0.6738206292131217\n",
      "iteration= 6  length= 151  difference= 1  change rate= 0.0009020356482103368\n",
      "cut_off= 0.674722664861332\n",
      "iteration= 7  length= 151  difference= 1  change rate= 0.0009020356482103368\n",
      "cut_off= 0.6756247005095424\n",
      "iteration= 8  length= 151  difference= 1  change rate= 0.0009020356482103368\n",
      "cut_off= 0.6765267361577527\n",
      "iteration= 9  length= 151  difference= 1  change rate= 0.0009020356482103368\n",
      "cut_off= 0.6774287718059631\n",
      "iteration= 10  length= 151  difference= 1  change rate= 0.0009020356482103368\n",
      "cut_off= 0.6783308074541734\n",
      "iteration= 11  length= 151  difference= 1  change rate= 0.0009020356482103368\n",
      "cut_off= 0.6792328431023837\n",
      "iteration= 12  length= 151  difference= 1  change rate= 0.0009020356482103368\n",
      "cut_off= 0.6801348787505941\n",
      "iteration= 13  length= 149  difference= -1  change rate= 0.0008118320833893031\n",
      "cut_off= 0.6793230466672048\n",
      "iteration= 14  length= 151  difference= 1  change rate= 0.0007306488750503728\n",
      "cut_off= 0.6800536955422551\n",
      "iteration= 15  length= 149  difference= -1  change rate= 0.0006575839875453355\n",
      "cut_off= 0.6793961115547098\n",
      "iteration= 16  length= 151  difference= 1  change rate= 0.000591825588790802\n",
      "cut_off= 0.6799879371435006\n",
      "iteration= 17  length= 149  difference= -1  change rate= 0.0005326430299117218\n",
      "cut_off= 0.6794552941135888\n",
      "iteration= 18  length= 151  difference= 1  change rate= 0.00047937872692054966\n",
      "cut_off= 0.6799346728405093\n",
      "iteration= 19  length= 150  difference= 1  change rate= 0.00047937872692054966\n",
      "Updating fc1.................\n",
      "torch.Size([180])  ->  torch.Size([150])\n",
      "torch.Size([180, 256])  ->  torch.Size([150, 256])\n",
      "Adjusting fc2 accordingly.................\n",
      "torch.Size([150, 256])\n",
      "torch.Size([60, 150])\n",
      "torch.Size([10, 60])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 24, 24]             156\n",
      "         MaxPool2d-2            [-1, 6, 12, 12]               0\n",
      "            Conv2d-3             [-1, 16, 8, 8]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 4, 4]               0\n",
      "            Linear-5                  [-1, 150]          38,550\n",
      "            Linear-6                   [-1, 60]           9,060\n",
      "            Linear-7                   [-1, 10]             610\n",
      "================================================================\n",
      "Total params: 50,792\n",
      "Trainable params: 50,792\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 0.19\n",
      "Estimated Total Size (MB): 0.24\n",
      "----------------------------------------------------------------\n",
      "Accuracy of the network on the test images: 94.750000 %\n",
      "Pruning fc2.................\n",
      "Finding clusters of nodes.................\n",
      "desired len= 50\n",
      "cut_off= 0.8989517398797234\n",
      "iteration= 1  length= 5  difference= -45  change rate= 0.0008989517398797234\n",
      "cut_off= 0.8584989115851359\n",
      "iteration= 2  length= 7  difference= -43  change rate= 0.0008989517398797234\n",
      "cut_off= 0.8198439867703078\n",
      "iteration= 3  length= 10  difference= -40  change rate= 0.0008989517398797234\n",
      "cut_off= 0.7838859171751189\n",
      "iteration= 4  length= 14  difference= -36  change rate= 0.0008989517398797234\n",
      "cut_off= 0.7515236545394489\n",
      "iteration= 5  length= 18  difference= -32  change rate= 0.0008989517398797234\n",
      "cut_off= 0.7227571988632978\n",
      "iteration= 6  length= 25  difference= -25  change rate= 0.0008989517398797234\n",
      "cut_off= 0.7002834053663047\n",
      "iteration= 7  length= 29  difference= -21  change rate= 0.0008989517398797234\n",
      "cut_off= 0.6814054188288305\n",
      "iteration= 8  length= 37  difference= -13  change rate= 0.0008989517398797234\n",
      "cut_off= 0.6697190462103941\n",
      "iteration= 9  length= 43  difference= -7  change rate= 0.0008989517398797234\n",
      "cut_off= 0.6634263840312361\n",
      "iteration= 10  length= 43  difference= -7  change rate= 0.0008989517398797234\n",
      "cut_off= 0.6571337218520781\n",
      "iteration= 11  length= 44  difference= -6  change rate= 0.0008989517398797234\n",
      "cut_off= 0.6517400114127997\n",
      "iteration= 12  length= 46  difference= -4  change rate= 0.0008989517398797234\n",
      "cut_off= 0.6481442044532808\n",
      "iteration= 13  length= 47  difference= -3  change rate= 0.0008989517398797234\n",
      "cut_off= 0.6454473492336417\n",
      "iteration= 14  length= 49  difference= -1  change rate= 0.0008989517398797234\n",
      "cut_off= 0.6445483974937619\n",
      "iteration= 15  length= 49  difference= -1  change rate= 0.0008989517398797234\n",
      "cut_off= 0.6436494457538822\n",
      "iteration= 16  length= 49  difference= -1  change rate= 0.0008989517398797234\n",
      "cut_off= 0.6427504940140024\n",
      "iteration= 17  length= 49  difference= -1  change rate= 0.0008989517398797234\n",
      "cut_off= 0.6418515422741227\n",
      "iteration= 18  length= 49  difference= -1  change rate= 0.0008989517398797234\n",
      "cut_off= 0.6409525905342429\n",
      "iteration= 19  length= 49  difference= -1  change rate= 0.0008989517398797234\n",
      "cut_off= 0.6400536387943632\n",
      "iteration= 20  length= 49  difference= -1  change rate= 0.0008989517398797234\n",
      "cut_off= 0.6391546870544834\n",
      "iteration= 21  length= 49  difference= -1  change rate= 0.0008989517398797234\n",
      "cut_off= 0.6382557353146037\n",
      "iteration= 22  length= 49  difference= -1  change rate= 0.0008989517398797234\n",
      "cut_off= 0.6373567835747239\n",
      "iteration= 23  length= 49  difference= -1  change rate= 0.0008989517398797234\n",
      "cut_off= 0.6364578318348442\n",
      "iteration= 24  length= 50  difference= -1  change rate= 0.0008989517398797234\n",
      "Updating fc2.................\n",
      "Adjusting fc3 accordingly.................\n",
      "torch.Size([150, 256])\n",
      "torch.Size([50, 150])\n",
      "torch.Size([10, 50])\n",
      "Accuracy of the network on the test images: 95.680000 %\n",
      "[1, 20] loss: 0.000585575276054442\n",
      "[1, 40] loss: 0.00035792807955294846\n",
      "[1, 60] loss: 0.0002965382030233741\n",
      "[1, 80] loss: 0.00031136070843786\n",
      "[1, 100] loss: 0.0002964813564904034\n",
      "[1, 120] loss: 0.00024328205501660704\n",
      "[1, 140] loss: 0.00028156964434310796\n",
      "[1, 160] loss: 0.00025872472021728755\n",
      "[1, 180] loss: 0.00026059784088283775\n",
      "[1, 200] loss: 0.0002636372246779501\n",
      "[1, 220] loss: 0.0002589728911407292\n",
      "[1, 240] loss: 0.0003462996263988316\n",
      "[1, 260] loss: 0.000313487455714494\n",
      "[1, 280] loss: 0.0002576082632876933\n",
      "[1, 300] loss: 0.0002786766733042896\n",
      "[2, 20] loss: 0.00024211528128944337\n",
      "[2, 40] loss: 0.00027827848168089983\n",
      "[2, 60] loss: 0.00022052154992707073\n",
      "[2, 80] loss: 0.0002319641560316086\n",
      "[2, 100] loss: 0.0002676504710689187\n",
      "[2, 120] loss: 0.00029466782324016097\n",
      "[2, 140] loss: 0.0002851244271732867\n",
      "[2, 160] loss: 0.00022546022897586228\n",
      "[2, 180] loss: 0.00023588628834113478\n",
      "[2, 200] loss: 0.00019996937946416436\n",
      "[2, 220] loss: 0.00024509557010605934\n",
      "[2, 240] loss: 0.00023936877120286226\n",
      "[2, 260] loss: 0.0002792231277562678\n",
      "[2, 280] loss: 0.00027425518492236735\n",
      "[2, 300] loss: 0.00028607112588360903\n",
      "[3, 20] loss: 0.00024634802108630536\n",
      "[3, 40] loss: 0.00024375208909623326\n",
      "[3, 60] loss: 0.0001892793755978346\n",
      "[3, 80] loss: 0.00020640338957309722\n",
      "[3, 100] loss: 0.00024180859536863863\n",
      "[3, 120] loss: 0.00024155889172106982\n",
      "[3, 140] loss: 0.00020265323878265919\n",
      "[3, 160] loss: 0.0003020139499567449\n",
      "[3, 180] loss: 0.00023475509183481337\n",
      "[3, 200] loss: 0.000265356722753495\n",
      "[3, 220] loss: 0.0002910167332738638\n",
      "[3, 240] loss: 0.00022905620699748396\n",
      "[3, 260] loss: 0.00026066693430766466\n",
      "[3, 280] loss: 0.0002653344422578812\n",
      "[3, 300] loss: 0.00023520578374154865\n",
      "[4, 20] loss: 0.0002534984645899385\n",
      "[4, 40] loss: 0.00024361863313242794\n",
      "[4, 60] loss: 0.00017429184936918317\n",
      "[4, 80] loss: 0.00023265650100074708\n",
      "[4, 100] loss: 0.00018132152175530792\n",
      "[4, 120] loss: 0.00029672286473214626\n",
      "[4, 140] loss: 0.0002668960685841739\n",
      "[4, 160] loss: 0.00026080344920046626\n",
      "[4, 180] loss: 0.00023432815331034362\n",
      "[4, 200] loss: 0.00019538495596498252\n",
      "[4, 220] loss: 0.0002472953833639622\n",
      "[4, 240] loss: 0.0002644529179669917\n",
      "[4, 260] loss: 0.00023586147977039217\n",
      "[4, 280] loss: 0.0002193305268883705\n",
      "[4, 300] loss: 0.0002444782683160156\n",
      "[5, 20] loss: 0.00026856359746307135\n",
      "[5, 40] loss: 0.00028689348604530094\n",
      "[5, 60] loss: 0.00024315588385798037\n",
      "[5, 80] loss: 0.0002322177216410637\n",
      "[5, 100] loss: 0.00023988743405789137\n",
      "[5, 120] loss: 0.00023678144300356507\n",
      "[5, 140] loss: 0.0002249315702356398\n",
      "[5, 160] loss: 0.00022317945025861262\n",
      "[5, 180] loss: 0.0002412427985109389\n",
      "[5, 200] loss: 0.00021770134475082158\n",
      "[5, 220] loss: 0.00019402973633259534\n",
      "[5, 240] loss: 0.0002463452664669603\n",
      "[5, 260] loss: 0.00024865443678572777\n",
      "[5, 280] loss: 0.00018855123384855688\n",
      "[5, 300] loss: 0.0001916262952145189\n",
      "[6, 20] loss: 0.00020091528282500804\n",
      "[6, 40] loss: 0.00028049937868490816\n",
      "[6, 60] loss: 0.0002077477965503931\n",
      "[6, 80] loss: 0.00019701345195062458\n",
      "[6, 100] loss: 0.0002003647411474958\n",
      "[6, 120] loss: 0.00022767498693428934\n",
      "[6, 140] loss: 0.00025347297079861167\n",
      "[6, 160] loss: 0.00025954550225287674\n",
      "[6, 180] loss: 0.00021075190044939518\n",
      "[6, 200] loss: 0.00020669777295552195\n",
      "[6, 220] loss: 0.0001877392027527094\n",
      "[6, 240] loss: 0.00022677270765416324\n",
      "[6, 260] loss: 0.00020555677521042525\n",
      "[6, 280] loss: 0.00024198324652388692\n",
      "[6, 300] loss: 0.00023792818561196326\n",
      "[7, 20] loss: 0.00019241136545315385\n",
      "[7, 40] loss: 0.0002641183566302061\n",
      "[7, 60] loss: 0.0001987452593166381\n",
      "[7, 80] loss: 0.00020694312918931245\n",
      "[7, 100] loss: 0.0001859027831815183\n",
      "[7, 120] loss: 0.00018564385478384794\n",
      "[7, 140] loss: 0.00020757193281315266\n",
      "[7, 160] loss: 0.00021383664989843963\n",
      "[7, 180] loss: 0.00019322639936581254\n",
      "[7, 200] loss: 0.00024000767339020968\n",
      "[7, 220] loss: 0.00023537661740556358\n",
      "[7, 240] loss: 0.00026647653500549496\n",
      "[7, 260] loss: 0.00019795082998462022\n",
      "[7, 280] loss: 0.00024680099333636464\n",
      "[7, 300] loss: 0.0002734454530291259\n",
      "[8, 20] loss: 0.0002262668057810515\n",
      "[8, 40] loss: 0.00020117541053332389\n",
      "[8, 60] loss: 0.0001942092222161591\n",
      "[8, 80] loss: 0.00018656687601469458\n",
      "[8, 100] loss: 0.00017668063449673355\n",
      "[8, 120] loss: 0.00019008451560512186\n",
      "[8, 140] loss: 0.0002712631232570857\n",
      "[8, 160] loss: 0.0002612450239248574\n",
      "[8, 180] loss: 0.00024124102760106326\n",
      "[8, 200] loss: 0.00020608004066161812\n",
      "[8, 220] loss: 0.00019912167219445108\n",
      "[8, 240] loss: 0.00023455865774303674\n",
      "[8, 260] loss: 0.00023123938892968\n",
      "[8, 280] loss: 0.00019043450546450913\n",
      "[8, 300] loss: 0.0001999737462028861\n",
      "[9, 20] loss: 0.0002293309976812452\n",
      "[9, 40] loss: 0.00022090309718623757\n",
      "[9, 60] loss: 0.0002081881701014936\n",
      "[9, 80] loss: 0.00019174776505678892\n",
      "[9, 100] loss: 0.0002268820651806891\n",
      "[9, 120] loss: 0.00023657128866761922\n",
      "[9, 140] loss: 0.00016302396939136087\n",
      "[9, 160] loss: 0.00023570894426666201\n",
      "[9, 180] loss: 0.00016445695329457522\n",
      "[9, 200] loss: 0.00021955715073272586\n",
      "[9, 220] loss: 0.00024040428688749672\n",
      "[9, 240] loss: 0.00024863928102422504\n",
      "[9, 260] loss: 0.00020847919466905295\n",
      "[9, 280] loss: 0.00024758609698619696\n",
      "[9, 300] loss: 0.00022415148699656128\n",
      "[10, 20] loss: 0.00022196585219353437\n",
      "[10, 40] loss: 0.0002265403976198286\n",
      "[10, 60] loss: 0.00026030770456418395\n",
      "[10, 80] loss: 0.00018256585905328392\n",
      "[10, 100] loss: 0.0002553146150894463\n",
      "[10, 120] loss: 0.0001622318709269166\n",
      "[10, 140] loss: 0.00021059265872463585\n",
      "[10, 160] loss: 0.0001783620927017182\n",
      "[10, 180] loss: 0.00020285602821968495\n",
      "[10, 200] loss: 0.00020206250995397567\n",
      "[10, 220] loss: 0.0002081033531576395\n",
      "[10, 240] loss: 0.00023139544459991156\n",
      "[10, 260] loss: 0.00018146709515713154\n",
      "[10, 280] loss: 0.00020822022715583443\n",
      "[10, 300] loss: 0.00017762244888581337\n",
      "[11, 20] loss: 0.00015631029917858542\n",
      "[11, 40] loss: 0.00016880379244685174\n",
      "[11, 60] loss: 0.00021889543905854225\n",
      "[11, 80] loss: 0.00017168904072605072\n",
      "[11, 100] loss: 0.00017453026259317995\n",
      "[11, 120] loss: 0.0002147634708089754\n",
      "[11, 140] loss: 0.0002000424494035542\n",
      "[11, 160] loss: 0.0002129720866214484\n",
      "[11, 180] loss: 0.00021830970724113285\n",
      "[11, 200] loss: 0.00017542646592482925\n",
      "[11, 220] loss: 0.00027866755751892926\n",
      "[11, 240] loss: 0.0002239834819920361\n",
      "[11, 260] loss: 0.00023247019480913877\n",
      "[11, 280] loss: 0.0002372888431418687\n",
      "[11, 300] loss: 0.00020197226293385028\n",
      "[12, 20] loss: 0.000233523175586015\n",
      "[12, 40] loss: 0.00019656644226051867\n",
      "[12, 60] loss: 0.00019628519052639605\n",
      "[12, 80] loss: 0.0001997349529992789\n",
      "[12, 100] loss: 0.00021082725981250405\n",
      "[12, 120] loss: 0.0002571382324676961\n",
      "[12, 140] loss: 0.00017745721293613314\n",
      "[12, 160] loss: 0.0002081662081182003\n",
      "[12, 180] loss: 0.00013070297287777065\n",
      "[12, 200] loss: 0.00019601117423735559\n",
      "[12, 220] loss: 0.00024614188959822057\n",
      "[12, 240] loss: 0.00021671352500561623\n",
      "[12, 260] loss: 0.00020828135148622095\n",
      "[12, 280] loss: 0.00021377028664574027\n",
      "[12, 300] loss: 0.0002485201717354357\n",
      "[13, 20] loss: 0.0002162022367119789\n",
      "[13, 40] loss: 0.00016184297297149896\n",
      "[13, 60] loss: 0.0002483966767322272\n",
      "[13, 80] loss: 0.00021067101880908014\n",
      "[13, 100] loss: 0.0002741458797827363\n",
      "[13, 120] loss: 0.0002009891807101667\n",
      "[13, 140] loss: 0.0001586338970810175\n",
      "[13, 160] loss: 0.00017535939277149736\n",
      "[13, 180] loss: 0.00015818788786418737\n",
      "[13, 200] loss: 0.00018343467742670328\n",
      "[13, 220] loss: 0.00018769635818898677\n",
      "[13, 240] loss: 0.00024732498242519793\n",
      "[13, 260] loss: 0.0002007469132076949\n",
      "[13, 280] loss: 0.0002126142696943134\n",
      "[13, 300] loss: 0.00016862437967211008\n",
      "[14, 20] loss: 0.0002055825584102422\n",
      "[14, 40] loss: 0.0001897043230710551\n",
      "[14, 60] loss: 0.00020731755811721086\n",
      "[14, 80] loss: 0.00022478349332232027\n",
      "[14, 100] loss: 0.00014338971441611647\n",
      "[14, 120] loss: 0.00027429952984675765\n",
      "[14, 140] loss: 0.00015847004298120737\n",
      "[14, 160] loss: 0.00020872146310284734\n",
      "[14, 180] loss: 0.00018039556802250444\n",
      "[14, 200] loss: 0.00023529649525880813\n",
      "[14, 220] loss: 0.00020201786700636148\n",
      "[14, 240] loss: 0.00016579800564795732\n",
      "[14, 260] loss: 0.0001678550965152681\n",
      "[14, 280] loss: 0.00015358724212273956\n",
      "[14, 300] loss: 0.00016849016700871288\n",
      "[15, 20] loss: 0.00016066302778199314\n",
      "[15, 40] loss: 0.00020707129966467618\n",
      "[15, 60] loss: 0.00015371517185121776\n",
      "[15, 80] loss: 0.00019840719504281878\n",
      "[15, 100] loss: 0.00018709094543009996\n",
      "[15, 120] loss: 0.00019626184832304715\n",
      "[15, 140] loss: 0.0001714547403389588\n",
      "[15, 160] loss: 0.0001653390689752996\n",
      "[15, 180] loss: 0.0002657508440315723\n",
      "[15, 200] loss: 0.00028088893042877317\n",
      "[15, 220] loss: 0.00016041086544282734\n",
      "[15, 240] loss: 0.0001899401576956734\n",
      "[15, 260] loss: 0.00018945502815768123\n",
      "[15, 280] loss: 0.00019261850416660308\n",
      "[15, 300] loss: 0.00015832813689485193\n",
      "[16, 20] loss: 0.0002224792931228876\n",
      "[16, 40] loss: 0.00018943249434232712\n",
      "[16, 60] loss: 0.00023434475407702849\n",
      "[16, 80] loss: 0.0001865520137362182\n",
      "[16, 100] loss: 0.0001697872169315815\n",
      "[16, 120] loss: 0.00016948019387200475\n",
      "[16, 140] loss: 0.00017725239787250757\n",
      "[16, 160] loss: 0.0001745076640509069\n",
      "[16, 180] loss: 0.00014030313421972096\n",
      "[16, 200] loss: 0.00015590719727333636\n",
      "[16, 220] loss: 0.00022173248045146465\n",
      "[16, 240] loss: 0.000181933818385005\n",
      "[16, 260] loss: 0.000237743200850673\n",
      "[16, 280] loss: 0.0002499364805407822\n",
      "[16, 300] loss: 0.00018305269931443035\n",
      "[17, 20] loss: 0.00017539133632089944\n",
      "[17, 40] loss: 0.00017186839040368796\n",
      "[17, 60] loss: 0.00017357238149270416\n",
      "[17, 80] loss: 0.00022686283732764422\n",
      "[17, 100] loss: 0.00016056654625572263\n",
      "[17, 120] loss: 0.0002189210585784167\n",
      "[17, 140] loss: 0.00023320182226598262\n",
      "[17, 160] loss: 0.00018801237642765046\n",
      "[17, 180] loss: 0.00017705688765272498\n",
      "[17, 200] loss: 0.00023949855333194137\n",
      "[17, 220] loss: 0.00019223415781743824\n",
      "[17, 240] loss: 0.00019759421353228392\n",
      "[17, 260] loss: 0.0002488759458065033\n",
      "[17, 280] loss: 0.00018849256238900124\n",
      "[17, 300] loss: 0.0001685756507795304\n",
      "[18, 20] loss: 0.00020692759822122752\n",
      "[18, 40] loss: 0.00019774151779711245\n",
      "[18, 60] loss: 0.00019339855923317372\n",
      "[18, 80] loss: 0.00013358466583304106\n",
      "[18, 100] loss: 0.00014285467716399581\n",
      "[18, 120] loss: 0.00016492046474013476\n",
      "[18, 140] loss: 0.00019967188988812267\n",
      "[18, 160] loss: 0.00018180462648160757\n",
      "[18, 180] loss: 0.00015730491583235563\n",
      "[18, 200] loss: 0.00022095102025195955\n",
      "[18, 220] loss: 0.00023487381869927049\n",
      "[18, 240] loss: 0.00019340795278549196\n",
      "[18, 260] loss: 0.0002046887062024325\n",
      "[18, 280] loss: 0.0001834755358286202\n",
      "[18, 300] loss: 0.00023670662543736397\n",
      "[19, 20] loss: 0.00017086467705667018\n",
      "[19, 40] loss: 0.0002154604522511363\n",
      "[19, 60] loss: 0.0001321878528688103\n",
      "[19, 80] loss: 0.0001566173145547509\n",
      "[19, 100] loss: 0.00024261238449253141\n",
      "[19, 120] loss: 0.0001791354299057275\n",
      "[19, 140] loss: 0.00018776330491527914\n",
      "[19, 160] loss: 0.00016052057221531868\n",
      "[19, 180] loss: 0.00019107550370972603\n",
      "[19, 200] loss: 0.0001605492194648832\n",
      "[19, 220] loss: 0.00017550183786079287\n",
      "[19, 240] loss: 0.00017001551296561956\n",
      "[19, 260] loss: 0.00017927737417630852\n",
      "[19, 280] loss: 0.00014907150249928236\n",
      "[19, 300] loss: 0.0002041432592086494\n",
      "[20, 20] loss: 0.00015025451662950217\n",
      "[20, 40] loss: 0.00016894397512078285\n",
      "[20, 60] loss: 0.00016443230584263803\n",
      "[20, 80] loss: 0.00016872068005613982\n",
      "[20, 100] loss: 0.00020637594675645233\n",
      "[20, 120] loss: 0.00020923772640526296\n",
      "[20, 140] loss: 0.0002475104455370456\n",
      "[20, 160] loss: 0.00017538580344989897\n",
      "[20, 180] loss: 0.0001634944381657988\n",
      "[20, 200] loss: 0.00015630871523171662\n",
      "[20, 220] loss: 0.00019559481355827302\n",
      "[20, 240] loss: 0.00018286380940116942\n",
      "[20, 260] loss: 0.00017344521870836616\n",
      "[20, 280] loss: 0.0001569041444454342\n",
      "[20, 300] loss: 0.00014646380278281868\n",
      "Finished Reraining\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 24, 24]             156\n",
      "         MaxPool2d-2            [-1, 6, 12, 12]               0\n",
      "            Conv2d-3             [-1, 16, 8, 8]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 4, 4]               0\n",
      "            Linear-5                  [-1, 150]          38,550\n",
      "            Linear-6                   [-1, 50]           7,550\n",
      "            Linear-7                   [-1, 10]             510\n",
      "================================================================\n",
      "Total params: 49,182\n",
      "Trainable params: 49,182\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 0.19\n",
      "Estimated Total Size (MB): 0.23\n",
      "----------------------------------------------------------------\n",
      "Accuracy of the network on the test images: 98.740000 %\n"
     ]
    }
   ],
   "source": [
    "len_1=150\n",
    "len_2=50\n",
    "\n",
    "print(\"Pruning fc1.................\")\n",
    "\n",
    "nodes=defaultdict(list)\n",
    "for j in range(len(net.state_dict()[\"fc1.weight\"])):  #Means j is a node of next layer, L2. Fc1 is connecting L1 and L2 layer.\n",
    "    nodes[j]=net.state_dict()[\"fc1.weight\"][j]\n",
    "\n",
    "# print(len(nodes), \" \", len(nodes[0]))\n",
    "\n",
    "# from math import sqrt\n",
    "distances=[]\n",
    "for i in nodes.keys():\n",
    "    for j in nodes.keys():\n",
    "        if(i!=j and j>i):\n",
    "            distances.append(euclidean_distance(nodes[i], nodes[j]))\n",
    "\n",
    "distances.sort()\n",
    "            \n",
    "print(\"Finding clusters of nodes.................\")\n",
    "setpoints=findsets(len_1, nodes, distances)\n",
    "\n",
    "# print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "temp_weights=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(net.state_dict()[\"fc1.weight\"][0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=net.state_dict()[\"fc1.weight\"][points]\n",
    "    row=row/len(setpoints[key])\n",
    "    temp_weights.append(row)\n",
    "# print(len(temp_weights), temp_weights[0].shape)\n",
    "\n",
    "# print(net.state_dict()[\"fc1.bias\"].shape)\n",
    "temp_bias=torch.zeros(len(temp_weights), dtype=torch.float)\n",
    "i=0\n",
    "for key in setpoints.keys():\n",
    "    for points in setpoints[key]:\n",
    "        temp_bias[i]+=net.state_dict()[\"fc1.bias\"][points]\n",
    "    temp_bias[i]/=len(setpoints[key])\n",
    "    i+=1\n",
    "# print(temp_bias.shape)\n",
    "\n",
    "print(\"Updating fc1.................\")\n",
    "net_1 = changenet(net, \"fc1\", temp_weights, temp_bias)\n",
    "\n",
    "print(net.state_dict()[\"fc1.bias\"].shape, \" -> \", net_1.state_dict()[\"fc1.bias\"].shape)\n",
    "print(net.state_dict()[\"fc1.weight\"].shape, \" -> \", net_1.state_dict()[\"fc1.weight\"].shape)\n",
    "\n",
    "net=copy.deepcopy(net_1)\n",
    "# print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "# print(net.state_dict()[\"fc1.bias\"].shape)\n",
    "\n",
    "#just to check if the copy has been done correctly\n",
    "# print(temp_weights[0],\"\\n\\n\",net.state_dict()[\"fc1.weight\"][0])    \n",
    "\n",
    "\n",
    "### Now, we have to change FC2 accordingly:\n",
    "# print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "print(\"Adjusting fc2 accordingly.................\")\n",
    "mat=net.state_dict()[\"fc2.weight\"].t()\n",
    "# print(mat.shape)\n",
    "\n",
    "temp_weight=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(mat[0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=mat[points]\n",
    "    temp_weight.append(row)\n",
    "# print(len(temp_weight), temp_weight[0].shape)\n",
    "\n",
    "newmat=torch.stack(temp_weight, dim=0)\n",
    "newmat=newmat.t()\n",
    "# print(newmat.shape)\n",
    "\n",
    "# print(net.state_dict()[\"fc2.bias\"].shape)\n",
    "\n",
    "net_2 = changenet(net, \"fc2\", newmat, net.state_dict()[\"fc2.bias\"])\n",
    "net=copy.deepcopy(net_2)\n",
    "\n",
    "print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "print(net.state_dict()[\"fc3.weight\"].shape)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, len(net.state_dict()[\"fc1.weight\"]))\n",
    "        self.fc2 = nn.Linear(len(net.state_dict()[\"fc2.weight\"][0]), len(net.state_dict()[\"fc2.weight\"]))\n",
    "        self.fc3 = nn.Linear(len(net.state_dict()[\"fc3.weight\"][0]), 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    \n",
    "from torchsummary import summary\n",
    "device=torch.device(\"cpu\")\n",
    "model=Net().to(device)\n",
    "summary(model, input_size=(1, 28, 28), device=\"cpu\")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "\n",
    "print(\"Pruning fc2.................\")\n",
    "from collections import defaultdict\n",
    "nodes=defaultdict(list)\n",
    "for j in range(len(net.state_dict()[\"fc2.weight\"])):  #Means j is a node of next layer, L2.\n",
    "    nodes[j]=net.state_dict()[\"fc2.weight\"][j]\n",
    "\n",
    "# print(len(nodes), \" \", len(nodes[0]))\n",
    "\n",
    "\n",
    "distances=[]\n",
    "for i in nodes.keys():\n",
    "    for j in nodes.keys():\n",
    "        if(i!=j and j>i):\n",
    "            distances.append(euclidean_distance(nodes[i], nodes[j]))\n",
    "            \n",
    "distances.sort()\n",
    "# print(len(distances))\n",
    "\n",
    "print(\"Finding clusters of nodes.................\")\n",
    "setpoints=findsets(len_2, nodes, distances)\n",
    "\n",
    "# print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "temp_weight=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(net.state_dict()[\"fc2.weight\"][0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=net.state_dict()[\"fc2.weight\"][points]\n",
    "    row=row/len(setpoints[key])\n",
    "    temp_weight.append(row)\n",
    "# print(len(temp_weight), temp_weight[0].shape)\n",
    "\n",
    "# print(net.state_dict()[\"fc2.bias\"].shape)\n",
    "temp_bias=torch.zeros(len(temp_weight), dtype=torch.float)\n",
    "i=0\n",
    "for key in setpoints.keys():\n",
    "    for points in setpoints[key]:\n",
    "        temp_bias[i]+=net.state_dict()[\"fc2.bias\"][points]\n",
    "    temp_bias[i]/=len(setpoints[key])\n",
    "    i+=1\n",
    "# print(temp_bias.shape)\n",
    "\n",
    "print(\"Updating fc2.................\")\n",
    "net_3 = changenet(net, \"fc2\", temp_weight, temp_bias)\n",
    "net=copy.deepcopy(net_3)\n",
    "\n",
    "mat=net.state_dict()[\"fc3.weight\"].t()\n",
    "# print(mat.shape)\n",
    "\n",
    "temp_weight=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(mat[0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=mat[points]\n",
    "    temp_weight.append(row)\n",
    "# print(len(temp_weight), temp_weight[0].shape)\n",
    "\n",
    "newmat=torch.stack(temp_weight, dim=0)\n",
    "newmat=newmat.t()\n",
    "# print(newmat.shape)\n",
    "\n",
    "print(\"Adjusting fc3 accordingly.................\")\n",
    "net_4 = changenet(net, \"fc3\", newmat, net.state_dict()[\"fc3.bias\"])\n",
    "net=copy.deepcopy(net_4)\n",
    "\n",
    "print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "print(net.state_dict()[\"fc3.weight\"].shape)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, len(net.state_dict()[\"fc1.weight\"]))\n",
    "        self.fc2 = nn.Linear(len(net.state_dict()[\"fc2.weight\"][0]), len(net.state_dict()[\"fc2.weight\"]))\n",
    "        self.fc3 = nn.Linear(len(net.state_dict()[\"fc3.weight\"][0]), 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "i=0\n",
    "for parameter in net.parameters():\n",
    "    i+=1\n",
    "    if(i<5):\n",
    "        parameter.requires_grad=False\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.1307,), (0.3081,))])\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=200,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=200,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('0', '1', '2', '3',\n",
    "           '4', '5', '6', '7', '8', '9')\n",
    "\n",
    "# import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        # print(inputs.shape)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    # print every 2000 mini-batches\n",
    "            print(\"[{}, {}] loss: {}\".format\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Reraining')\n",
    "\n",
    "\n",
    "from torchsummary import summary\n",
    "device=torch.device(\"cpu\")\n",
    "model=Net().to(device)\n",
    "summary(model, input_size=(1, 28, 28), device=\"cpu\")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"LeNET_150_50_MNIST_Model_My_Exiperiment_4_Fine_Tuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning fc1.................\n",
      "Finding clusters of nodes.................\n",
      "desired len= 120\n",
      "cut_off= 0.9369274934462453\n",
      "iteration= 1  length= 1  difference= -119  change rate= 0.0009369274934462453\n",
      "cut_off= 0.825433121726142\n",
      "iteration= 2  length= 1  difference= -119  change rate= 0.0009369274934462453\n",
      "cut_off= 0.7139387500060388\n",
      "iteration= 3  length= 26  difference= -94  change rate= 0.0009369274934462453\n",
      "cut_off= 0.6258675656220918\n",
      "iteration= 4  length= 142  difference= 22  change rate= 0.0009369274934462453\n",
      "cut_off= 0.6464799704779092\n",
      "iteration= 5  length= 121  difference= 1  change rate= 0.0009369274934462453\n",
      "cut_off= 0.6474168979713554\n",
      "iteration= 6  length= 119  difference= -1  change rate= 0.0008432347441016208\n",
      "cut_off= 0.6465736632272537\n",
      "iteration= 7  length= 121  difference= 1  change rate= 0.0007589112696914588\n",
      "cut_off= 0.6473325744969451\n",
      "iteration= 8  length= 119  difference= -1  change rate= 0.0006830201427223129\n",
      "cut_off= 0.6466495543542228\n",
      "iteration= 9  length= 120  difference= -1  change rate= 0.0006830201427223129\n",
      "Updating fc1.................\n",
      "torch.Size([150])  ->  torch.Size([120])\n",
      "torch.Size([150, 256])  ->  torch.Size([120, 256])\n",
      "Adjusting fc2 accordingly.................\n",
      "torch.Size([120, 256])\n",
      "torch.Size([50, 120])\n",
      "torch.Size([10, 50])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 24, 24]             156\n",
      "         MaxPool2d-2            [-1, 6, 12, 12]               0\n",
      "            Conv2d-3             [-1, 16, 8, 8]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 4, 4]               0\n",
      "            Linear-5                  [-1, 120]          30,840\n",
      "            Linear-6                   [-1, 50]           6,050\n",
      "            Linear-7                   [-1, 10]             510\n",
      "================================================================\n",
      "Total params: 39,972\n",
      "Trainable params: 39,972\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 0.15\n",
      "Estimated Total Size (MB): 0.20\n",
      "----------------------------------------------------------------\n",
      "Accuracy of the network on the test images: 98.020000 %\n",
      "Pruning fc2.................\n",
      "Finding clusters of nodes.................\n",
      "desired len= 40\n",
      "cut_off= 0.9051962349408377\n",
      "iteration= 1  length= 7  difference= -33  change rate= 0.0009051962349408377\n",
      "cut_off= 0.8753247591877901\n",
      "iteration= 2  length= 7  difference= -33  change rate= 0.0009051962349408377\n",
      "cut_off= 0.8454532834347425\n",
      "iteration= 3  length= 7  difference= -33  change rate= 0.0009051962349408377\n",
      "cut_off= 0.8155818076816949\n",
      "iteration= 4  length= 9  difference= -31  change rate= 0.0009051962349408377\n",
      "cut_off= 0.7875207243985289\n",
      "iteration= 5  length= 12  difference= -28  change rate= 0.0009051962349408377\n",
      "cut_off= 0.7621752298201855\n",
      "iteration= 6  length= 14  difference= -26  change rate= 0.0009051962349408377\n",
      "cut_off= 0.7386401277117237\n",
      "iteration= 7  length= 18  difference= -22  change rate= 0.0009051962349408377\n",
      "cut_off= 0.7187258105430253\n",
      "iteration= 8  length= 20  difference= -20  change rate= 0.0009051962349408377\n",
      "cut_off= 0.7006218858442086\n",
      "iteration= 9  length= 23  difference= -17  change rate= 0.0009051962349408377\n",
      "cut_off= 0.6852335498502143\n",
      "iteration= 10  length= 27  difference= -13  change rate= 0.0009051962349408377\n",
      "cut_off= 0.6734659987959835\n",
      "iteration= 11  length= 29  difference= -11  change rate= 0.0009051962349408377\n",
      "cut_off= 0.6635088402116343\n",
      "iteration= 12  length= 29  difference= -11  change rate= 0.0009051962349408377\n",
      "cut_off= 0.653551681627285\n",
      "iteration= 13  length= 34  difference= -6  change rate= 0.0009051962349408377\n",
      "cut_off= 0.64812050421764\n",
      "iteration= 14  length= 35  difference= -5  change rate= 0.0009051962349408377\n",
      "cut_off= 0.6435945230429359\n",
      "iteration= 15  length= 35  difference= -5  change rate= 0.0009051962349408377\n",
      "cut_off= 0.6390685418682317\n",
      "iteration= 16  length= 38  difference= -2  change rate= 0.0009051962349408377\n",
      "cut_off= 0.63725814939835\n",
      "iteration= 17  length= 38  difference= -2  change rate= 0.0009051962349408377\n",
      "cut_off= 0.6354477569284683\n",
      "iteration= 18  length= 39  difference= -1  change rate= 0.0009051962349408377\n",
      "cut_off= 0.6345425606935275\n",
      "iteration= 19  length= 40  difference= -1  change rate= 0.0009051962349408377\n",
      "Updating fc2.................\n",
      "Adjusting fc3 accordingly.................\n",
      "torch.Size([120, 256])\n",
      "torch.Size([40, 120])\n",
      "torch.Size([10, 40])\n",
      "Accuracy of the network on the test images: 97.030000 %\n",
      "[1, 20] loss: 0.0004241609079763293\n",
      "[1, 40] loss: 0.00029228189634159207\n",
      "[1, 60] loss: 0.0003658662810921669\n",
      "[1, 80] loss: 0.0003008095961995423\n",
      "[1, 100] loss: 0.0003166222060099244\n",
      "[1, 120] loss: 0.0002672666893340647\n",
      "[1, 140] loss: 0.0002896302747540176\n",
      "[1, 160] loss: 0.00031463915202766657\n",
      "[1, 180] loss: 0.00024968133540824054\n",
      "[1, 200] loss: 0.00029377389140427114\n",
      "[1, 220] loss: 0.0003631358393467963\n",
      "[1, 240] loss: 0.00028066363744437697\n",
      "[1, 260] loss: 0.00028015523171052336\n",
      "[1, 280] loss: 0.0003090417585335672\n",
      "[1, 300] loss: 0.00021133800642564893\n",
      "[2, 20] loss: 0.0002279939758591354\n",
      "[2, 40] loss: 0.00021496215416118503\n",
      "[2, 60] loss: 0.00020793269528076054\n",
      "[2, 80] loss: 0.00025499875098466875\n",
      "[2, 100] loss: 0.000248826427385211\n",
      "[2, 120] loss: 0.0002969954772852361\n",
      "[2, 140] loss: 0.00019827543012797833\n",
      "[2, 160] loss: 0.0002741421144455671\n",
      "[2, 180] loss: 0.00028053261665627363\n",
      "[2, 200] loss: 0.00025161355314776303\n",
      "[2, 220] loss: 0.0002772280068602413\n",
      "[2, 240] loss: 0.0002725604057777673\n",
      "[2, 260] loss: 0.00021430676663294435\n",
      "[2, 280] loss: 0.00020334283681586386\n",
      "[2, 300] loss: 0.0002818010374903679\n",
      "[3, 20] loss: 0.0002497248100116849\n",
      "[3, 40] loss: 0.00025796028529293837\n",
      "[3, 60] loss: 0.00026740991696715355\n",
      "[3, 80] loss: 0.000195681759621948\n",
      "[3, 100] loss: 0.00021861510910093783\n",
      "[3, 120] loss: 0.0002454637475311756\n",
      "[3, 140] loss: 0.00027207745146006347\n",
      "[3, 160] loss: 0.00023140480346046387\n",
      "[3, 180] loss: 0.0002531417151913047\n",
      "[3, 200] loss: 0.0002057065344415605\n",
      "[3, 220] loss: 0.00020668437378481032\n",
      "[3, 240] loss: 0.00029458600142970683\n",
      "[3, 260] loss: 0.00024667986179701984\n",
      "[3, 280] loss: 0.00023870350420475005\n",
      "[3, 300] loss: 0.0002024682625196874\n",
      "[4, 20] loss: 0.00018284693895839155\n",
      "[4, 40] loss: 0.00023077810159884393\n",
      "[4, 60] loss: 0.00021731945755891502\n",
      "[4, 80] loss: 0.0002196401390247047\n",
      "[4, 100] loss: 0.00020236808178015052\n",
      "[4, 120] loss: 0.00025639652600511906\n",
      "[4, 140] loss: 0.0002144685504026711\n",
      "[4, 160] loss: 0.0002506831930950284\n",
      "[4, 180] loss: 0.0002529357229359448\n",
      "[4, 200] loss: 0.00025786618911661206\n",
      "[4, 220] loss: 0.00023977559106424452\n",
      "[4, 240] loss: 0.00021724834211636336\n",
      "[4, 260] loss: 0.00019467203575186431\n",
      "[4, 280] loss: 0.00019320031674578786\n",
      "[4, 300] loss: 0.0002923123536165804\n",
      "[5, 20] loss: 0.0002582771596498787\n",
      "[5, 40] loss: 0.00021549915778450667\n",
      "[5, 60] loss: 0.00024244293966330587\n",
      "[5, 80] loss: 0.00020730954594910144\n",
      "[5, 100] loss: 0.00018858801247552038\n",
      "[5, 120] loss: 0.00021581767313182354\n",
      "[5, 140] loss: 0.00019344347203150393\n",
      "[5, 160] loss: 0.0002661807965487242\n",
      "[5, 180] loss: 0.00022791083296760917\n",
      "[5, 200] loss: 0.0002574633585754782\n",
      "[5, 220] loss: 0.00023326454358175397\n",
      "[5, 240] loss: 0.00024116287333890795\n",
      "[5, 260] loss: 0.00022497219266369938\n",
      "[5, 280] loss: 0.00023665526858530938\n",
      "[5, 300] loss: 0.0002140343338251114\n",
      "[6, 20] loss: 0.00017694470402784644\n",
      "[6, 40] loss: 0.00018950707418844104\n",
      "[6, 60] loss: 0.00026966976723633707\n",
      "[6, 80] loss: 0.00023862360091879965\n",
      "[6, 100] loss: 0.000202395208645612\n",
      "[6, 120] loss: 0.00022806655615568162\n",
      "[6, 140] loss: 0.00020638157357461752\n",
      "[6, 160] loss: 0.00021917927218601107\n",
      "[6, 180] loss: 0.00021230669948272407\n",
      "[6, 200] loss: 0.00021210561413317918\n",
      "[6, 220] loss: 0.00019501222530379892\n",
      "[6, 240] loss: 0.00017451380635611713\n",
      "[6, 260] loss: 0.00021285141143016518\n",
      "[6, 280] loss: 0.00024825226701796055\n",
      "[6, 300] loss: 0.00023707881662994622\n",
      "[7, 20] loss: 0.0001707366406917572\n",
      "[7, 40] loss: 0.00021536190109327437\n",
      "[7, 60] loss: 0.00020492538646794855\n",
      "[7, 80] loss: 0.00022438726457767188\n",
      "[7, 100] loss: 0.00019377410924062134\n",
      "[7, 120] loss: 0.00024226733995601535\n",
      "[7, 140] loss: 0.00020412970008328558\n",
      "[7, 160] loss: 0.00018214913527481259\n",
      "[7, 180] loss: 0.0002761832308024168\n",
      "[7, 200] loss: 0.0002179524414241314\n",
      "[7, 220] loss: 0.0002500657890923321\n",
      "[7, 240] loss: 0.00019529115152545275\n",
      "[7, 260] loss: 0.00019621246098540723\n",
      "[7, 280] loss: 0.0001705889729782939\n",
      "[7, 300] loss: 0.00020695536874700338\n",
      "[8, 20] loss: 0.00016035487060435117\n",
      "[8, 40] loss: 0.00016659400938078762\n",
      "[8, 60] loss: 0.0001718463278375566\n",
      "[8, 80] loss: 0.000205837138928473\n",
      "[8, 100] loss: 0.00021583842730615288\n",
      "[8, 120] loss: 0.00023071610741317274\n",
      "[8, 140] loss: 0.00021362758055329322\n",
      "[8, 160] loss: 0.00019089686032384634\n",
      "[8, 180] loss: 0.0002011137583758682\n",
      "[8, 200] loss: 0.00019900843081995846\n",
      "[8, 220] loss: 0.00020032558729872108\n",
      "[8, 240] loss: 0.000188408097717911\n",
      "[8, 260] loss: 0.00028241268219426273\n",
      "[8, 280] loss: 0.00020938460319302977\n",
      "[8, 300] loss: 0.00021401729295030236\n",
      "[9, 20] loss: 0.00024292523553594948\n",
      "[9, 40] loss: 0.00016804858646355568\n",
      "[9, 60] loss: 0.0002587828179821372\n",
      "[9, 80] loss: 0.00019144631922245027\n",
      "[9, 100] loss: 0.00020546907582320273\n",
      "[9, 120] loss: 0.00016380706802010536\n",
      "[9, 140] loss: 0.00021035912446677686\n",
      "[9, 160] loss: 0.0001824422572972253\n",
      "[9, 180] loss: 0.00019994749641045928\n",
      "[9, 200] loss: 0.00019877790240570902\n",
      "[9, 220] loss: 0.00021355163375847043\n",
      "[9, 240] loss: 0.00019199587032198907\n",
      "[9, 260] loss: 0.0001867440529167652\n",
      "[9, 280] loss: 0.000197306212852709\n",
      "[9, 300] loss: 0.0002145894025452435\n",
      "[10, 20] loss: 0.00018649094412103297\n",
      "[10, 40] loss: 0.00017786598578095435\n",
      "[10, 60] loss: 0.00016975369630381465\n",
      "[10, 80] loss: 0.00017947943462058902\n",
      "[10, 100] loss: 0.0002694112928584218\n",
      "[10, 120] loss: 0.00016047969833016395\n",
      "[10, 140] loss: 0.000249818867770955\n",
      "[10, 160] loss: 0.00018116392323281615\n",
      "[10, 180] loss: 0.0002072456870228052\n",
      "[10, 200] loss: 0.00020678567443974317\n",
      "[10, 220] loss: 0.0001645591767737642\n",
      "[10, 240] loss: 0.0001921723836567253\n",
      "[10, 260] loss: 0.0001652675187215209\n",
      "[10, 280] loss: 0.0001637895037420094\n",
      "[10, 300] loss: 0.00021563004073686898\n",
      "[11, 20] loss: 0.00015931082400493323\n",
      "[11, 40] loss: 0.00017735369026195257\n",
      "[11, 60] loss: 0.00020287560555152595\n",
      "[11, 80] loss: 0.00017622517189010977\n",
      "[11, 100] loss: 0.0001753920700866729\n",
      "[11, 120] loss: 0.00018308753287419677\n",
      "[11, 140] loss: 0.00017565828515216707\n",
      "[11, 160] loss: 0.00021979742613621056\n",
      "[11, 180] loss: 0.00017307418072596192\n",
      "[11, 200] loss: 0.00026283532055094836\n",
      "[11, 220] loss: 0.0002088535916991532\n",
      "[11, 240] loss: 0.0001902648734394461\n",
      "[11, 260] loss: 0.00020676070591434836\n",
      "[11, 280] loss: 0.0001734110964462161\n",
      "[11, 300] loss: 0.0001741955978795886\n",
      "[12, 20] loss: 0.00014007170405238868\n",
      "[12, 40] loss: 0.00016652614809572696\n",
      "[12, 60] loss: 0.00018084530322812496\n",
      "[12, 80] loss: 0.00016499569127336144\n",
      "[12, 100] loss: 0.00015675715706311167\n",
      "[12, 120] loss: 0.00020449928008019924\n",
      "[12, 140] loss: 0.00021584273804910482\n",
      "[12, 160] loss: 0.00023477808851748706\n",
      "[12, 180] loss: 0.00021348556852899493\n",
      "[12, 200] loss: 0.00016770975245162845\n",
      "[12, 220] loss: 0.00017420527804642915\n",
      "[12, 240] loss: 0.0001617860528640449\n",
      "[12, 260] loss: 0.00025299943471327423\n",
      "[12, 280] loss: 0.00024275897489860654\n",
      "[12, 300] loss: 0.00020737126469612123\n",
      "[13, 20] loss: 0.00018763808230869473\n",
      "[13, 40] loss: 0.0001752310274168849\n",
      "[13, 60] loss: 0.00022956256405450403\n",
      "[13, 80] loss: 0.00016960660740733148\n",
      "[13, 100] loss: 0.00017857794067822398\n",
      "[13, 120] loss: 0.0001820506020449102\n",
      "[13, 140] loss: 0.00022952102799899876\n",
      "[13, 160] loss: 0.000150461514480412\n",
      "[13, 180] loss: 0.00018207248975522815\n",
      "[13, 200] loss: 0.00014694438292644918\n",
      "[13, 220] loss: 0.0001776928692124784\n",
      "[13, 240] loss: 0.00017473949468694628\n",
      "[13, 260] loss: 0.00017854881123639644\n",
      "[13, 280] loss: 0.000170727166114375\n",
      "[13, 300] loss: 0.00021183268819004297\n",
      "[14, 20] loss: 0.00016784434858709574\n",
      "[14, 40] loss: 0.0001491650315001607\n",
      "[14, 60] loss: 0.00019909848575480282\n",
      "[14, 80] loss: 0.0002247872995212674\n",
      "[14, 100] loss: 0.0001729334859410301\n",
      "[14, 120] loss: 0.0001770361640956253\n",
      "[14, 140] loss: 0.00019873636914417148\n",
      "[14, 160] loss: 0.00016950422525405885\n",
      "[14, 180] loss: 0.00020488891925197095\n",
      "[14, 200] loss: 0.0002223057015798986\n",
      "[14, 220] loss: 0.00023393864557147027\n",
      "[14, 240] loss: 0.00019281691825017333\n",
      "[14, 260] loss: 0.00021215019188821317\n",
      "[14, 280] loss: 0.00013776882027741522\n",
      "[14, 300] loss: 0.00016488362685777248\n",
      "[15, 20] loss: 0.00018842641939409077\n",
      "[15, 40] loss: 0.0001891081342473626\n",
      "[15, 60] loss: 0.0001850266414694488\n",
      "[15, 80] loss: 0.000264246774604544\n",
      "[15, 100] loss: 0.0001606467857491225\n",
      "[15, 120] loss: 0.00015317688998766244\n",
      "[15, 140] loss: 0.00014942046045325697\n",
      "[15, 160] loss: 0.00017113443557173014\n",
      "[15, 180] loss: 0.00016557716764509678\n",
      "[15, 200] loss: 0.00015490323898848147\n",
      "[15, 220] loss: 0.00014602163247764112\n",
      "[15, 240] loss: 0.00019612210360355674\n",
      "[15, 260] loss: 0.0001684280578047037\n",
      "[15, 280] loss: 0.00017729795956984162\n",
      "[15, 300] loss: 0.00018054992868565023\n",
      "[16, 20] loss: 0.00015614101360552013\n",
      "[16, 40] loss: 0.0001517060841433704\n",
      "[16, 60] loss: 0.00016541991638951005\n",
      "[16, 80] loss: 0.00015300721110543235\n",
      "[16, 100] loss: 0.00016642601415514945\n",
      "[16, 120] loss: 0.00015408884058706461\n",
      "[16, 140] loss: 0.00017446039314381777\n",
      "[16, 160] loss: 0.00021811125508975238\n",
      "[16, 180] loss: 0.0001645875390386209\n",
      "[16, 200] loss: 0.00018396244500763716\n",
      "[16, 220] loss: 0.00020362201798707248\n",
      "[16, 240] loss: 0.00015586706716567278\n",
      "[16, 260] loss: 0.00018805725232232362\n",
      "[16, 280] loss: 0.00018497500685043633\n",
      "[16, 300] loss: 0.00015216996404342353\n",
      "[17, 20] loss: 0.00016477820917498322\n",
      "[17, 40] loss: 0.00014786564325913786\n",
      "[17, 60] loss: 0.00015299771935679019\n",
      "[17, 80] loss: 0.0002027328348485753\n",
      "[17, 100] loss: 0.00014591395598836243\n",
      "[17, 120] loss: 0.0001599177459720522\n",
      "[17, 140] loss: 0.00022982988692820072\n",
      "[17, 160] loss: 0.000181418236810714\n",
      "[17, 180] loss: 0.00018227698118425905\n",
      "[17, 200] loss: 0.00019449095521122218\n",
      "[17, 220] loss: 0.00019949465501122176\n",
      "[17, 240] loss: 0.0001713582833763212\n",
      "[17, 260] loss: 0.0001890922870952636\n",
      "[17, 280] loss: 0.00014708429668098687\n",
      "[17, 300] loss: 0.00014636695967055858\n",
      "[18, 20] loss: 0.00015477961138822137\n",
      "[18, 40] loss: 0.00014190290949773042\n",
      "[18, 60] loss: 0.00014865535113494843\n",
      "[18, 80] loss: 0.00017959305760450661\n",
      "[18, 100] loss: 0.00017951202765107154\n",
      "[18, 120] loss: 0.0001856334109324962\n",
      "[18, 140] loss: 0.00015730918594636023\n",
      "[18, 160] loss: 0.00014316285005770623\n",
      "[18, 180] loss: 0.0001135670953663066\n",
      "[18, 200] loss: 0.00016531664482317865\n",
      "[18, 220] loss: 0.000189989808248356\n",
      "[18, 240] loss: 0.0001741356496931985\n",
      "[18, 260] loss: 0.0002298059978056699\n",
      "[18, 280] loss: 0.00021043351385742427\n",
      "[18, 300] loss: 0.0001670767576433718\n",
      "[19, 20] loss: 0.00023520618746988476\n",
      "[19, 40] loss: 0.00017867712967563421\n",
      "[19, 60] loss: 0.00015621495828963816\n",
      "[19, 80] loss: 0.00016483842104207723\n",
      "[19, 100] loss: 0.0001623682004865259\n",
      "[19, 120] loss: 0.00013862538221292198\n",
      "[19, 140] loss: 0.00015053812216501682\n",
      "[19, 160] loss: 0.00016356577700935303\n",
      "[19, 180] loss: 0.0002140148258768022\n",
      "[19, 200] loss: 0.0001739320047199726\n",
      "[19, 220] loss: 0.00017910084943287074\n",
      "[19, 240] loss: 0.00014687981514725833\n",
      "[19, 260] loss: 0.000181694399099797\n",
      "[19, 280] loss: 0.00016949797165580094\n",
      "[19, 300] loss: 0.0001813710641581565\n",
      "[20, 20] loss: 0.0002336388579569757\n",
      "[20, 40] loss: 0.00012834783527068794\n",
      "[20, 60] loss: 0.00015368970786221325\n",
      "[20, 80] loss: 0.00017868878552690148\n",
      "[20, 100] loss: 0.00020319464150816201\n",
      "[20, 120] loss: 0.00016112181171774864\n",
      "[20, 140] loss: 0.0002068089353851974\n",
      "[20, 160] loss: 0.00017689373064786194\n",
      "[20, 180] loss: 0.00017226738040335477\n",
      "[20, 200] loss: 0.00013929000846110283\n",
      "[20, 220] loss: 0.00012524417438544334\n",
      "[20, 240] loss: 0.00013022213988006116\n",
      "[20, 260] loss: 0.0001409491141093895\n",
      "[20, 280] loss: 0.000162245491752401\n",
      "[20, 300] loss: 0.00013958271907176821\n",
      "Finished Reraining\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 24, 24]             156\n",
      "         MaxPool2d-2            [-1, 6, 12, 12]               0\n",
      "            Conv2d-3             [-1, 16, 8, 8]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 4, 4]               0\n",
      "            Linear-5                  [-1, 120]          30,840\n",
      "            Linear-6                   [-1, 40]           4,840\n",
      "            Linear-7                   [-1, 10]             410\n",
      "================================================================\n",
      "Total params: 38,662\n",
      "Trainable params: 38,662\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 0.15\n",
      "Estimated Total Size (MB): 0.19\n",
      "----------------------------------------------------------------\n",
      "Accuracy of the network on the test images: 98.550000 %\n"
     ]
    }
   ],
   "source": [
    "len_1=120\n",
    "len_2=40\n",
    "\n",
    "print(\"Pruning fc1.................\")\n",
    "\n",
    "nodes=defaultdict(list)\n",
    "for j in range(len(net.state_dict()[\"fc1.weight\"])):  #Means j is a node of next layer, L2. Fc1 is connecting L1 and L2 layer.\n",
    "    nodes[j]=net.state_dict()[\"fc1.weight\"][j]\n",
    "\n",
    "# print(len(nodes), \" \", len(nodes[0]))\n",
    "\n",
    "# from math import sqrt\n",
    "distances=[]\n",
    "for i in nodes.keys():\n",
    "    for j in nodes.keys():\n",
    "        if(i!=j and j>i):\n",
    "            distances.append(euclidean_distance(nodes[i], nodes[j]))\n",
    "\n",
    "distances.sort()\n",
    "            \n",
    "print(\"Finding clusters of nodes.................\")\n",
    "setpoints=findsets(len_1, nodes, distances)\n",
    "\n",
    "# print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "temp_weights=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(net.state_dict()[\"fc1.weight\"][0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=net.state_dict()[\"fc1.weight\"][points]\n",
    "    row=row/len(setpoints[key])\n",
    "    temp_weights.append(row)\n",
    "# print(len(temp_weights), temp_weights[0].shape)\n",
    "\n",
    "# print(net.state_dict()[\"fc1.bias\"].shape)\n",
    "temp_bias=torch.zeros(len(temp_weights), dtype=torch.float)\n",
    "i=0\n",
    "for key in setpoints.keys():\n",
    "    for points in setpoints[key]:\n",
    "        temp_bias[i]+=net.state_dict()[\"fc1.bias\"][points]\n",
    "    temp_bias[i]/=len(setpoints[key])\n",
    "    i+=1\n",
    "# print(temp_bias.shape)\n",
    "\n",
    "print(\"Updating fc1.................\")\n",
    "net_1 = changenet(net, \"fc1\", temp_weights, temp_bias)\n",
    "\n",
    "print(net.state_dict()[\"fc1.bias\"].shape, \" -> \", net_1.state_dict()[\"fc1.bias\"].shape)\n",
    "print(net.state_dict()[\"fc1.weight\"].shape, \" -> \", net_1.state_dict()[\"fc1.weight\"].shape)\n",
    "\n",
    "net=copy.deepcopy(net_1)\n",
    "# print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "# print(net.state_dict()[\"fc1.bias\"].shape)\n",
    "\n",
    "#just to check if the copy has been done correctly\n",
    "# print(temp_weights[0],\"\\n\\n\",net.state_dict()[\"fc1.weight\"][0])    \n",
    "\n",
    "\n",
    "### Now, we have to change FC2 accordingly:\n",
    "# print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "print(\"Adjusting fc2 accordingly.................\")\n",
    "mat=net.state_dict()[\"fc2.weight\"].t()\n",
    "# print(mat.shape)\n",
    "\n",
    "temp_weight=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(mat[0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=mat[points]\n",
    "    temp_weight.append(row)\n",
    "# print(len(temp_weight), temp_weight[0].shape)\n",
    "\n",
    "newmat=torch.stack(temp_weight, dim=0)\n",
    "newmat=newmat.t()\n",
    "# print(newmat.shape)\n",
    "\n",
    "# print(net.state_dict()[\"fc2.bias\"].shape)\n",
    "\n",
    "net_2 = changenet(net, \"fc2\", newmat, net.state_dict()[\"fc2.bias\"])\n",
    "net=copy.deepcopy(net_2)\n",
    "\n",
    "print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "print(net.state_dict()[\"fc3.weight\"].shape)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, len(net.state_dict()[\"fc1.weight\"]))\n",
    "        self.fc2 = nn.Linear(len(net.state_dict()[\"fc2.weight\"][0]), len(net.state_dict()[\"fc2.weight\"]))\n",
    "        self.fc3 = nn.Linear(len(net.state_dict()[\"fc3.weight\"][0]), 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    \n",
    "from torchsummary import summary\n",
    "device=torch.device(\"cpu\")\n",
    "model=Net().to(device)\n",
    "summary(model, input_size=(1, 28, 28), device=\"cpu\")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "\n",
    "print(\"Pruning fc2.................\")\n",
    "from collections import defaultdict\n",
    "nodes=defaultdict(list)\n",
    "for j in range(len(net.state_dict()[\"fc2.weight\"])):  #Means j is a node of next layer, L2.\n",
    "    nodes[j]=net.state_dict()[\"fc2.weight\"][j]\n",
    "\n",
    "# print(len(nodes), \" \", len(nodes[0]))\n",
    "\n",
    "\n",
    "distances=[]\n",
    "for i in nodes.keys():\n",
    "    for j in nodes.keys():\n",
    "        if(i!=j and j>i):\n",
    "            distances.append(euclidean_distance(nodes[i], nodes[j]))\n",
    "            \n",
    "distances.sort()\n",
    "# print(len(distances))\n",
    "\n",
    "print(\"Finding clusters of nodes.................\")\n",
    "setpoints=findsets(len_2, nodes, distances)\n",
    "\n",
    "# print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "temp_weight=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(net.state_dict()[\"fc2.weight\"][0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=net.state_dict()[\"fc2.weight\"][points]\n",
    "    row=row/len(setpoints[key])\n",
    "    temp_weight.append(row)\n",
    "# print(len(temp_weight), temp_weight[0].shape)\n",
    "\n",
    "# print(net.state_dict()[\"fc2.bias\"].shape)\n",
    "temp_bias=torch.zeros(len(temp_weight), dtype=torch.float)\n",
    "i=0\n",
    "for key in setpoints.keys():\n",
    "    for points in setpoints[key]:\n",
    "        temp_bias[i]+=net.state_dict()[\"fc2.bias\"][points]\n",
    "    temp_bias[i]/=len(setpoints[key])\n",
    "    i+=1\n",
    "# print(temp_bias.shape)\n",
    "\n",
    "print(\"Updating fc2.................\")\n",
    "net_3 = changenet(net, \"fc2\", temp_weight, temp_bias)\n",
    "net=copy.deepcopy(net_3)\n",
    "\n",
    "mat=net.state_dict()[\"fc3.weight\"].t()\n",
    "# print(mat.shape)\n",
    "\n",
    "temp_weight=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(mat[0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=mat[points]\n",
    "    temp_weight.append(row)\n",
    "# print(len(temp_weight), temp_weight[0].shape)\n",
    "\n",
    "newmat=torch.stack(temp_weight, dim=0)\n",
    "newmat=newmat.t()\n",
    "# print(newmat.shape)\n",
    "\n",
    "print(\"Adjusting fc3 accordingly.................\")\n",
    "net_4 = changenet(net, \"fc3\", newmat, net.state_dict()[\"fc3.bias\"])\n",
    "net=copy.deepcopy(net_4)\n",
    "\n",
    "print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "print(net.state_dict()[\"fc3.weight\"].shape)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, len(net.state_dict()[\"fc1.weight\"]))\n",
    "        self.fc2 = nn.Linear(len(net.state_dict()[\"fc2.weight\"][0]), len(net.state_dict()[\"fc2.weight\"]))\n",
    "        self.fc3 = nn.Linear(len(net.state_dict()[\"fc3.weight\"][0]), 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "i=0\n",
    "for parameter in net.parameters():\n",
    "    i+=1\n",
    "    if(i<5):\n",
    "        parameter.requires_grad=False\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.1307,), (0.3081,))])\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=200,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=200,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('0', '1', '2', '3',\n",
    "           '4', '5', '6', '7', '8', '9')\n",
    "\n",
    "# import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        # print(inputs.shape)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    # print every 2000 mini-batches\n",
    "            print(\"[{}, {}] loss: {}\".format\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Reraining')\n",
    "\n",
    "\n",
    "from torchsummary import summary\n",
    "device=torch.device(\"cpu\")\n",
    "model=Net().to(device)\n",
    "summary(model, input_size=(1, 28, 28), device=\"cpu\")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"LeNET_120_40_MNIST_Model_My_Exiperiment_4_Fine_Tuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning fc1.................\n",
      "Finding clusters of nodes.................\n",
      "desired len= 90\n",
      "cut_off= 0.9729651454689077\n",
      "iteration= 1  length= 1  difference= -89  change rate= 0.0009729651454689077\n",
      "cut_off= 0.8863712475221749\n",
      "iteration= 2  length= 1  difference= -89  change rate= 0.0009729651454689077\n",
      "cut_off= 0.7997773495754421\n",
      "iteration= 3  length= 7  difference= -83  change rate= 0.0009729651454689077\n",
      "cut_off= 0.7190212425015228\n",
      "iteration= 4  length= 31  difference= -59  change rate= 0.0009729651454689077\n",
      "cut_off= 0.6616162989188572\n",
      "iteration= 5  length= 102  difference= 12  change rate= 0.0009729651454689077\n",
      "cut_off= 0.6732918806644841\n",
      "iteration= 6  length= 91  difference= 1  change rate= 0.0009729651454689077\n",
      "cut_off= 0.674264845809953\n",
      "iteration= 7  length= 91  difference= 1  change rate= 0.0009729651454689077\n",
      "cut_off= 0.675237810955422\n",
      "iteration= 8  length= 91  difference= 1  change rate= 0.0009729651454689077\n",
      "cut_off= 0.676210776100891\n",
      "iteration= 9  length= 90  difference= 1  change rate= 0.0009729651454689077\n",
      "Updating fc1.................\n",
      "torch.Size([120])  ->  torch.Size([90])\n",
      "torch.Size([120, 256])  ->  torch.Size([90, 256])\n",
      "Adjusting fc2 accordingly.................\n",
      "torch.Size([90, 256])\n",
      "torch.Size([40, 90])\n",
      "torch.Size([10, 40])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 24, 24]             156\n",
      "         MaxPool2d-2            [-1, 6, 12, 12]               0\n",
      "            Conv2d-3             [-1, 16, 8, 8]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 4, 4]               0\n",
      "            Linear-5                   [-1, 90]          23,130\n",
      "            Linear-6                   [-1, 40]           3,640\n",
      "            Linear-7                   [-1, 10]             410\n",
      "================================================================\n",
      "Total params: 29,752\n",
      "Trainable params: 29,752\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 0.11\n",
      "Estimated Total Size (MB): 0.16\n",
      "----------------------------------------------------------------\n",
      "Accuracy of the network on the test images: 97.490000 %\n",
      "Pruning fc2.................\n",
      "Finding clusters of nodes.................\n",
      "desired len= 30\n",
      "cut_off= 0.959786229422848\n",
      "iteration= 1  length= 7  difference= -23  change rate= 0.000959786229422848\n",
      "cut_off= 0.9377111461461225\n",
      "iteration= 2  length= 7  difference= -23  change rate= 0.000959786229422848\n",
      "cut_off= 0.915636062869397\n",
      "iteration= 3  length= 7  difference= -23  change rate= 0.000959786229422848\n",
      "cut_off= 0.8935609795926716\n",
      "iteration= 4  length= 8  difference= -22  change rate= 0.000959786229422848\n",
      "cut_off= 0.8724456825453689\n",
      "iteration= 5  length= 9  difference= -21  change rate= 0.000959786229422848\n",
      "cut_off= 0.8522901717274891\n",
      "iteration= 6  length= 8  difference= -22  change rate= 0.000959786229422848\n",
      "cut_off= 0.8311748746801865\n",
      "iteration= 7  length= 10  difference= -20  change rate= 0.000959786229422848\n",
      "cut_off= 0.8119791500917295\n",
      "iteration= 8  length= 11  difference= -19  change rate= 0.000959786229422848\n",
      "cut_off= 0.7937432117326954\n",
      "iteration= 9  length= 12  difference= -18  change rate= 0.000959786229422848\n",
      "cut_off= 0.776467059603084\n",
      "iteration= 10  length= 13  difference= -17  change rate= 0.000959786229422848\n",
      "cut_off= 0.7601506937028957\n",
      "iteration= 11  length= 14  difference= -16  change rate= 0.000959786229422848\n",
      "cut_off= 0.7447941140321301\n",
      "iteration= 12  length= 15  difference= -15  change rate= 0.000959786229422848\n",
      "cut_off= 0.7303973205907874\n",
      "iteration= 13  length= 15  difference= -15  change rate= 0.000959786229422848\n",
      "cut_off= 0.7160005271494447\n",
      "iteration= 14  length= 16  difference= -14  change rate= 0.000959786229422848\n",
      "cut_off= 0.7025635199375249\n",
      "iteration= 15  length= 16  difference= -14  change rate= 0.000959786229422848\n",
      "cut_off= 0.689126512725605\n",
      "iteration= 16  length= 15  difference= -15  change rate= 0.000959786229422848\n",
      "cut_off= 0.6747297192842623\n",
      "iteration= 17  length= 18  difference= -12  change rate= 0.000959786229422848\n",
      "cut_off= 0.6632122845311881\n",
      "iteration= 18  length= 22  difference= -8  change rate= 0.000959786229422848\n",
      "cut_off= 0.6555339946958053\n",
      "iteration= 19  length= 24  difference= -6  change rate= 0.000959786229422848\n",
      "cut_off= 0.6497752773192682\n",
      "iteration= 20  length= 26  difference= -4  change rate= 0.000959786229422848\n",
      "cut_off= 0.6459361324015768\n",
      "iteration= 21  length= 26  difference= -4  change rate= 0.000959786229422848\n",
      "cut_off= 0.6420969874838853\n",
      "iteration= 22  length= 27  difference= -3  change rate= 0.000959786229422848\n",
      "cut_off= 0.6392176287956168\n",
      "iteration= 23  length= 27  difference= -3  change rate= 0.000959786229422848\n",
      "cut_off= 0.6363382701073483\n",
      "iteration= 24  length= 27  difference= -3  change rate= 0.000959786229422848\n",
      "cut_off= 0.6334589114190798\n",
      "iteration= 25  length= 27  difference= -3  change rate= 0.000959786229422848\n",
      "cut_off= 0.6305795527308113\n",
      "iteration= 26  length= 28  difference= -2  change rate= 0.000959786229422848\n",
      "cut_off= 0.6286599802719657\n",
      "iteration= 27  length= 28  difference= -2  change rate= 0.000959786229422848\n",
      "cut_off= 0.62674040781312\n",
      "iteration= 28  length= 28  difference= -2  change rate= 0.000959786229422848\n",
      "cut_off= 0.6248208353542744\n",
      "iteration= 29  length= 28  difference= -2  change rate= 0.000959786229422848\n",
      "cut_off= 0.6229012628954287\n",
      "iteration= 30  length= 28  difference= -2  change rate= 0.000959786229422848\n",
      "cut_off= 0.620981690436583\n",
      "iteration= 31  length= 28  difference= -2  change rate= 0.000959786229422848\n",
      "cut_off= 0.6190621179777374\n",
      "iteration= 32  length= 28  difference= -2  change rate= 0.000959786229422848\n",
      "cut_off= 0.6171425455188917\n",
      "iteration= 33  length= 29  difference= -1  change rate= 0.000959786229422848\n",
      "cut_off= 0.6161827592894689\n",
      "iteration= 34  length= 29  difference= -1  change rate= 0.000959786229422848\n",
      "cut_off= 0.615222973060046\n",
      "iteration= 35  length= 29  difference= -1  change rate= 0.000959786229422848\n",
      "cut_off= 0.6142631868306232\n",
      "iteration= 36  length= 29  difference= -1  change rate= 0.000959786229422848\n",
      "cut_off= 0.6133034006012004\n",
      "iteration= 37  length= 29  difference= -1  change rate= 0.000959786229422848\n",
      "cut_off= 0.6123436143717775\n",
      "iteration= 38  length= 29  difference= -1  change rate= 0.000959786229422848\n",
      "cut_off= 0.6113838281423547\n",
      "iteration= 39  length= 29  difference= -1  change rate= 0.000959786229422848\n",
      "cut_off= 0.6104240419129319\n",
      "iteration= 40  length= 29  difference= -1  change rate= 0.000959786229422848\n",
      "cut_off= 0.609464255683509\n",
      "iteration= 41  length= 29  difference= -1  change rate= 0.000959786229422848\n",
      "cut_off= 0.6085044694540862\n",
      "iteration= 42  length= 29  difference= -1  change rate= 0.000959786229422848\n",
      "cut_off= 0.6075446832246634\n",
      "iteration= 43  length= 29  difference= -1  change rate= 0.000959786229422848\n",
      "cut_off= 0.6065848969952405\n",
      "iteration= 44  length= 29  difference= -1  change rate= 0.000959786229422848\n",
      "cut_off= 0.6056251107658177\n",
      "iteration= 45  length= 31  difference= 1  change rate= 0.0008638076064805632\n",
      "cut_off= 0.6064889183722982\n",
      "iteration= 46  length= 30  difference= 1  change rate= 0.0008638076064805632\n",
      "Updating fc2.................\n",
      "Adjusting fc3 accordingly.................\n",
      "torch.Size([90, 256])\n",
      "torch.Size([30, 90])\n",
      "torch.Size([10, 30])\n",
      "Accuracy of the network on the test images: 94.020000 %\n",
      "[1, 20] loss: 0.0006900352500379085\n",
      "[1, 40] loss: 0.0005164122683927417\n",
      "[1, 60] loss: 0.0006569463089108467\n",
      "[1, 80] loss: 0.0005400159927085042\n",
      "[1, 100] loss: 0.0005014658351428807\n",
      "[1, 120] loss: 0.0004817301193252206\n",
      "[1, 140] loss: 0.0003922554589807987\n",
      "[1, 160] loss: 0.00036915194615721704\n",
      "[1, 180] loss: 0.0003447136802133173\n",
      "[1, 200] loss: 0.0003079684723634273\n",
      "[1, 220] loss: 0.0004138343278318644\n",
      "[1, 240] loss: 0.0003510159566067159\n",
      "[1, 260] loss: 0.0004753571669571102\n",
      "[1, 280] loss: 0.00046166658122092486\n",
      "[1, 300] loss: 0.0004056897787377238\n",
      "[2, 20] loss: 0.0004507649044971913\n",
      "[2, 40] loss: 0.00044613941479474306\n",
      "[2, 60] loss: 0.00030804105009883643\n",
      "[2, 80] loss: 0.00028066036105155943\n",
      "[2, 100] loss: 0.0002554033328779042\n",
      "[2, 120] loss: 0.0003926232443191111\n",
      "[2, 140] loss: 0.00035087021207436917\n",
      "[2, 160] loss: 0.00032104166923090815\n",
      "[2, 180] loss: 0.0002983341813087463\n",
      "[2, 200] loss: 0.00034632396697998046\n",
      "[2, 220] loss: 0.0002919741440564394\n",
      "[2, 240] loss: 0.0003535458003170788\n",
      "[2, 260] loss: 0.0003451886810362339\n",
      "[2, 280] loss: 0.00027610344090498985\n",
      "[2, 300] loss: 0.0004207276040688157\n",
      "[3, 20] loss: 0.00026212902739644053\n",
      "[3, 40] loss: 0.00027265369798988104\n",
      "[3, 60] loss: 0.00026693837018683554\n",
      "[3, 80] loss: 0.0002807461102493107\n",
      "[3, 100] loss: 0.0002641074247658253\n",
      "[3, 120] loss: 0.0002281637906562537\n",
      "[3, 140] loss: 0.00025754042714834215\n",
      "[3, 160] loss: 0.0002865767111070454\n",
      "[3, 180] loss: 0.00024980521434918047\n",
      "[3, 200] loss: 0.0002972723057027906\n",
      "[3, 220] loss: 0.0003700557369738817\n",
      "[3, 240] loss: 0.0003673531413078308\n",
      "[3, 260] loss: 0.000257063303142786\n",
      "[3, 280] loss: 0.00023352923803031443\n",
      "[3, 300] loss: 0.0003042812771163881\n",
      "[4, 20] loss: 0.0002295166044496\n",
      "[4, 40] loss: 0.0002730152402073145\n",
      "[4, 60] loss: 0.0003021292248740792\n",
      "[4, 80] loss: 0.00023729590559378266\n",
      "[4, 100] loss: 0.00026624022936448454\n",
      "[4, 120] loss: 0.0003493483737111092\n",
      "[4, 140] loss: 0.00023796094558201731\n",
      "[4, 160] loss: 0.00025096781412139535\n",
      "[4, 180] loss: 0.00024134918418712914\n",
      "[4, 200] loss: 0.0002709182910621166\n",
      "[4, 220] loss: 0.0002822848274372518\n",
      "[4, 240] loss: 0.00027040045522153377\n",
      "[4, 260] loss: 0.00023702356172725558\n",
      "[4, 280] loss: 0.00023138987948186695\n",
      "[4, 300] loss: 0.00029155159229412675\n",
      "[5, 20] loss: 0.00018146310676820577\n",
      "[5, 40] loss: 0.00018431889684870838\n",
      "[5, 60] loss: 0.0002494282159022987\n",
      "[5, 80] loss: 0.00029476880701258777\n",
      "[5, 100] loss: 0.00027521860133856535\n",
      "[5, 120] loss: 0.0003268094933591783\n",
      "[5, 140] loss: 0.0002594374255277216\n",
      "[5, 160] loss: 0.0002547786948271096\n",
      "[5, 180] loss: 0.00020794022013433276\n",
      "[5, 200] loss: 0.00022513216221705079\n",
      "[5, 220] loss: 0.00024231725046411156\n",
      "[5, 240] loss: 0.0002712223334237933\n",
      "[5, 260] loss: 0.00025794420880265536\n",
      "[5, 280] loss: 0.00025686760526150463\n",
      "[5, 300] loss: 0.000292913063429296\n",
      "[6, 20] loss: 0.00027164272405207155\n",
      "[6, 40] loss: 0.00024514350667595864\n",
      "[6, 60] loss: 0.00024881589179858566\n",
      "[6, 80] loss: 0.0002657112351153046\n",
      "[6, 100] loss: 0.00025188643345609306\n",
      "[6, 120] loss: 0.0002462230406235903\n",
      "[6, 140] loss: 0.00024136227276176214\n",
      "[6, 160] loss: 0.00030101905902847647\n",
      "[6, 180] loss: 0.00025999971246346834\n",
      "[6, 200] loss: 0.0002608084989478812\n",
      "[6, 220] loss: 0.0002424484365619719\n",
      "[6, 240] loss: 0.00023076060134917498\n",
      "[6, 260] loss: 0.0002003649657126516\n",
      "[6, 280] loss: 0.00019748159497976302\n",
      "[6, 300] loss: 0.0002724110810086131\n",
      "[7, 20] loss: 0.00022310719219967724\n",
      "[7, 40] loss: 0.00022110975254327058\n",
      "[7, 60] loss: 0.0002457813562359661\n",
      "[7, 80] loss: 0.00025225535919889806\n",
      "[7, 100] loss: 0.00028861302835866807\n",
      "[7, 120] loss: 0.00019050145940855144\n",
      "[7, 140] loss: 0.00025816369568929074\n",
      "[7, 160] loss: 0.00024189705168828368\n",
      "[7, 180] loss: 0.00025227048830129206\n",
      "[7, 200] loss: 0.0002183691458776593\n",
      "[7, 220] loss: 0.0002286574887111783\n",
      "[7, 240] loss: 0.00024901451054029167\n",
      "[7, 260] loss: 0.00021888857218436896\n",
      "[7, 280] loss: 0.00025273560546338556\n",
      "[7, 300] loss: 0.00023807798000052572\n",
      "[8, 20] loss: 0.00027267168276011943\n",
      "[8, 40] loss: 0.00020239049789961427\n",
      "[8, 60] loss: 0.00026416136231273413\n",
      "[8, 80] loss: 0.00024245988647453488\n",
      "[8, 100] loss: 0.00023417715274263174\n",
      "[8, 120] loss: 0.00019491507671773434\n",
      "[8, 140] loss: 0.0002292663026601076\n",
      "[8, 160] loss: 0.00017574696708470584\n",
      "[8, 180] loss: 0.00021068339049816132\n",
      "[8, 200] loss: 0.0002526747721713036\n",
      "[8, 220] loss: 0.0002429350451566279\n",
      "[8, 240] loss: 0.0002458801050670445\n",
      "[8, 260] loss: 0.00022717656870372592\n",
      "[8, 280] loss: 0.00028354901913553476\n",
      "[8, 300] loss: 0.0002279962934553623\n",
      "[9, 20] loss: 0.0002596928793936968\n",
      "[9, 40] loss: 0.00028274690452963116\n",
      "[9, 60] loss: 0.00021867398533504455\n",
      "[9, 80] loss: 0.00022528443578630685\n",
      "[9, 100] loss: 0.00021787067083641886\n",
      "[9, 120] loss: 0.00017908289725892247\n",
      "[9, 140] loss: 0.00026439855596981944\n",
      "[9, 160] loss: 0.0002295549816917628\n",
      "[9, 180] loss: 0.0002484832615591586\n",
      "[9, 200] loss: 0.00022881554951891304\n",
      "[9, 220] loss: 0.00022222404507920147\n",
      "[9, 240] loss: 0.0002035296927206218\n",
      "[9, 260] loss: 0.00019054185040295123\n",
      "[9, 280] loss: 0.0001662735161371529\n",
      "[9, 300] loss: 0.00020140624186024069\n",
      "[10, 20] loss: 0.0001837576162070036\n",
      "[10, 40] loss: 0.00026662901253439485\n",
      "[10, 60] loss: 0.00020934654958546162\n",
      "[10, 80] loss: 0.0002378810248337686\n",
      "[10, 100] loss: 0.0002530032931827009\n",
      "[10, 120] loss: 0.00032325990311801435\n",
      "[10, 140] loss: 0.00023151396750472486\n",
      "[10, 160] loss: 0.00018184827570803463\n",
      "[10, 180] loss: 0.0001941321382764727\n",
      "[10, 200] loss: 0.00024262671172618866\n",
      "[10, 220] loss: 0.0002595026872586459\n",
      "[10, 240] loss: 0.00020079731312580408\n",
      "[10, 260] loss: 0.00021067365910857916\n",
      "[10, 280] loss: 0.00025265530357137324\n",
      "[10, 300] loss: 0.00019914671732112766\n",
      "[11, 20] loss: 0.00021252720756456255\n",
      "[11, 40] loss: 0.00018864810583181678\n",
      "[11, 60] loss: 0.00018349442165344954\n",
      "[11, 80] loss: 0.00023436804860830308\n",
      "[11, 100] loss: 0.00021984103228896856\n",
      "[11, 120] loss: 0.00017623049637768417\n",
      "[11, 140] loss: 0.000218092349357903\n",
      "[11, 160] loss: 0.00019286055560223758\n",
      "[11, 180] loss: 0.0002417227542027831\n",
      "[11, 200] loss: 0.00024805155233480035\n",
      "[11, 220] loss: 0.00029389704577624797\n",
      "[11, 240] loss: 0.00018890851736068725\n",
      "[11, 260] loss: 0.0002070415804628283\n",
      "[11, 280] loss: 0.00019629258289933206\n",
      "[11, 300] loss: 0.00024941875552758576\n",
      "[12, 20] loss: 0.0002197026868816465\n",
      "[12, 40] loss: 0.00025090481340885165\n",
      "[12, 60] loss: 0.00022915611951611936\n",
      "[12, 80] loss: 0.0001825159159488976\n",
      "[12, 100] loss: 0.0001825470360927284\n",
      "[12, 120] loss: 0.00025742959696799516\n",
      "[12, 140] loss: 0.0002240678088273853\n",
      "[12, 160] loss: 0.0001972970678471029\n",
      "[12, 180] loss: 0.0002247152985073626\n",
      "[12, 200] loss: 0.000163274516351521\n",
      "[12, 220] loss: 0.00027704647812061014\n",
      "[12, 240] loss: 0.00018235831800848245\n",
      "[12, 260] loss: 0.00021730657981242985\n",
      "[12, 280] loss: 0.00022836188622750342\n",
      "[12, 300] loss: 0.00023104896559379996\n",
      "[13, 20] loss: 0.00016057834052480758\n",
      "[13, 40] loss: 0.00021930603543296456\n",
      "[13, 60] loss: 0.00023971461923792957\n",
      "[13, 80] loss: 0.00017947413143701852\n",
      "[13, 100] loss: 0.0001994288582354784\n",
      "[13, 120] loss: 0.00018854179489426315\n",
      "[13, 140] loss: 0.00020705529139377176\n",
      "[13, 160] loss: 0.00023575929645448923\n",
      "[13, 180] loss: 0.000204654345754534\n",
      "[13, 200] loss: 0.00018327952385880053\n",
      "[13, 220] loss: 0.00017669648281298578\n",
      "[13, 240] loss: 0.00017928152321837842\n",
      "[13, 260] loss: 0.0002339028778951615\n",
      "[13, 280] loss: 0.00022580229677259922\n",
      "[13, 300] loss: 0.0002254330851137638\n",
      "[14, 20] loss: 0.00017444226378574967\n",
      "[14, 40] loss: 0.000187544000800699\n",
      "[14, 60] loss: 0.0002178840530104935\n",
      "[14, 80] loss: 0.00017205143789760768\n",
      "[14, 100] loss: 0.0002119622176978737\n",
      "[14, 120] loss: 0.00019457817170768975\n",
      "[14, 140] loss: 0.00020622078177984804\n",
      "[14, 160] loss: 0.0001793819407466799\n",
      "[14, 180] loss: 0.00017731808312237263\n",
      "[14, 200] loss: 0.00022097918181680144\n",
      "[14, 220] loss: 0.00019723536679521202\n",
      "[14, 240] loss: 0.00018558663176372647\n",
      "[14, 260] loss: 0.0002291726574767381\n",
      "[14, 280] loss: 0.00022006469545885922\n",
      "[14, 300] loss: 0.00024163573537953198\n",
      "[15, 20] loss: 0.0002166989385150373\n",
      "[15, 40] loss: 0.00020058838976547123\n",
      "[15, 60] loss: 0.00021417442336678504\n",
      "[15, 80] loss: 0.00019301661639474334\n",
      "[15, 100] loss: 0.0002169856852851808\n",
      "[15, 120] loss: 0.00019920194428414107\n",
      "[15, 140] loss: 0.0001703218724578619\n",
      "[15, 160] loss: 0.00020490105799399316\n",
      "[15, 180] loss: 0.00020574118243530393\n",
      "[15, 200] loss: 0.00018853830499574543\n",
      "[15, 220] loss: 0.00014130140747874975\n",
      "[15, 240] loss: 0.00022433169814758003\n",
      "[15, 260] loss: 0.0002410560029093176\n",
      "[15, 280] loss: 0.00019349761866033078\n",
      "[15, 300] loss: 0.00016698290663771332\n",
      "[16, 20] loss: 0.00015437127440236508\n",
      "[16, 40] loss: 0.00021797954104840755\n",
      "[16, 60] loss: 0.00019534005410969257\n",
      "[16, 80] loss: 0.00018558351253159343\n",
      "[16, 100] loss: 0.00021589688956737517\n",
      "[16, 120] loss: 0.00017028273828327656\n",
      "[16, 140] loss: 0.0002003969647921622\n",
      "[16, 160] loss: 0.00016099474299699067\n",
      "[16, 180] loss: 0.00018131867621559649\n",
      "[16, 200] loss: 0.00019313535164110362\n",
      "[16, 220] loss: 0.0002102956564631313\n",
      "[16, 240] loss: 0.00023276779404841363\n",
      "[16, 260] loss: 0.0001688363968860358\n",
      "[16, 280] loss: 0.00017338639870285988\n",
      "[16, 300] loss: 0.00017895131302066148\n",
      "[17, 20] loss: 0.00020657612523064018\n",
      "[17, 40] loss: 0.0002847883636131883\n",
      "[17, 60] loss: 0.00017505916254594923\n",
      "[17, 80] loss: 0.00018215206044260411\n",
      "[17, 100] loss: 0.000195478031411767\n",
      "[17, 120] loss: 0.0001599807993043214\n",
      "[17, 140] loss: 0.00018445501639507712\n",
      "[17, 160] loss: 0.0001715782593237236\n",
      "[17, 180] loss: 0.0001500613703392446\n",
      "[17, 200] loss: 0.00022977471025660635\n",
      "[17, 220] loss: 0.00018247776525095105\n",
      "[17, 240] loss: 0.0001925975224003196\n",
      "[17, 260] loss: 0.00021444735210388898\n",
      "[17, 280] loss: 0.00018776714685373008\n",
      "[17, 300] loss: 0.00016143902228213847\n",
      "[18, 20] loss: 0.00015967147145420313\n",
      "[18, 40] loss: 0.00014058946282602847\n",
      "[18, 60] loss: 0.00016402410564478486\n",
      "[18, 80] loss: 0.0001873499855864793\n",
      "[18, 100] loss: 0.00022009865543805063\n",
      "[18, 120] loss: 0.00016355107177514584\n",
      "[18, 140] loss: 0.0001850109703373164\n",
      "[18, 160] loss: 0.00026629503141157326\n",
      "[18, 180] loss: 0.0002335700076073408\n",
      "[18, 200] loss: 0.0002135102148167789\n",
      "[18, 220] loss: 0.00019783578254282475\n",
      "[18, 240] loss: 0.00018885755236260594\n",
      "[18, 260] loss: 0.0001837710915133357\n",
      "[18, 280] loss: 0.00016372234467417003\n",
      "[18, 300] loss: 0.0001640076981857419\n",
      "[19, 20] loss: 0.00018867491162382065\n",
      "[19, 40] loss: 0.00014387432218063623\n",
      "[19, 60] loss: 0.00020096254302188755\n",
      "[19, 80] loss: 0.00017652910039760172\n",
      "[19, 100] loss: 0.00019442248274572193\n",
      "[19, 120] loss: 0.0002554438738152385\n",
      "[19, 140] loss: 0.00012564888061024248\n",
      "[19, 160] loss: 0.00016582296462729572\n",
      "[19, 180] loss: 0.0001598373274318874\n",
      "[19, 200] loss: 0.00017635245830751955\n",
      "[19, 220] loss: 0.00020415821601636709\n",
      "[19, 240] loss: 0.0002546933768317103\n",
      "[19, 260] loss: 0.00021380332321859895\n",
      "[19, 280] loss: 0.00016571538196876644\n",
      "[19, 300] loss: 0.00021571860346011816\n",
      "[20, 20] loss: 0.00017943424801342188\n",
      "[20, 40] loss: 0.00016598546388559043\n",
      "[20, 60] loss: 0.000157846286194399\n",
      "[20, 80] loss: 0.00018482574471272528\n",
      "[20, 100] loss: 0.00016634406801313163\n",
      "[20, 120] loss: 0.0002250944112893194\n",
      "[20, 140] loss: 0.00021142540825530887\n",
      "[20, 160] loss: 0.000151588401873596\n",
      "[20, 180] loss: 0.00013000008324161173\n",
      "[20, 200] loss: 0.000194164160406217\n",
      "[20, 220] loss: 0.00019580720248632132\n",
      "[20, 240] loss: 0.0002198476220946759\n",
      "[20, 260] loss: 0.00018092266982421278\n",
      "[20, 280] loss: 0.00020316844200715423\n",
      "[20, 300] loss: 0.00014657361549325288\n",
      "Finished Reraining\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 24, 24]             156\n",
      "         MaxPool2d-2            [-1, 6, 12, 12]               0\n",
      "            Conv2d-3             [-1, 16, 8, 8]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 4, 4]               0\n",
      "            Linear-5                   [-1, 90]          23,130\n",
      "            Linear-6                   [-1, 30]           2,730\n",
      "            Linear-7                   [-1, 10]             310\n",
      "================================================================\n",
      "Total params: 28,742\n",
      "Trainable params: 28,742\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 0.11\n",
      "Estimated Total Size (MB): 0.16\n",
      "----------------------------------------------------------------\n",
      "Accuracy of the network on the test images: 98.530000 %\n"
     ]
    }
   ],
   "source": [
    "len_1=90\n",
    "len_2=30\n",
    "\n",
    "print(\"Pruning fc1.................\")\n",
    "\n",
    "nodes=defaultdict(list)\n",
    "for j in range(len(net.state_dict()[\"fc1.weight\"])):  #Means j is a node of next layer, L2. Fc1 is connecting L1 and L2 layer.\n",
    "    nodes[j]=net.state_dict()[\"fc1.weight\"][j]\n",
    "\n",
    "# print(len(nodes), \" \", len(nodes[0]))\n",
    "\n",
    "# from math import sqrt\n",
    "distances=[]\n",
    "for i in nodes.keys():\n",
    "    for j in nodes.keys():\n",
    "        if(i!=j and j>i):\n",
    "            distances.append(euclidean_distance(nodes[i], nodes[j]))\n",
    "\n",
    "distances.sort()\n",
    "            \n",
    "print(\"Finding clusters of nodes.................\")\n",
    "setpoints=findsets(len_1, nodes, distances)\n",
    "\n",
    "# print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "temp_weights=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(net.state_dict()[\"fc1.weight\"][0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=net.state_dict()[\"fc1.weight\"][points]\n",
    "    row=row/len(setpoints[key])\n",
    "    temp_weights.append(row)\n",
    "# print(len(temp_weights), temp_weights[0].shape)\n",
    "\n",
    "# print(net.state_dict()[\"fc1.bias\"].shape)\n",
    "temp_bias=torch.zeros(len(temp_weights), dtype=torch.float)\n",
    "i=0\n",
    "for key in setpoints.keys():\n",
    "    for points in setpoints[key]:\n",
    "        temp_bias[i]+=net.state_dict()[\"fc1.bias\"][points]\n",
    "    temp_bias[i]/=len(setpoints[key])\n",
    "    i+=1\n",
    "# print(temp_bias.shape)\n",
    "\n",
    "print(\"Updating fc1.................\")\n",
    "net_1 = changenet(net, \"fc1\", temp_weights, temp_bias)\n",
    "\n",
    "print(net.state_dict()[\"fc1.bias\"].shape, \" -> \", net_1.state_dict()[\"fc1.bias\"].shape)\n",
    "print(net.state_dict()[\"fc1.weight\"].shape, \" -> \", net_1.state_dict()[\"fc1.weight\"].shape)\n",
    "\n",
    "net=copy.deepcopy(net_1)\n",
    "# print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "# print(net.state_dict()[\"fc1.bias\"].shape)\n",
    "\n",
    "#just to check if the copy has been done correctly\n",
    "# print(temp_weights[0],\"\\n\\n\",net.state_dict()[\"fc1.weight\"][0])    \n",
    "\n",
    "\n",
    "### Now, we have to change FC2 accordingly:\n",
    "# print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "print(\"Adjusting fc2 accordingly.................\")\n",
    "mat=net.state_dict()[\"fc2.weight\"].t()\n",
    "# print(mat.shape)\n",
    "\n",
    "temp_weight=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(mat[0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=mat[points]\n",
    "    temp_weight.append(row)\n",
    "# print(len(temp_weight), temp_weight[0].shape)\n",
    "\n",
    "newmat=torch.stack(temp_weight, dim=0)\n",
    "newmat=newmat.t()\n",
    "# print(newmat.shape)\n",
    "\n",
    "# print(net.state_dict()[\"fc2.bias\"].shape)\n",
    "\n",
    "net_2 = changenet(net, \"fc2\", newmat, net.state_dict()[\"fc2.bias\"])\n",
    "net=copy.deepcopy(net_2)\n",
    "\n",
    "print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "print(net.state_dict()[\"fc3.weight\"].shape)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, len(net.state_dict()[\"fc1.weight\"]))\n",
    "        self.fc2 = nn.Linear(len(net.state_dict()[\"fc2.weight\"][0]), len(net.state_dict()[\"fc2.weight\"]))\n",
    "        self.fc3 = nn.Linear(len(net.state_dict()[\"fc3.weight\"][0]), 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    \n",
    "from torchsummary import summary\n",
    "device=torch.device(\"cpu\")\n",
    "model=Net().to(device)\n",
    "summary(model, input_size=(1, 28, 28), device=\"cpu\")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "\n",
    "print(\"Pruning fc2.................\")\n",
    "from collections import defaultdict\n",
    "nodes=defaultdict(list)\n",
    "for j in range(len(net.state_dict()[\"fc2.weight\"])):  #Means j is a node of next layer, L2.\n",
    "    nodes[j]=net.state_dict()[\"fc2.weight\"][j]\n",
    "\n",
    "# print(len(nodes), \" \", len(nodes[0]))\n",
    "\n",
    "\n",
    "distances=[]\n",
    "for i in nodes.keys():\n",
    "    for j in nodes.keys():\n",
    "        if(i!=j and j>i):\n",
    "            distances.append(euclidean_distance(nodes[i], nodes[j]))\n",
    "            \n",
    "distances.sort()\n",
    "# print(len(distances))\n",
    "\n",
    "print(\"Finding clusters of nodes.................\")\n",
    "setpoints=findsets(len_2, nodes, distances)\n",
    "\n",
    "# print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "temp_weight=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(net.state_dict()[\"fc2.weight\"][0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=net.state_dict()[\"fc2.weight\"][points]\n",
    "    row=row/len(setpoints[key])\n",
    "    temp_weight.append(row)\n",
    "# print(len(temp_weight), temp_weight[0].shape)\n",
    "\n",
    "# print(net.state_dict()[\"fc2.bias\"].shape)\n",
    "temp_bias=torch.zeros(len(temp_weight), dtype=torch.float)\n",
    "i=0\n",
    "for key in setpoints.keys():\n",
    "    for points in setpoints[key]:\n",
    "        temp_bias[i]+=net.state_dict()[\"fc2.bias\"][points]\n",
    "    temp_bias[i]/=len(setpoints[key])\n",
    "    i+=1\n",
    "# print(temp_bias.shape)\n",
    "\n",
    "print(\"Updating fc2.................\")\n",
    "net_3 = changenet(net, \"fc2\", temp_weight, temp_bias)\n",
    "net=copy.deepcopy(net_3)\n",
    "\n",
    "mat=net.state_dict()[\"fc3.weight\"].t()\n",
    "# print(mat.shape)\n",
    "\n",
    "temp_weight=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(mat[0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=mat[points]\n",
    "    temp_weight.append(row)\n",
    "# print(len(temp_weight), temp_weight[0].shape)\n",
    "\n",
    "newmat=torch.stack(temp_weight, dim=0)\n",
    "newmat=newmat.t()\n",
    "# print(newmat.shape)\n",
    "\n",
    "print(\"Adjusting fc3 accordingly.................\")\n",
    "net_4 = changenet(net, \"fc3\", newmat, net.state_dict()[\"fc3.bias\"])\n",
    "net=copy.deepcopy(net_4)\n",
    "\n",
    "print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "print(net.state_dict()[\"fc3.weight\"].shape)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, len(net.state_dict()[\"fc1.weight\"]))\n",
    "        self.fc2 = nn.Linear(len(net.state_dict()[\"fc2.weight\"][0]), len(net.state_dict()[\"fc2.weight\"]))\n",
    "        self.fc3 = nn.Linear(len(net.state_dict()[\"fc3.weight\"][0]), 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "i=0\n",
    "for parameter in net.parameters():\n",
    "    i+=1\n",
    "    if(i<5):\n",
    "        parameter.requires_grad=False\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.1307,), (0.3081,))])\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=200,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=200,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('0', '1', '2', '3',\n",
    "           '4', '5', '6', '7', '8', '9')\n",
    "\n",
    "# import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        # print(inputs.shape)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    # print every 2000 mini-batches\n",
    "            print(\"[{}, {}] loss: {}\".format\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Reraining')\n",
    "\n",
    "\n",
    "from torchsummary import summary\n",
    "device=torch.device(\"cpu\")\n",
    "model=Net().to(device)\n",
    "summary(model, input_size=(1, 28, 28), device=\"cpu\")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"LeNET_90_30_MNIST_Model_My_Exiperiment_4_Fine_Tuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning fc1.................\n",
      "Finding clusters of nodes.................\n",
      "desired len= 60\n",
      "cut_off= 1.0209020409849774\n",
      "iteration= 1  length= 1  difference= -59  change rate= 0.0010209020409849773\n",
      "cut_off= 0.9606688205668638\n",
      "iteration= 2  length= 1  difference= -59  change rate= 0.0010209020409849773\n",
      "cut_off= 0.9004356001487501\n",
      "iteration= 3  length= 1  difference= -59  change rate= 0.0010209020409849773\n",
      "cut_off= 0.8402023797306365\n",
      "iteration= 4  length= 8  difference= -52  change rate= 0.0010209020409849773\n",
      "cut_off= 0.7871154735994177\n",
      "iteration= 5  length= 21  difference= -39  change rate= 0.0010209020409849773\n",
      "cut_off= 0.7473002940010036\n",
      "iteration= 6  length= 59  difference= -1  change rate= 0.0010209020409849773\n",
      "cut_off= 0.7462793919600187\n",
      "iteration= 7  length= 59  difference= -1  change rate= 0.0010209020409849773\n",
      "cut_off= 0.7452584899190338\n",
      "iteration= 8  length= 61  difference= 1  change rate= 0.0009188118368864796\n",
      "cut_off= 0.7461773017559202\n",
      "iteration= 9  length= 61  difference= 1  change rate= 0.00010053546239418662\n",
      "cut_off= 0.7462778372183144\n",
      "iteration= 10  length= 59  difference= -1  change rate= 9.048191615476797e-05\n",
      "cut_off= 0.7461873553021596\n",
      "iteration= 11  length= 61  difference= 1  change rate= 8.143372453929117e-05\n",
      "cut_off= 0.7462687890266989\n",
      "iteration= 12  length= 59  difference= -1  change rate= 7.329035208536206e-05\n",
      "cut_off= 0.7461954986746135\n",
      "iteration= 13  length= 61  difference= 1  change rate= 6.596131687682586e-05\n",
      "cut_off= 0.7462614599914904\n",
      "iteration= 14  length= 59  difference= -1  change rate= 5.9365185189143275e-05\n",
      "cut_off= 0.7462020948063013\n",
      "iteration= 15  length= 61  difference= 1  change rate= 5.342866667022895e-05\n",
      "cut_off= 0.7462555234729715\n",
      "iteration= 16  length= 59  difference= -1  change rate= 4.808580000320605e-05\n",
      "cut_off= 0.7462074376729683\n",
      "iteration= 17  length= 61  difference= 1  change rate= 4.327722000288545e-05\n",
      "cut_off= 0.7462507148929711\n",
      "iteration= 18  length= 59  difference= -1  change rate= 3.8949498002596906e-05\n",
      "cut_off= 0.7462117653949685\n",
      "iteration= 19  length= 61  difference= 1  change rate= 3.505454820233722e-05\n",
      "cut_off= 0.7462468199431708\n",
      "iteration= 20  length= 59  difference= -1  change rate= 3.1549093382103495e-05\n",
      "cut_off= 0.7462152708497887\n",
      "iteration= 21  length= 61  difference= 1  change rate= 2.8394184043893145e-05\n",
      "cut_off= 0.7462436650338325\n",
      "iteration= 22  length= 59  difference= -1  change rate= 2.555476563950383e-05\n",
      "cut_off= 0.7462181102681931\n",
      "iteration= 23  length= 61  difference= 1  change rate= 2.2999289075553447e-05\n",
      "cut_off= 0.7462411095572686\n",
      "iteration= 24  length= 59  difference= -1  change rate= 2.0699360167998103e-05\n",
      "cut_off= 0.7462204101971006\n",
      "iteration= 25  length= 59  difference= -1  change rate= 2.2649030652514452e-06\n",
      "cut_off= 0.7462181452940354\n",
      "iteration= 26  length= 61  difference= 1  change rate= 2.038412758726301e-06\n",
      "cut_off= 0.7462201837067941\n",
      "iteration= 27  length= 59  difference= -1  change rate= 1.8345714828536708e-06\n",
      "cut_off= 0.7462183491353113\n",
      "iteration= 28  length= 61  difference= 1  change rate= 1.6511143345683037e-06\n",
      "cut_off= 0.7462200002496459\n",
      "iteration= 29  length= 59  difference= -1  change rate= 1.4860029011114734e-06\n",
      "cut_off= 0.7462185142467448\n",
      "iteration= 30  length= 60  difference= -1  change rate= 1.4860029011114734e-06\n",
      "Updating fc1.................\n",
      "torch.Size([90])  ->  torch.Size([60])\n",
      "torch.Size([90, 256])  ->  torch.Size([60, 256])\n",
      "Adjusting fc2 accordingly.................\n",
      "torch.Size([60, 256])\n",
      "torch.Size([30, 60])\n",
      "torch.Size([10, 30])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 24, 24]             156\n",
      "         MaxPool2d-2            [-1, 6, 12, 12]               0\n",
      "            Conv2d-3             [-1, 16, 8, 8]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 4, 4]               0\n",
      "            Linear-5                   [-1, 60]          15,420\n",
      "            Linear-6                   [-1, 30]           1,830\n",
      "            Linear-7                   [-1, 10]             310\n",
      "================================================================\n",
      "Total params: 20,132\n",
      "Trainable params: 20,132\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 0.08\n",
      "Estimated Total Size (MB): 0.12\n",
      "----------------------------------------------------------------\n",
      "Accuracy of the network on the test images: 87.040000 %\n",
      "Pruning fc2.................\n",
      "Finding clusters of nodes.................\n",
      "desired len= 20\n",
      "cut_off= 1.143085647414547\n",
      "iteration= 1  length= 4  difference= -16  change rate= 0.001143085647414547\n",
      "cut_off= 1.1247962770559143\n",
      "iteration= 2  length= 4  difference= -16  change rate= 0.001143085647414547\n",
      "cut_off= 1.1065069066972817\n",
      "iteration= 3  length= 4  difference= -16  change rate= 0.001143085647414547\n",
      "cut_off= 1.088217536338649\n",
      "iteration= 4  length= 4  difference= -16  change rate= 0.001143085647414547\n",
      "cut_off= 1.0699281659800164\n",
      "iteration= 5  length= 4  difference= -16  change rate= 0.001143085647414547\n",
      "cut_off= 1.0516387956213837\n",
      "iteration= 6  length= 4  difference= -16  change rate= 0.001143085647414547\n",
      "cut_off= 1.033349425262751\n",
      "iteration= 7  length= 4  difference= -16  change rate= 0.001143085647414547\n",
      "cut_off= 1.0150600549041184\n",
      "iteration= 8  length= 4  difference= -16  change rate= 0.001143085647414547\n",
      "cut_off= 0.9967706845454857\n",
      "iteration= 9  length= 4  difference= -16  change rate= 0.001143085647414547\n",
      "cut_off= 0.9784813141868529\n",
      "iteration= 10  length= 4  difference= -16  change rate= 0.001143085647414547\n",
      "cut_off= 0.9601919438282202\n",
      "iteration= 11  length= 5  difference= -15  change rate= 0.001143085647414547\n",
      "cut_off= 0.943045659117002\n",
      "iteration= 12  length= 5  difference= -15  change rate= 0.001143085647414547\n",
      "cut_off= 0.9258993744057838\n",
      "iteration= 13  length= 5  difference= -15  change rate= 0.001143085647414547\n",
      "cut_off= 0.9087530896945657\n",
      "iteration= 14  length= 5  difference= -15  change rate= 0.001143085647414547\n",
      "cut_off= 0.8916068049833475\n",
      "iteration= 15  length= 6  difference= -14  change rate= 0.001143085647414547\n",
      "cut_off= 0.8756036059195439\n",
      "iteration= 16  length= 7  difference= -13  change rate= 0.001143085647414547\n",
      "cut_off= 0.8607434925031547\n",
      "iteration= 17  length= 8  difference= -12  change rate= 0.001143085647414547\n",
      "cut_off= 0.8470264647341802\n",
      "iteration= 18  length= 8  difference= -12  change rate= 0.001143085647414547\n",
      "cut_off= 0.8333094369652057\n",
      "iteration= 19  length= 8  difference= -12  change rate= 0.001143085647414547\n",
      "cut_off= 0.8195924091962311\n",
      "iteration= 20  length= 9  difference= -11  change rate= 0.001143085647414547\n",
      "cut_off= 0.8070184670746711\n",
      "iteration= 21  length= 9  difference= -11  change rate= 0.001143085647414547\n",
      "cut_off= 0.794444524953111\n",
      "iteration= 22  length= 10  difference= -10  change rate= 0.001143085647414547\n",
      "cut_off= 0.7830136684789656\n",
      "iteration= 23  length= 11  difference= -9  change rate= 0.001143085647414547\n",
      "cut_off= 0.7727258976522347\n",
      "iteration= 24  length= 12  difference= -8  change rate= 0.001143085647414547\n",
      "cut_off= 0.7635812124729183\n",
      "iteration= 25  length= 12  difference= -8  change rate= 0.001143085647414547\n",
      "cut_off= 0.754436527293602\n",
      "iteration= 26  length= 12  difference= -8  change rate= 0.001143085647414547\n",
      "cut_off= 0.7452918421142857\n",
      "iteration= 27  length= 12  difference= -8  change rate= 0.001143085647414547\n",
      "cut_off= 0.7361471569349693\n",
      "iteration= 28  length= 13  difference= -7  change rate= 0.001143085647414547\n",
      "cut_off= 0.7281455574030675\n",
      "iteration= 29  length= 13  difference= -7  change rate= 0.001143085647414547\n",
      "cut_off= 0.7201439578711657\n",
      "iteration= 30  length= 13  difference= -7  change rate= 0.001143085647414547\n",
      "cut_off= 0.7121423583392639\n",
      "iteration= 31  length= 13  difference= -7  change rate= 0.001143085647414547\n",
      "cut_off= 0.704140758807362\n",
      "iteration= 32  length= 14  difference= -6  change rate= 0.001143085647414547\n",
      "cut_off= 0.6972822449228747\n",
      "iteration= 33  length= 14  difference= -6  change rate= 0.001143085647414547\n",
      "cut_off= 0.6904237310383874\n",
      "iteration= 34  length= 13  difference= -7  change rate= 0.001143085647414547\n",
      "cut_off= 0.6824221315064856\n",
      "iteration= 35  length= 14  difference= -6  change rate= 0.001143085647414547\n",
      "cut_off= 0.6755636176219982\n",
      "iteration= 36  length= 14  difference= -6  change rate= 0.001143085647414547\n",
      "cut_off= 0.6687051037375109\n",
      "iteration= 37  length= 15  difference= -5  change rate= 0.001143085647414547\n",
      "cut_off= 0.6629896755004382\n",
      "iteration= 38  length= 15  difference= -5  change rate= 0.001143085647414547\n",
      "cut_off= 0.6572742472633655\n",
      "iteration= 39  length= 15  difference= -5  change rate= 0.001143085647414547\n",
      "cut_off= 0.6515588190262928\n",
      "iteration= 40  length= 15  difference= -5  change rate= 0.001143085647414547\n",
      "cut_off= 0.64584339078922\n",
      "iteration= 41  length= 15  difference= -5  change rate= 0.001143085647414547\n",
      "cut_off= 0.6401279625521473\n",
      "iteration= 42  length= 15  difference= -5  change rate= 0.001143085647414547\n",
      "cut_off= 0.6344125343150746\n",
      "iteration= 43  length= 18  difference= -2  change rate= 0.001143085647414547\n",
      "cut_off= 0.6321263630202455\n",
      "iteration= 44  length= 18  difference= -2  change rate= 0.001143085647414547\n",
      "cut_off= 0.6298401917254164\n",
      "iteration= 45  length= 18  difference= -2  change rate= 0.001143085647414547\n",
      "cut_off= 0.6275540204305873\n",
      "iteration= 46  length= 18  difference= -2  change rate= 0.001143085647414547\n",
      "cut_off= 0.6252678491357582\n",
      "iteration= 47  length= 18  difference= -2  change rate= 0.001143085647414547\n",
      "cut_off= 0.6229816778409291\n",
      "iteration= 48  length= 18  difference= -2  change rate= 0.001143085647414547\n",
      "cut_off= 0.6206955065461\n",
      "iteration= 49  length= 19  difference= -1  change rate= 0.001143085647414547\n",
      "cut_off= 0.6195524208986855\n",
      "iteration= 50  length= 19  difference= -1  change rate= 0.001143085647414547\n",
      "cut_off= 0.618409335251271\n",
      "iteration= 51  length= 19  difference= -1  change rate= 0.001143085647414547\n",
      "cut_off= 0.6172662496038565\n",
      "iteration= 52  length= 19  difference= -1  change rate= 0.001143085647414547\n",
      "cut_off= 0.616123163956442\n",
      "iteration= 53  length= 19  difference= -1  change rate= 0.001143085647414547\n",
      "cut_off= 0.6149800783090275\n",
      "iteration= 54  length= 19  difference= -1  change rate= 0.001143085647414547\n",
      "cut_off= 0.613836992661613\n",
      "iteration= 55  length= 19  difference= -1  change rate= 0.001143085647414547\n",
      "cut_off= 0.6126939070141985\n",
      "iteration= 56  length= 19  difference= -1  change rate= 0.001143085647414547\n",
      "cut_off= 0.611550821366784\n",
      "iteration= 57  length= 19  difference= -1  change rate= 0.001143085647414547\n",
      "cut_off= 0.6104077357193695\n",
      "iteration= 58  length= 19  difference= -1  change rate= 0.001143085647414547\n",
      "cut_off= 0.609264650071955\n",
      "iteration= 59  length= 19  difference= -1  change rate= 0.001143085647414547\n",
      "cut_off= 0.6081215644245405\n",
      "iteration= 60  length= 19  difference= -1  change rate= 0.001143085647414547\n",
      "cut_off= 0.606978478777126\n",
      "iteration= 61  length= 19  difference= -1  change rate= 0.001143085647414547\n",
      "cut_off= 0.6058353931297115\n",
      "iteration= 62  length= 19  difference= -1  change rate= 0.001143085647414547\n",
      "cut_off= 0.604692307482297\n",
      "iteration= 63  length= 19  difference= -1  change rate= 0.001143085647414547\n",
      "cut_off= 0.6035492218348825\n",
      "iteration= 64  length= 19  difference= -1  change rate= 0.001143085647414547\n",
      "cut_off= 0.602406136187468\n",
      "iteration= 65  length= 19  difference= -1  change rate= 0.001143085647414547\n",
      "cut_off= 0.6012630505400535\n",
      "iteration= 66  length= 19  difference= -1  change rate= 0.001143085647414547\n",
      "cut_off= 0.600119964892639\n",
      "iteration= 67  length= 19  difference= -1  change rate= 0.001143085647414547\n",
      "cut_off= 0.5989768792452245\n",
      "iteration= 68  length= 19  difference= -1  change rate= 0.001143085647414547\n",
      "cut_off= 0.59783379359781\n",
      "iteration= 69  length= 19  difference= -1  change rate= 0.001143085647414547\n",
      "cut_off= 0.5966907079503955\n",
      "iteration= 70  length= 20  difference= -1  change rate= 0.001143085647414547\n",
      "Updating fc2.................\n",
      "Adjusting fc3 accordingly.................\n",
      "torch.Size([60, 256])\n",
      "torch.Size([20, 60])\n",
      "torch.Size([10, 20])\n",
      "Accuracy of the network on the test images: 68.100000 %\n",
      "[1, 20] loss: 0.007105429090559483\n",
      "[1, 40] loss: 0.0014971623197197915\n",
      "[1, 60] loss: 0.000957375267520547\n",
      "[1, 80] loss: 0.0008052097745239735\n",
      "[1, 100] loss: 0.000706093905493617\n",
      "[1, 120] loss: 0.000604277360253036\n",
      "[1, 140] loss: 0.000649974700063467\n",
      "[1, 160] loss: 0.0005003559906035662\n",
      "[1, 180] loss: 0.0005633764192461968\n",
      "[1, 200] loss: 0.0005457635130733251\n",
      "[1, 220] loss: 0.0005952650429680943\n",
      "[1, 240] loss: 0.000525516327470541\n",
      "[1, 260] loss: 0.0005294124400243163\n",
      "[1, 280] loss: 0.0004743064809590578\n",
      "[1, 300] loss: 0.0005526061411947012\n",
      "[2, 20] loss: 0.0004637698009610176\n",
      "[2, 40] loss: 0.0005115006612613798\n",
      "[2, 60] loss: 0.00045657688472419976\n",
      "[2, 80] loss: 0.0004984791539609432\n",
      "[2, 100] loss: 0.00039722078060731294\n",
      "[2, 120] loss: 0.00043949094973504545\n",
      "[2, 140] loss: 0.0003923326805233955\n",
      "[2, 160] loss: 0.00038415141822770236\n",
      "[2, 180] loss: 0.000376169316470623\n",
      "[2, 200] loss: 0.0004053739830851555\n",
      "[2, 220] loss: 0.00048650970589369537\n",
      "[2, 240] loss: 0.00038587003806605933\n",
      "[2, 260] loss: 0.00035306641506031156\n",
      "[2, 280] loss: 0.00040015442948788406\n",
      "[2, 300] loss: 0.0003983307648450136\n",
      "[3, 20] loss: 0.00043333458434790373\n",
      "[3, 40] loss: 0.0003666028417646885\n",
      "[3, 60] loss: 0.0003899400015361607\n",
      "[3, 80] loss: 0.000425459245685488\n",
      "[3, 100] loss: 0.0003804747150279582\n",
      "[3, 120] loss: 0.0003186568203382194\n",
      "[3, 140] loss: 0.00039408174902200697\n",
      "[3, 160] loss: 0.0004300019880756736\n",
      "[3, 180] loss: 0.000309501017909497\n",
      "[3, 200] loss: 0.000342450013384223\n",
      "[3, 220] loss: 0.00033355532120913267\n",
      "[3, 240] loss: 0.00043478361144661903\n",
      "[3, 260] loss: 0.0003155074380338192\n",
      "[3, 280] loss: 0.00038341174367815254\n",
      "[3, 300] loss: 0.0003908046381548047\n",
      "[4, 20] loss: 0.00039288810174912213\n",
      "[4, 40] loss: 0.0003123104148544371\n",
      "[4, 60] loss: 0.0003234248314984143\n",
      "[4, 80] loss: 0.0003328338642604649\n",
      "[4, 100] loss: 0.0004482998149469495\n",
      "[4, 120] loss: 0.00032870705053210256\n",
      "[4, 140] loss: 0.00034893087949603796\n",
      "[4, 160] loss: 0.0003356265379115939\n",
      "[4, 180] loss: 0.0003160933270119131\n",
      "[4, 200] loss: 0.00029402660625055434\n",
      "[4, 220] loss: 0.0003099335436709225\n",
      "[4, 240] loss: 0.0003027447806671262\n",
      "[4, 260] loss: 0.00032260651327669623\n",
      "[4, 280] loss: 0.00028413556795567276\n",
      "[4, 300] loss: 0.00031614455906674264\n",
      "[5, 20] loss: 0.00035698125371709467\n",
      "[5, 40] loss: 0.00035962783824652433\n",
      "[5, 60] loss: 0.00033665429847314955\n",
      "[5, 80] loss: 0.0003431445974856615\n",
      "[5, 100] loss: 0.00027177663566544654\n",
      "[5, 120] loss: 0.00027857368206605316\n",
      "[5, 140] loss: 0.0002559122983366251\n",
      "[5, 160] loss: 0.00030152546148747207\n",
      "[5, 180] loss: 0.00032100496022030713\n",
      "[5, 200] loss: 0.00038233326328918337\n",
      "[5, 220] loss: 0.0003004443091340363\n",
      "[5, 240] loss: 0.0003390420461073518\n",
      "[5, 260] loss: 0.00028539404971525075\n",
      "[5, 280] loss: 0.00029967484064400194\n",
      "[5, 300] loss: 0.00035055270697921515\n",
      "[6, 20] loss: 0.00027001147158443926\n",
      "[6, 40] loss: 0.0002649764323141426\n",
      "[6, 60] loss: 0.00037753166211768985\n",
      "[6, 80] loss: 0.0003561473814770579\n",
      "[6, 100] loss: 0.0003966560699045658\n",
      "[6, 120] loss: 0.00026345075108110907\n",
      "[6, 140] loss: 0.00028319303691387175\n",
      "[6, 160] loss: 0.0003008691184222698\n",
      "[6, 180] loss: 0.0003551455610431731\n",
      "[6, 200] loss: 0.0003513187519274652\n",
      "[6, 220] loss: 0.0002969281952828169\n",
      "[6, 240] loss: 0.000327513060066849\n",
      "[6, 260] loss: 0.00036015675496309994\n",
      "[6, 280] loss: 0.00036830452829599383\n",
      "[6, 300] loss: 0.0003259726911783218\n",
      "[7, 20] loss: 0.000378838142612949\n",
      "[7, 40] loss: 0.0002381823812611401\n",
      "[7, 60] loss: 0.00031350522255524995\n",
      "[7, 80] loss: 0.00027166950120590625\n",
      "[7, 100] loss: 0.0002885721414349973\n",
      "[7, 120] loss: 0.00025968738412484525\n",
      "[7, 140] loss: 0.0003032927182503045\n",
      "[7, 160] loss: 0.00033054859237745406\n",
      "[7, 180] loss: 0.00029163317335769535\n",
      "[7, 200] loss: 0.0003036986845545471\n",
      "[7, 220] loss: 0.0003197384839877486\n",
      "[7, 240] loss: 0.0003770655235275626\n",
      "[7, 260] loss: 0.000266402249224484\n",
      "[7, 280] loss: 0.0002669597575441003\n",
      "[7, 300] loss: 0.0003415959160774946\n",
      "[8, 20] loss: 0.0002812493690289557\n",
      "[8, 40] loss: 0.00024407127499580383\n",
      "[8, 60] loss: 0.00025280855712480845\n",
      "[8, 80] loss: 0.00025688204914331436\n",
      "[8, 100] loss: 0.0002868026541545987\n",
      "[8, 120] loss: 0.00026652555493637917\n",
      "[8, 140] loss: 0.000299726284109056\n",
      "[8, 160] loss: 0.0002638152902945876\n",
      "[8, 180] loss: 0.00027005775645375254\n",
      "[8, 200] loss: 0.0002744315122254193\n",
      "[8, 220] loss: 0.0003792597739957273\n",
      "[8, 240] loss: 0.0004001204194501042\n",
      "[8, 260] loss: 0.00027035990031436084\n",
      "[8, 280] loss: 0.00031507087778300045\n",
      "[8, 300] loss: 0.00035949962493032217\n",
      "[9, 20] loss: 0.0002771684848703444\n",
      "[9, 40] loss: 0.00025113604869693516\n",
      "[9, 60] loss: 0.0002648253501392901\n",
      "[9, 80] loss: 0.0002684646686539054\n",
      "[9, 100] loss: 0.00032012122124433517\n",
      "[9, 120] loss: 0.00027683131210505963\n",
      "[9, 140] loss: 0.0003133476227521896\n",
      "[9, 160] loss: 0.0003152782861143351\n",
      "[9, 180] loss: 0.00025328503735363485\n",
      "[9, 200] loss: 0.000262027520686388\n",
      "[9, 220] loss: 0.00028767365030944346\n",
      "[9, 240] loss: 0.000225468541495502\n",
      "[9, 260] loss: 0.0002768541043624282\n",
      "[9, 280] loss: 0.0003292110851034522\n",
      "[9, 300] loss: 0.0002786221096757799\n",
      "[10, 20] loss: 0.00023581831413321198\n",
      "[10, 40] loss: 0.00025208421354182064\n",
      "[10, 60] loss: 0.000282444367883727\n",
      "[10, 80] loss: 0.00024853599537163974\n",
      "[10, 100] loss: 0.00024135766737163066\n",
      "[10, 120] loss: 0.0002457245937548578\n",
      "[10, 140] loss: 0.0002898115839343518\n",
      "[10, 160] loss: 0.0002771031241863966\n",
      "[10, 180] loss: 0.00038276564702391624\n",
      "[10, 200] loss: 0.0002161643411964178\n",
      "[10, 220] loss: 0.0002815362187102437\n",
      "[10, 240] loss: 0.0002655779160559177\n",
      "[10, 260] loss: 0.0002746260112617165\n",
      "[10, 280] loss: 0.00024475493375211954\n",
      "[10, 300] loss: 0.00029922306025400756\n",
      "[11, 20] loss: 0.00028676445642486216\n",
      "[11, 40] loss: 0.00024027947732247412\n",
      "[11, 60] loss: 0.0002620660699903965\n",
      "[11, 80] loss: 0.00020959561318159103\n",
      "[11, 100] loss: 0.00021661105053499342\n",
      "[11, 120] loss: 0.0002903710976243019\n",
      "[11, 140] loss: 0.000263105517718941\n",
      "[11, 160] loss: 0.0003024236769415438\n",
      "[11, 180] loss: 0.00026093336683698\n",
      "[11, 200] loss: 0.00026064432971179485\n",
      "[11, 220] loss: 0.00032846419792622325\n",
      "[11, 240] loss: 0.000306180811021477\n",
      "[11, 260] loss: 0.00023758808663114906\n",
      "[11, 280] loss: 0.00030422853166237474\n",
      "[11, 300] loss: 0.00032921557081863286\n",
      "[12, 20] loss: 0.0002438952662050724\n",
      "[12, 40] loss: 0.00032863993756473064\n",
      "[12, 60] loss: 0.00027843585796654227\n",
      "[12, 80] loss: 0.00028132428787648676\n",
      "[12, 100] loss: 0.0002809648015536368\n",
      "[12, 120] loss: 0.00025434684520587325\n",
      "[12, 140] loss: 0.0002513734488748014\n",
      "[12, 160] loss: 0.00023274718457832932\n",
      "[12, 180] loss: 0.0002224439731799066\n",
      "[12, 200] loss: 0.00022931562270969152\n",
      "[12, 220] loss: 0.00024211559374816716\n",
      "[12, 240] loss: 0.000261797855142504\n",
      "[12, 260] loss: 0.0002634009642060846\n",
      "[12, 280] loss: 0.00022552388487383722\n",
      "[12, 300] loss: 0.00022416832856833935\n",
      "[13, 20] loss: 0.0001984962379792705\n",
      "[13, 40] loss: 0.00020570181903894992\n",
      "[13, 60] loss: 0.0002126914653927088\n",
      "[13, 80] loss: 0.00022489081881940366\n",
      "[13, 100] loss: 0.00023475174512714147\n",
      "[13, 120] loss: 0.00033188074990175663\n",
      "[13, 140] loss: 0.00030296985432505606\n",
      "[13, 160] loss: 0.00033166809985414147\n",
      "[13, 180] loss: 0.0003207327034324408\n",
      "[13, 200] loss: 0.00023907524347305297\n",
      "[13, 220] loss: 0.00027211285149678587\n",
      "[13, 240] loss: 0.00029981771344318985\n",
      "[13, 260] loss: 0.00022911370219662786\n",
      "[13, 280] loss: 0.00018055156897753478\n",
      "[13, 300] loss: 0.000267807082273066\n",
      "[14, 20] loss: 0.00023576866881921886\n",
      "[14, 40] loss: 0.0002469894108362496\n",
      "[14, 60] loss: 0.0002534584328532219\n",
      "[14, 80] loss: 0.00027403404004871845\n",
      "[14, 100] loss: 0.00020130205107852817\n",
      "[14, 120] loss: 0.00030091689620167014\n",
      "[14, 140] loss: 0.00027254104590974747\n",
      "[14, 160] loss: 0.00023436702182516456\n",
      "[14, 180] loss: 0.0002646776158362627\n",
      "[14, 200] loss: 0.00033665383560582994\n",
      "[14, 220] loss: 0.00022953226487152278\n",
      "[14, 240] loss: 0.00021609490900300444\n",
      "[14, 260] loss: 0.00024325410556048154\n",
      "[14, 280] loss: 0.00021619149716570974\n",
      "[14, 300] loss: 0.0001938688682857901\n",
      "[15, 20] loss: 0.00017085193609818816\n",
      "[15, 40] loss: 0.0001992399264127016\n",
      "[15, 60] loss: 0.00023990682605654\n",
      "[15, 80] loss: 0.0002700977388303727\n",
      "[15, 100] loss: 0.0002625715131871402\n",
      "[15, 120] loss: 0.00023207368748262526\n",
      "[15, 140] loss: 0.00023694213479757308\n",
      "[15, 160] loss: 0.0002588625904172659\n",
      "[15, 180] loss: 0.00024825443024747073\n",
      "[15, 200] loss: 0.0002424063626676798\n",
      "[15, 220] loss: 0.00032883959030732514\n",
      "[15, 240] loss: 0.0002466212355066091\n",
      "[15, 260] loss: 0.00019890114828012884\n",
      "[15, 280] loss: 0.0002951639494858682\n",
      "[15, 300] loss: 0.0002787330900318921\n",
      "[16, 20] loss: 0.00024085545283742248\n",
      "[16, 40] loss: 0.0001835187622345984\n",
      "[16, 60] loss: 0.00019525512238033116\n",
      "[16, 80] loss: 0.00025895989360287785\n",
      "[16, 100] loss: 0.00029483203776180743\n",
      "[16, 120] loss: 0.0002781572621315718\n",
      "[16, 140] loss: 0.00023038475692737848\n",
      "[16, 160] loss: 0.0002773832236416638\n",
      "[16, 180] loss: 0.00020316796679981054\n",
      "[16, 200] loss: 0.00021109768771566451\n",
      "[16, 220] loss: 0.0003355607567355037\n",
      "[16, 240] loss: 0.00021297780878376215\n",
      "[16, 260] loss: 0.00026288654399104415\n",
      "[16, 280] loss: 0.0002747817137278616\n",
      "[16, 300] loss: 0.00023386560822837054\n",
      "[17, 20] loss: 0.00022414843342266977\n",
      "[17, 40] loss: 0.0002464901783969253\n",
      "[17, 60] loss: 0.00019053858611732722\n",
      "[17, 80] loss: 0.00023302246630191802\n",
      "[17, 100] loss: 0.00022219105996191502\n",
      "[17, 120] loss: 0.0002186975146178156\n",
      "[17, 140] loss: 0.0002173856385052204\n",
      "[17, 160] loss: 0.0002098321325611323\n",
      "[17, 180] loss: 0.00022234992543235422\n",
      "[17, 200] loss: 0.00024453043565154074\n",
      "[17, 220] loss: 0.0003185567599721253\n",
      "[17, 240] loss: 0.00026309448620304463\n",
      "[17, 260] loss: 0.00026396385719999673\n",
      "[17, 280] loss: 0.00030514190765097737\n",
      "[17, 300] loss: 0.0002433625445701182\n",
      "[18, 20] loss: 0.0002073740721680224\n",
      "[18, 40] loss: 0.000214357971213758\n",
      "[18, 60] loss: 0.00015302516636438667\n",
      "[18, 80] loss: 0.00023534236499108375\n",
      "[18, 100] loss: 0.00026988897379487755\n",
      "[18, 120] loss: 0.00025237427232787014\n",
      "[18, 140] loss: 0.00021607631188817322\n",
      "[18, 160] loss: 0.00020022854884155095\n",
      "[18, 180] loss: 0.00020143741008359938\n",
      "[18, 200] loss: 0.00021697052335366607\n",
      "[18, 220] loss: 0.00028870357992127535\n",
      "[18, 240] loss: 0.0002983045661821961\n",
      "[18, 260] loss: 0.00028267582505941394\n",
      "[18, 280] loss: 0.0002767616957426071\n",
      "[18, 300] loss: 0.0002771005555987358\n",
      "[19, 20] loss: 0.0001919490322470665\n",
      "[19, 40] loss: 0.00023131681303493679\n",
      "[19, 60] loss: 0.00027122150151990355\n",
      "[19, 80] loss: 0.00019939097994938493\n",
      "[19, 100] loss: 0.00020681471074931323\n",
      "[19, 120] loss: 0.0002154928871896118\n",
      "[19, 140] loss: 0.00027265981771051884\n",
      "[19, 160] loss: 0.00016628242353908718\n",
      "[19, 180] loss: 0.00021327951410785316\n",
      "[19, 200] loss: 0.00022932650474831462\n",
      "[19, 220] loss: 0.00024573295935988426\n",
      "[19, 240] loss: 0.00017905808379873632\n",
      "[19, 260] loss: 0.00017967261117883025\n",
      "[19, 280] loss: 0.0002760724215768278\n",
      "[19, 300] loss: 0.00031827292242087425\n",
      "[20, 20] loss: 0.00020906417467631398\n",
      "[20, 40] loss: 0.0002043724525719881\n",
      "[20, 60] loss: 0.00017302761983592062\n",
      "[20, 80] loss: 0.00020340980915352702\n",
      "[20, 100] loss: 0.0001867917161434889\n",
      "[20, 120] loss: 0.00016531346109695732\n",
      "[20, 140] loss: 0.0002301268361043185\n",
      "[20, 160] loss: 0.00023217360558919607\n",
      "[20, 180] loss: 0.0001787105961702764\n",
      "[20, 200] loss: 0.0002661865530535579\n",
      "[20, 220] loss: 0.0001662421803921461\n",
      "[20, 240] loss: 0.00019701670156791807\n",
      "[20, 260] loss: 0.0002962313764728606\n",
      "[20, 280] loss: 0.00028918355610221624\n",
      "[20, 300] loss: 0.00027231729170307516\n",
      "Finished Reraining\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 24, 24]             156\n",
      "         MaxPool2d-2            [-1, 6, 12, 12]               0\n",
      "            Conv2d-3             [-1, 16, 8, 8]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 4, 4]               0\n",
      "            Linear-5                   [-1, 60]          15,420\n",
      "            Linear-6                   [-1, 20]           1,220\n",
      "            Linear-7                   [-1, 10]             210\n",
      "================================================================\n",
      "Total params: 19,422\n",
      "Trainable params: 19,422\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 0.07\n",
      "Estimated Total Size (MB): 0.12\n",
      "----------------------------------------------------------------\n",
      "Accuracy of the network on the test images: 98.430000 %\n"
     ]
    }
   ],
   "source": [
    "len_1=60\n",
    "len_2=20\n",
    "\n",
    "print(\"Pruning fc1.................\")\n",
    "\n",
    "nodes=defaultdict(list)\n",
    "for j in range(len(net.state_dict()[\"fc1.weight\"])):  #Means j is a node of next layer, L2. Fc1 is connecting L1 and L2 layer.\n",
    "    nodes[j]=net.state_dict()[\"fc1.weight\"][j]\n",
    "\n",
    "# print(len(nodes), \" \", len(nodes[0]))\n",
    "\n",
    "# from math import sqrt\n",
    "distances=[]\n",
    "for i in nodes.keys():\n",
    "    for j in nodes.keys():\n",
    "        if(i!=j and j>i):\n",
    "            distances.append(euclidean_distance(nodes[i], nodes[j]))\n",
    "\n",
    "distances.sort()\n",
    "            \n",
    "print(\"Finding clusters of nodes.................\")\n",
    "setpoints=findsets(len_1, nodes, distances)\n",
    "\n",
    "# print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "temp_weights=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(net.state_dict()[\"fc1.weight\"][0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=net.state_dict()[\"fc1.weight\"][points]\n",
    "    row=row/len(setpoints[key])\n",
    "    temp_weights.append(row)\n",
    "# print(len(temp_weights), temp_weights[0].shape)\n",
    "\n",
    "# print(net.state_dict()[\"fc1.bias\"].shape)\n",
    "temp_bias=torch.zeros(len(temp_weights), dtype=torch.float)\n",
    "i=0\n",
    "for key in setpoints.keys():\n",
    "    for points in setpoints[key]:\n",
    "        temp_bias[i]+=net.state_dict()[\"fc1.bias\"][points]\n",
    "    temp_bias[i]/=len(setpoints[key])\n",
    "    i+=1\n",
    "# print(temp_bias.shape)\n",
    "\n",
    "print(\"Updating fc1.................\")\n",
    "net_1 = changenet(net, \"fc1\", temp_weights, temp_bias)\n",
    "\n",
    "print(net.state_dict()[\"fc1.bias\"].shape, \" -> \", net_1.state_dict()[\"fc1.bias\"].shape)\n",
    "print(net.state_dict()[\"fc1.weight\"].shape, \" -> \", net_1.state_dict()[\"fc1.weight\"].shape)\n",
    "\n",
    "net=copy.deepcopy(net_1)\n",
    "# print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "# print(net.state_dict()[\"fc1.bias\"].shape)\n",
    "\n",
    "#just to check if the copy has been done correctly\n",
    "# print(temp_weights[0],\"\\n\\n\",net.state_dict()[\"fc1.weight\"][0])    \n",
    "\n",
    "\n",
    "### Now, we have to change FC2 accordingly:\n",
    "# print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "print(\"Adjusting fc2 accordingly.................\")\n",
    "mat=net.state_dict()[\"fc2.weight\"].t()\n",
    "# print(mat.shape)\n",
    "\n",
    "temp_weight=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(mat[0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=mat[points]\n",
    "    temp_weight.append(row)\n",
    "# print(len(temp_weight), temp_weight[0].shape)\n",
    "\n",
    "newmat=torch.stack(temp_weight, dim=0)\n",
    "newmat=newmat.t()\n",
    "# print(newmat.shape)\n",
    "\n",
    "# print(net.state_dict()[\"fc2.bias\"].shape)\n",
    "\n",
    "net_2 = changenet(net, \"fc2\", newmat, net.state_dict()[\"fc2.bias\"])\n",
    "net=copy.deepcopy(net_2)\n",
    "\n",
    "print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "print(net.state_dict()[\"fc3.weight\"].shape)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, len(net.state_dict()[\"fc1.weight\"]))\n",
    "        self.fc2 = nn.Linear(len(net.state_dict()[\"fc2.weight\"][0]), len(net.state_dict()[\"fc2.weight\"]))\n",
    "        self.fc3 = nn.Linear(len(net.state_dict()[\"fc3.weight\"][0]), 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    \n",
    "from torchsummary import summary\n",
    "device=torch.device(\"cpu\")\n",
    "model=Net().to(device)\n",
    "summary(model, input_size=(1, 28, 28), device=\"cpu\")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "\n",
    "print(\"Pruning fc2.................\")\n",
    "from collections import defaultdict\n",
    "nodes=defaultdict(list)\n",
    "for j in range(len(net.state_dict()[\"fc2.weight\"])):  #Means j is a node of next layer, L2.\n",
    "    nodes[j]=net.state_dict()[\"fc2.weight\"][j]\n",
    "\n",
    "# print(len(nodes), \" \", len(nodes[0]))\n",
    "\n",
    "\n",
    "distances=[]\n",
    "for i in nodes.keys():\n",
    "    for j in nodes.keys():\n",
    "        if(i!=j and j>i):\n",
    "            distances.append(euclidean_distance(nodes[i], nodes[j]))\n",
    "            \n",
    "distances.sort()\n",
    "# print(len(distances))\n",
    "\n",
    "print(\"Finding clusters of nodes.................\")\n",
    "setpoints=findsets(len_2, nodes, distances)\n",
    "\n",
    "# print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "temp_weight=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(net.state_dict()[\"fc2.weight\"][0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=net.state_dict()[\"fc2.weight\"][points]\n",
    "    row=row/len(setpoints[key])\n",
    "    temp_weight.append(row)\n",
    "# print(len(temp_weight), temp_weight[0].shape)\n",
    "\n",
    "# print(net.state_dict()[\"fc2.bias\"].shape)\n",
    "temp_bias=torch.zeros(len(temp_weight), dtype=torch.float)\n",
    "i=0\n",
    "for key in setpoints.keys():\n",
    "    for points in setpoints[key]:\n",
    "        temp_bias[i]+=net.state_dict()[\"fc2.bias\"][points]\n",
    "    temp_bias[i]/=len(setpoints[key])\n",
    "    i+=1\n",
    "# print(temp_bias.shape)\n",
    "\n",
    "print(\"Updating fc2.................\")\n",
    "net_3 = changenet(net, \"fc2\", temp_weight, temp_bias)\n",
    "net=copy.deepcopy(net_3)\n",
    "\n",
    "mat=net.state_dict()[\"fc3.weight\"].t()\n",
    "# print(mat.shape)\n",
    "\n",
    "temp_weight=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(mat[0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=mat[points]\n",
    "    temp_weight.append(row)\n",
    "# print(len(temp_weight), temp_weight[0].shape)\n",
    "\n",
    "newmat=torch.stack(temp_weight, dim=0)\n",
    "newmat=newmat.t()\n",
    "# print(newmat.shape)\n",
    "\n",
    "print(\"Adjusting fc3 accordingly.................\")\n",
    "net_4 = changenet(net, \"fc3\", newmat, net.state_dict()[\"fc3.bias\"])\n",
    "net=copy.deepcopy(net_4)\n",
    "\n",
    "print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "print(net.state_dict()[\"fc3.weight\"].shape)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, len(net.state_dict()[\"fc1.weight\"]))\n",
    "        self.fc2 = nn.Linear(len(net.state_dict()[\"fc2.weight\"][0]), len(net.state_dict()[\"fc2.weight\"]))\n",
    "        self.fc3 = nn.Linear(len(net.state_dict()[\"fc3.weight\"][0]), 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "i=0\n",
    "for parameter in net.parameters():\n",
    "    i+=1\n",
    "    if(i<5):\n",
    "        parameter.requires_grad=False\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.1307,), (0.3081,))])\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=200,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=200,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('0', '1', '2', '3',\n",
    "           '4', '5', '6', '7', '8', '9')\n",
    "\n",
    "# import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        # print(inputs.shape)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    # print every 2000 mini-batches\n",
    "            print(\"[{}, {}] loss: {}\".format\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Reraining')\n",
    "\n",
    "\n",
    "from torchsummary import summary\n",
    "device=torch.device(\"cpu\")\n",
    "model=Net().to(device)\n",
    "summary(model, input_size=(1, 28, 28), device=\"cpu\")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"LeNET_60_20_MNIST_Model_My_Exiperiment_4_Fine_Tuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning fc1.................\n",
      "Finding clusters of nodes.................\n",
      "desired len= 30\n",
      "cut_off= 1.0944377371834768\n",
      "iteration= 1  length= 11  difference= -19  change rate= 0.0010944377371834768\n",
      "cut_off= 1.0736434201769907\n",
      "iteration= 2  length= 13  difference= -17  change rate= 0.0010944377371834768\n",
      "cut_off= 1.0550379786448716\n",
      "iteration= 3  length= 16  difference= -14  change rate= 0.0010944377371834768\n",
      "cut_off= 1.039715850324303\n",
      "iteration= 4  length= 17  difference= -13  change rate= 0.0010944377371834768\n",
      "cut_off= 1.0254881597409178\n",
      "iteration= 5  length= 20  difference= -10  change rate= 0.0010944377371834768\n",
      "cut_off= 1.014543782369083\n",
      "iteration= 6  length= 21  difference= -9  change rate= 0.0010944377371834768\n",
      "cut_off= 1.0046938427344319\n",
      "iteration= 7  length= 25  difference= -5  change rate= 0.0010944377371834768\n",
      "cut_off= 0.9992216540485145\n",
      "iteration= 8  length= 25  difference= -5  change rate= 0.0010944377371834768\n",
      "cut_off= 0.9937494653625971\n",
      "iteration= 9  length= 28  difference= -2  change rate= 0.0010944377371834768\n",
      "cut_off= 0.9915605898882301\n",
      "iteration= 10  length= 28  difference= -2  change rate= 0.0010944377371834768\n",
      "cut_off= 0.9893717144138632\n",
      "iteration= 11  length= 29  difference= -1  change rate= 0.0010944377371834768\n",
      "cut_off= 0.9882772766766798\n",
      "iteration= 12  length= 28  difference= -2  change rate= 0.0010944377371834768\n",
      "cut_off= 0.9860884012023128\n",
      "iteration= 13  length= 30  difference= -2  change rate= 0.0010944377371834768\n",
      "Updating fc1.................\n",
      "torch.Size([60])  ->  torch.Size([30])\n",
      "torch.Size([60, 256])  ->  torch.Size([30, 256])\n",
      "Adjusting fc2 accordingly.................\n",
      "torch.Size([30, 256])\n",
      "torch.Size([20, 30])\n",
      "torch.Size([10, 20])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 24, 24]             156\n",
      "         MaxPool2d-2            [-1, 6, 12, 12]               0\n",
      "            Conv2d-3             [-1, 16, 8, 8]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 4, 4]               0\n",
      "            Linear-5                   [-1, 30]           7,710\n",
      "            Linear-6                   [-1, 20]             620\n",
      "            Linear-7                   [-1, 10]             210\n",
      "================================================================\n",
      "Total params: 11,112\n",
      "Trainable params: 11,112\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 0.04\n",
      "Estimated Total Size (MB): 0.09\n",
      "----------------------------------------------------------------\n",
      "Accuracy of the network on the test images: 93.250000 %\n",
      "Pruning fc2.................\n",
      "Finding clusters of nodes.................\n",
      "desired len= 10\n",
      "cut_off= 1.4446461559125288\n",
      "iteration= 1  length= 4  difference= -6  change rate= 0.0014446461559125287\n",
      "cut_off= 1.4359782789770537\n",
      "iteration= 2  length= 4  difference= -6  change rate= 0.0014446461559125287\n",
      "cut_off= 1.4273104020415786\n",
      "iteration= 3  length= 4  difference= -6  change rate= 0.0014446461559125287\n",
      "cut_off= 1.4186425251061034\n",
      "iteration= 4  length= 4  difference= -6  change rate= 0.0014446461559125287\n",
      "cut_off= 1.4099746481706283\n",
      "iteration= 5  length= 4  difference= -6  change rate= 0.0014446461559125287\n",
      "cut_off= 1.4013067712351532\n",
      "iteration= 6  length= 4  difference= -6  change rate= 0.0014446461559125287\n",
      "cut_off= 1.3926388942996781\n",
      "iteration= 7  length= 4  difference= -6  change rate= 0.0014446461559125287\n",
      "cut_off= 1.383971017364203\n",
      "iteration= 8  length= 4  difference= -6  change rate= 0.0014446461559125287\n",
      "cut_off= 1.375303140428728\n",
      "iteration= 9  length= 4  difference= -6  change rate= 0.0014446461559125287\n",
      "cut_off= 1.3666352634932528\n",
      "iteration= 10  length= 4  difference= -6  change rate= 0.0014446461559125287\n",
      "cut_off= 1.3579673865577777\n",
      "iteration= 11  length= 4  difference= -6  change rate= 0.0014446461559125287\n",
      "cut_off= 1.3492995096223026\n",
      "iteration= 12  length= 4  difference= -6  change rate= 0.0014446461559125287\n",
      "cut_off= 1.3406316326868275\n",
      "iteration= 13  length= 5  difference= -5  change rate= 0.0014446461559125287\n",
      "cut_off= 1.333408401907265\n",
      "iteration= 14  length= 5  difference= -5  change rate= 0.0014446461559125287\n",
      "cut_off= 1.3261851711277024\n",
      "iteration= 15  length= 5  difference= -5  change rate= 0.0014446461559125287\n",
      "cut_off= 1.3189619403481398\n",
      "iteration= 16  length= 5  difference= -5  change rate= 0.0014446461559125287\n",
      "cut_off= 1.3117387095685773\n",
      "iteration= 17  length= 6  difference= -4  change rate= 0.0014446461559125287\n",
      "cut_off= 1.305960124944927\n",
      "iteration= 18  length= 6  difference= -4  change rate= 0.0014446461559125287\n",
      "cut_off= 1.3001815403212769\n",
      "iteration= 19  length= 6  difference= -4  change rate= 0.0014446461559125287\n",
      "cut_off= 1.2944029556976266\n",
      "iteration= 20  length= 6  difference= -4  change rate= 0.0014446461559125287\n",
      "cut_off= 1.2886243710739764\n",
      "iteration= 21  length= 6  difference= -4  change rate= 0.0014446461559125287\n",
      "cut_off= 1.2828457864503262\n",
      "iteration= 22  length= 6  difference= -4  change rate= 0.0014446461559125287\n",
      "cut_off= 1.277067201826676\n",
      "iteration= 23  length= 6  difference= -4  change rate= 0.0014446461559125287\n",
      "cut_off= 1.2712886172030258\n",
      "iteration= 24  length= 6  difference= -4  change rate= 0.0014446461559125287\n",
      "cut_off= 1.2655100325793756\n",
      "iteration= 25  length= 6  difference= -4  change rate= 0.0014446461559125287\n",
      "cut_off= 1.2597314479557253\n",
      "iteration= 26  length= 6  difference= -4  change rate= 0.0014446461559125287\n",
      "cut_off= 1.2539528633320751\n",
      "iteration= 27  length= 6  difference= -4  change rate= 0.0014446461559125287\n",
      "cut_off= 1.248174278708425\n",
      "iteration= 28  length= 6  difference= -4  change rate= 0.0014446461559125287\n",
      "cut_off= 1.2423956940847747\n",
      "iteration= 29  length= 6  difference= -4  change rate= 0.0014446461559125287\n",
      "cut_off= 1.2366171094611245\n",
      "iteration= 30  length= 6  difference= -4  change rate= 0.0014446461559125287\n",
      "cut_off= 1.2308385248374742\n",
      "iteration= 31  length= 6  difference= -4  change rate= 0.0014446461559125287\n",
      "cut_off= 1.225059940213824\n",
      "iteration= 32  length= 6  difference= -4  change rate= 0.0014446461559125287\n",
      "cut_off= 1.2192813555901738\n",
      "iteration= 33  length= 6  difference= -4  change rate= 0.0014446461559125287\n",
      "cut_off= 1.2135027709665236\n",
      "iteration= 34  length= 6  difference= -4  change rate= 0.0014446461559125287\n",
      "cut_off= 1.2077241863428734\n",
      "iteration= 35  length= 6  difference= -4  change rate= 0.0014446461559125287\n",
      "cut_off= 1.2019456017192232\n",
      "iteration= 36  length= 6  difference= -4  change rate= 0.0014446461559125287\n",
      "cut_off= 1.196167017095573\n",
      "iteration= 37  length= 7  difference= -3  change rate= 0.0014446461559125287\n",
      "cut_off= 1.1918330786278353\n",
      "iteration= 38  length= 7  difference= -3  change rate= 0.0014446461559125287\n",
      "cut_off= 1.1874991401600976\n",
      "iteration= 39  length= 7  difference= -3  change rate= 0.0014446461559125287\n",
      "cut_off= 1.18316520169236\n",
      "iteration= 40  length= 7  difference= -3  change rate= 0.0014446461559125287\n",
      "cut_off= 1.1788312632246223\n",
      "iteration= 41  length= 7  difference= -3  change rate= 0.0014446461559125287\n",
      "cut_off= 1.1744973247568846\n",
      "iteration= 42  length= 7  difference= -3  change rate= 0.0014446461559125287\n",
      "cut_off= 1.170163386289147\n",
      "iteration= 43  length= 7  difference= -3  change rate= 0.0014446461559125287\n",
      "cut_off= 1.1658294478214093\n",
      "iteration= 44  length= 7  difference= -3  change rate= 0.0014446461559125287\n",
      "cut_off= 1.1614955093536716\n",
      "iteration= 45  length= 7  difference= -3  change rate= 0.0014446461559125287\n",
      "cut_off= 1.157161570885934\n",
      "iteration= 46  length= 7  difference= -3  change rate= 0.0014446461559125287\n",
      "cut_off= 1.1528276324181963\n",
      "iteration= 47  length= 7  difference= -3  change rate= 0.0014446461559125287\n",
      "cut_off= 1.1484936939504586\n",
      "iteration= 48  length= 7  difference= -3  change rate= 0.0014446461559125287\n",
      "cut_off= 1.144159755482721\n",
      "iteration= 49  length= 7  difference= -3  change rate= 0.0014446461559125287\n",
      "cut_off= 1.1398258170149833\n",
      "iteration= 50  length= 7  difference= -3  change rate= 0.0014446461559125287\n",
      "cut_off= 1.1354918785472456\n",
      "iteration= 51  length= 7  difference= -3  change rate= 0.0014446461559125287\n",
      "cut_off= 1.131157940079508\n",
      "iteration= 52  length= 8  difference= -2  change rate= 0.0014446461559125287\n",
      "cut_off= 1.1282686477676829\n",
      "iteration= 53  length= 8  difference= -2  change rate= 0.0014446461559125287\n",
      "cut_off= 1.1253793554558578\n",
      "iteration= 54  length= 8  difference= -2  change rate= 0.0014446461559125287\n",
      "cut_off= 1.1224900631440327\n",
      "iteration= 55  length= 8  difference= -2  change rate= 0.0014446461559125287\n",
      "cut_off= 1.1196007708322075\n",
      "iteration= 56  length= 8  difference= -2  change rate= 0.0014446461559125287\n",
      "cut_off= 1.1167114785203824\n",
      "iteration= 57  length= 8  difference= -2  change rate= 0.0014446461559125287\n",
      "cut_off= 1.1138221862085573\n",
      "iteration= 58  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.1123775400526448\n",
      "iteration= 59  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.1109328938967322\n",
      "iteration= 60  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.1094882477408197\n",
      "iteration= 61  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.1080436015849071\n",
      "iteration= 62  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.1065989554289946\n",
      "iteration= 63  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.105154309273082\n",
      "iteration= 64  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.1037096631171694\n",
      "iteration= 65  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.102265016961257\n",
      "iteration= 66  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.1008203708053443\n",
      "iteration= 67  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0993757246494318\n",
      "iteration= 68  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0979310784935192\n",
      "iteration= 69  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0964864323376067\n",
      "iteration= 70  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0950417861816941\n",
      "iteration= 71  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0935971400257816\n",
      "iteration= 72  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.092152493869869\n",
      "iteration= 73  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0907078477139565\n",
      "iteration= 74  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.089263201558044\n",
      "iteration= 75  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0878185554021313\n",
      "iteration= 76  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0863739092462188\n",
      "iteration= 77  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0849292630903062\n",
      "iteration= 78  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0834846169343937\n",
      "iteration= 79  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0820399707784811\n",
      "iteration= 80  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0805953246225686\n",
      "iteration= 81  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.079150678466656\n",
      "iteration= 82  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0777060323107435\n",
      "iteration= 83  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.076261386154831\n",
      "iteration= 84  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0748167399989184\n",
      "iteration= 85  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0733720938430058\n",
      "iteration= 86  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0719274476870932\n",
      "iteration= 87  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0704828015311807\n",
      "iteration= 88  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0690381553752681\n",
      "iteration= 89  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0675935092193556\n",
      "iteration= 90  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.066148863063443\n",
      "iteration= 91  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0647042169075305\n",
      "iteration= 92  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.063259570751618\n",
      "iteration= 93  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0618149245957054\n",
      "iteration= 94  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0603702784397928\n",
      "iteration= 95  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0589256322838803\n",
      "iteration= 96  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0574809861279677\n",
      "iteration= 97  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0560363399720551\n",
      "iteration= 98  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0545916938161426\n",
      "iteration= 99  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.05314704766023\n",
      "iteration= 100  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0517024015043175\n",
      "iteration= 101  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.050257755348405\n",
      "iteration= 102  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0488131091924924\n",
      "iteration= 103  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0473684630365798\n",
      "iteration= 104  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0459238168806673\n",
      "iteration= 105  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0444791707247547\n",
      "iteration= 106  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0430345245688422\n",
      "iteration= 107  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0415898784129296\n",
      "iteration= 108  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.040145232257017\n",
      "iteration= 109  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0387005861011045\n",
      "iteration= 110  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.037255939945192\n",
      "iteration= 111  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0358112937892794\n",
      "iteration= 112  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0343666476333668\n",
      "iteration= 113  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0329220014774543\n",
      "iteration= 114  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0314773553215417\n",
      "iteration= 115  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0300327091656292\n",
      "iteration= 116  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0285880630097166\n",
      "iteration= 117  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.027143416853804\n",
      "iteration= 118  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0256987706978915\n",
      "iteration= 119  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.024254124541979\n",
      "iteration= 120  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0228094783860664\n",
      "iteration= 121  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0213648322301538\n",
      "iteration= 122  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0199201860742413\n",
      "iteration= 123  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0184755399183287\n",
      "iteration= 124  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0170308937624162\n",
      "iteration= 125  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0155862476065036\n",
      "iteration= 126  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.014141601450591\n",
      "iteration= 127  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0126969552946785\n",
      "iteration= 128  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.011252309138766\n",
      "iteration= 129  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0098076629828534\n",
      "iteration= 130  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0083630168269409\n",
      "iteration= 131  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0069183706710283\n",
      "iteration= 132  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0054737245151157\n",
      "iteration= 133  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0040290783592032\n",
      "iteration= 134  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.0025844322032906\n",
      "iteration= 135  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 1.001139786047378\n",
      "iteration= 136  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 0.9996951398914655\n",
      "iteration= 137  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 0.998250493735553\n",
      "iteration= 138  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 0.9968058475796404\n",
      "iteration= 139  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 0.9953612014237279\n",
      "iteration= 140  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 0.9939165552678153\n",
      "iteration= 141  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 0.9924719091119028\n",
      "iteration= 142  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 0.9910272629559902\n",
      "iteration= 143  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 0.9895826168000776\n",
      "iteration= 144  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 0.9881379706441651\n",
      "iteration= 145  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 0.9866933244882525\n",
      "iteration= 146  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 0.98524867833234\n",
      "iteration= 147  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 0.9838040321764274\n",
      "iteration= 148  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 0.9823593860205149\n",
      "iteration= 149  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 0.9809147398646023\n",
      "iteration= 150  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 0.9794700937086898\n",
      "iteration= 151  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 0.9780254475527772\n",
      "iteration= 152  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 0.9765808013968647\n",
      "iteration= 153  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 0.9751361552409521\n",
      "iteration= 154  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 0.9736915090850395\n",
      "iteration= 155  length= 9  difference= -1  change rate= 0.0014446461559125287\n",
      "cut_off= 0.972246862929127\n",
      "iteration= 156  length= 10  difference= -1  change rate= 0.0014446461559125287\n",
      "Updating fc2.................\n",
      "Adjusting fc3 accordingly.................\n",
      "torch.Size([30, 256])\n",
      "torch.Size([10, 30])\n",
      "torch.Size([10, 10])\n",
      "Accuracy of the network on the test images: 57.120000 %\n",
      "[1, 20] loss: 0.005856565043330193\n",
      "[1, 40] loss: 0.002781614974141121\n",
      "[1, 60] loss: 0.002124854385852814\n",
      "[1, 80] loss: 0.0016841632053256035\n",
      "[1, 100] loss: 0.0014904014356434344\n",
      "[1, 120] loss: 0.001395848996937275\n",
      "[1, 140] loss: 0.0013020273633301258\n",
      "[1, 160] loss: 0.0011429136395454407\n",
      "[1, 180] loss: 0.0011217552982270718\n",
      "[1, 200] loss: 0.001135570239275694\n",
      "[1, 220] loss: 0.0011337504126131535\n",
      "[1, 240] loss: 0.0011912586055696011\n",
      "[1, 260] loss: 0.0011288994196802379\n",
      "[1, 280] loss: 0.001002699164673686\n",
      "[1, 300] loss: 0.0011462556887418033\n",
      "[2, 20] loss: 0.0010371194127947092\n",
      "[2, 40] loss: 0.0008217153325676918\n",
      "[2, 60] loss: 0.0008427839744836092\n",
      "[2, 80] loss: 0.000789792126044631\n",
      "[2, 100] loss: 0.0009814795069396495\n",
      "[2, 120] loss: 0.0010598712861537934\n",
      "[2, 140] loss: 0.0010120077673345805\n",
      "[2, 160] loss: 0.0008603875022381544\n",
      "[2, 180] loss: 0.0009790794309228659\n",
      "[2, 200] loss: 0.0008944168481975794\n",
      "[2, 220] loss: 0.000947531871497631\n",
      "[2, 240] loss: 0.0008263748604804277\n",
      "[2, 260] loss: 0.0009586663004010915\n",
      "[2, 280] loss: 0.000983086047694087\n",
      "[2, 300] loss: 0.0007353292740881443\n",
      "[3, 20] loss: 0.0007501218225806952\n",
      "[3, 40] loss: 0.0008306550644338131\n",
      "[3, 60] loss: 0.0007083119852468371\n",
      "[3, 80] loss: 0.0007566367629915475\n",
      "[3, 100] loss: 0.000835421409457922\n",
      "[3, 120] loss: 0.0009964312240481376\n",
      "[3, 140] loss: 0.0008653255514800549\n",
      "[3, 160] loss: 0.0007684598173946142\n",
      "[3, 180] loss: 0.0007967867664992809\n",
      "[3, 200] loss: 0.0007523395735770464\n",
      "[3, 220] loss: 0.0007059886939823627\n",
      "[3, 240] loss: 0.000765483072027564\n",
      "[3, 260] loss: 0.0007022395953536033\n",
      "[3, 280] loss: 0.0007506444025784731\n",
      "[3, 300] loss: 0.0008772816397249699\n",
      "[4, 20] loss: 0.0006721228454262019\n",
      "[4, 40] loss: 0.0006793227400630713\n",
      "[4, 60] loss: 0.0006631712317466736\n",
      "[4, 80] loss: 0.0007502019852399826\n",
      "[4, 100] loss: 0.0007073146607726813\n",
      "[4, 120] loss: 0.0008039288353174925\n",
      "[4, 140] loss: 0.0007654463443905115\n",
      "[4, 160] loss: 0.0006880634631961584\n",
      "[4, 180] loss: 0.0007039821399375797\n",
      "[4, 200] loss: 0.0006229526353999972\n",
      "[4, 220] loss: 0.0007710055988281965\n",
      "[4, 240] loss: 0.0006745570423081518\n",
      "[4, 260] loss: 0.0007483474221080541\n",
      "[4, 280] loss: 0.0006947063338011504\n",
      "[4, 300] loss: 0.0007068724706768989\n",
      "[5, 20] loss: 0.0006373819848522543\n",
      "[5, 40] loss: 0.000563223890028894\n",
      "[5, 60] loss: 0.0005639655310660601\n",
      "[5, 80] loss: 0.0006544042080640792\n",
      "[5, 100] loss: 0.0006981788976117969\n",
      "[5, 120] loss: 0.0006970466040074825\n",
      "[5, 140] loss: 0.000697666822001338\n",
      "[5, 160] loss: 0.0007061263285577297\n",
      "[5, 180] loss: 0.000724681703839451\n",
      "[5, 200] loss: 0.0006492658033967018\n",
      "[5, 220] loss: 0.0006414374839514494\n",
      "[5, 240] loss: 0.0007456790991127491\n",
      "[5, 260] loss: 0.000688927854411304\n",
      "[5, 280] loss: 0.0008195400815457106\n",
      "[5, 300] loss: 0.0007186373192816973\n",
      "[6, 20] loss: 0.0006233822684735059\n",
      "[6, 40] loss: 0.0005914342105388642\n",
      "[6, 60] loss: 0.0005879003601148724\n",
      "[6, 80] loss: 0.0006649676077067852\n",
      "[6, 100] loss: 0.0007419812101870776\n",
      "[6, 120] loss: 0.0006296754544600845\n",
      "[6, 140] loss: 0.0006165617667138576\n",
      "[6, 160] loss: 0.0007007953403517604\n",
      "[6, 180] loss: 0.0007311186036095023\n",
      "[6, 200] loss: 0.0006405890667811037\n",
      "[6, 220] loss: 0.0007256016973406077\n",
      "[6, 240] loss: 0.0006938253752887249\n",
      "[6, 260] loss: 0.0005787676889449358\n",
      "[6, 280] loss: 0.0006124552488327026\n",
      "[6, 300] loss: 0.0005309330550953746\n",
      "[7, 20] loss: 0.0005726736951619386\n",
      "[7, 40] loss: 0.0005817259075120092\n",
      "[7, 60] loss: 0.0005930488863959909\n",
      "[7, 80] loss: 0.0005001152055338025\n",
      "[7, 100] loss: 0.0006563928266987204\n",
      "[7, 120] loss: 0.0006378664337098599\n",
      "[7, 140] loss: 0.0006085341973230242\n",
      "[7, 160] loss: 0.0005652457177639008\n",
      "[7, 180] loss: 0.0006229220796376467\n",
      "[7, 200] loss: 0.0006023628711700439\n",
      "[7, 220] loss: 0.0005751649541780353\n",
      "[7, 240] loss: 0.0005784765565767884\n",
      "[7, 260] loss: 0.0007792180180549622\n",
      "[7, 280] loss: 0.0006849881689995527\n",
      "[7, 300] loss: 0.0005417330153286457\n",
      "[8, 20] loss: 0.0006152497930452228\n",
      "[8, 40] loss: 0.0005598647706210613\n",
      "[8, 60] loss: 0.0006296793613582849\n",
      "[8, 80] loss: 0.0006080539021641016\n",
      "[8, 100] loss: 0.0006077424064278602\n",
      "[8, 120] loss: 0.0006018875697627663\n",
      "[8, 140] loss: 0.0005298776682466269\n",
      "[8, 160] loss: 0.00055127555411309\n",
      "[8, 180] loss: 0.0006248567644506692\n",
      "[8, 200] loss: 0.000582515150308609\n",
      "[8, 220] loss: 0.0004545573089271784\n",
      "[8, 240] loss: 0.0005177792590111494\n",
      "[8, 260] loss: 0.00047662285156548025\n",
      "[8, 280] loss: 0.0005338522223755718\n",
      "[8, 300] loss: 0.000692854167893529\n",
      "[9, 20] loss: 0.0006554151764139533\n",
      "[9, 40] loss: 0.0006201374400407076\n",
      "[9, 60] loss: 0.0005108086434192956\n",
      "[9, 80] loss: 0.0004925247235223651\n",
      "[9, 100] loss: 0.0005215610982850194\n",
      "[9, 120] loss: 0.0005121290730312467\n",
      "[9, 140] loss: 0.000587182586081326\n",
      "[9, 160] loss: 0.0005968269472941757\n",
      "[9, 180] loss: 0.0006090665953233838\n",
      "[9, 200] loss: 0.000596891232766211\n",
      "[9, 220] loss: 0.0005460746278986335\n",
      "[9, 240] loss: 0.000586396056227386\n",
      "[9, 260] loss: 0.0006344071128405631\n",
      "[9, 280] loss: 0.000620110746473074\n",
      "[9, 300] loss: 0.000580498862080276\n",
      "[10, 20] loss: 0.0005855492539703846\n",
      "[10, 40] loss: 0.0005259342398494482\n",
      "[10, 60] loss: 0.0006280467147007585\n",
      "[10, 80] loss: 0.0005823922520503402\n",
      "[10, 100] loss: 0.0006514915386214852\n",
      "[10, 120] loss: 0.0005610181060619652\n",
      "[10, 140] loss: 0.0005011426396667958\n",
      "[10, 160] loss: 0.0004988849498331547\n",
      "[10, 180] loss: 0.00040881712920963763\n",
      "[10, 200] loss: 0.0005788582311943173\n",
      "[10, 220] loss: 0.0005353955226019024\n",
      "[10, 240] loss: 0.0005168166952207685\n",
      "[10, 260] loss: 0.00041253833565860985\n",
      "[10, 280] loss: 0.0005404350720345974\n",
      "[10, 300] loss: 0.0005683932360261678\n",
      "[11, 20] loss: 0.0005810859892517328\n",
      "[11, 40] loss: 0.0004303233679383993\n",
      "[11, 60] loss: 0.0003974838275462389\n",
      "[11, 80] loss: 0.00045429548434913156\n",
      "[11, 100] loss: 0.0005085584223270416\n",
      "[11, 120] loss: 0.0005737806637771428\n",
      "[11, 140] loss: 0.00042895623482763767\n",
      "[11, 160] loss: 0.000499789847061038\n",
      "[11, 180] loss: 0.0005647386172786355\n",
      "[11, 200] loss: 0.0005826771436259151\n",
      "[11, 220] loss: 0.0005121755031868815\n",
      "[11, 240] loss: 0.0005210846522822976\n",
      "[11, 260] loss: 0.0006297287214547396\n",
      "[11, 280] loss: 0.0005694548189640045\n",
      "[11, 300] loss: 0.0006159013165161014\n",
      "[12, 20] loss: 0.0005902807395905256\n",
      "[12, 40] loss: 0.0004969063019379974\n",
      "[12, 60] loss: 0.0004539162749424577\n",
      "[12, 80] loss: 0.0004883111314848065\n",
      "[12, 100] loss: 0.0004973504147492349\n",
      "[12, 120] loss: 0.0004903284045867621\n",
      "[12, 140] loss: 0.0005697660194709897\n",
      "[12, 160] loss: 0.0005203825328499079\n",
      "[12, 180] loss: 0.0005464630704373121\n",
      "[12, 200] loss: 0.0005026597762480378\n",
      "[12, 220] loss: 0.0004856838947162032\n",
      "[12, 240] loss: 0.0005616064607165754\n",
      "[12, 260] loss: 0.0005557831609621644\n",
      "[12, 280] loss: 0.0004790934626944363\n",
      "[12, 300] loss: 0.0005042369440197944\n",
      "[13, 20] loss: 0.0004479053067043424\n",
      "[13, 40] loss: 0.0005218348549678922\n",
      "[13, 60] loss: 0.0005785824880003929\n",
      "[13, 80] loss: 0.00040525084640830755\n",
      "[13, 100] loss: 0.0004279321422800422\n",
      "[13, 120] loss: 0.0004334846674464643\n",
      "[13, 140] loss: 0.00047732855007052424\n",
      "[13, 160] loss: 0.0004747577081434429\n",
      "[13, 180] loss: 0.0005499582896009087\n",
      "[13, 200] loss: 0.0003688061218708754\n",
      "[13, 220] loss: 0.0004130055978894234\n",
      "[13, 240] loss: 0.00048382233362644913\n",
      "[13, 260] loss: 0.0005462988922372461\n",
      "[13, 280] loss: 0.0006100609069690108\n",
      "[13, 300] loss: 0.000547646944411099\n",
      "[14, 20] loss: 0.00043362950906157495\n",
      "[14, 40] loss: 0.00045542279677465556\n",
      "[14, 60] loss: 0.00047020179219543935\n",
      "[14, 80] loss: 0.0005537804430350661\n",
      "[14, 100] loss: 0.0005486276298761368\n",
      "[14, 120] loss: 0.0006424488890916109\n",
      "[14, 140] loss: 0.000647826299071312\n",
      "[14, 160] loss: 0.0005005034692585469\n",
      "[14, 180] loss: 0.0003769818926230073\n",
      "[14, 200] loss: 0.0005205787308514118\n",
      "[14, 220] loss: 0.0004870468326844275\n",
      "[14, 240] loss: 0.0004558428740128875\n",
      "[14, 260] loss: 0.0004259523572400212\n",
      "[14, 280] loss: 0.0005297709992155433\n",
      "[14, 300] loss: 0.0005198293114081025\n",
      "[15, 20] loss: 0.0004487761124037206\n",
      "[15, 40] loss: 0.0004834189065732062\n",
      "[15, 60] loss: 0.00041394970659166576\n",
      "[15, 80] loss: 0.0004354262219276279\n",
      "[15, 100] loss: 0.0005642794668674469\n",
      "[15, 120] loss: 0.00042823322676122186\n",
      "[15, 140] loss: 0.0003716364521533251\n",
      "[15, 160] loss: 0.00038572801323607565\n",
      "[15, 180] loss: 0.00048161078989505767\n",
      "[15, 200] loss: 0.00044718909729272126\n",
      "[15, 220] loss: 0.0004579746890813112\n",
      "[15, 240] loss: 0.0005145237119868397\n",
      "[15, 260] loss: 0.0005356028266251087\n",
      "[15, 280] loss: 0.0005032608015462756\n",
      "[15, 300] loss: 0.00056937803234905\n",
      "[16, 20] loss: 0.00046753433672711253\n",
      "[16, 40] loss: 0.00038828226015903054\n",
      "[16, 60] loss: 0.00040792819019407035\n",
      "[16, 80] loss: 0.00045431561022996904\n",
      "[16, 100] loss: 0.0004875847743824124\n",
      "[16, 120] loss: 0.0004113495941273868\n",
      "[16, 140] loss: 0.00044186872243881227\n",
      "[16, 160] loss: 0.0006069234916940331\n",
      "[16, 180] loss: 0.0005051446729339659\n",
      "[16, 200] loss: 0.00045001630764454604\n",
      "[16, 220] loss: 0.00044127839989960196\n",
      "[16, 240] loss: 0.0004086784226819873\n",
      "[16, 260] loss: 0.00043638144247233867\n",
      "[16, 280] loss: 0.000413392286747694\n",
      "[16, 300] loss: 0.0004888749076053501\n",
      "[17, 20] loss: 0.00048789758514612914\n",
      "[17, 40] loss: 0.00041410232475027443\n",
      "[17, 60] loss: 0.00040963551914319397\n",
      "[17, 80] loss: 0.0004097314216196537\n",
      "[17, 100] loss: 0.0005027584666386246\n",
      "[17, 120] loss: 0.0004130955245345831\n",
      "[17, 140] loss: 0.0003696876158937812\n",
      "[17, 160] loss: 0.0004984033983200789\n",
      "[17, 180] loss: 0.00041696489229798314\n",
      "[17, 200] loss: 0.0004385417951270938\n",
      "[17, 220] loss: 0.0004690931597724557\n",
      "[17, 240] loss: 0.000458562717307359\n",
      "[17, 260] loss: 0.0004131684496533126\n",
      "[17, 280] loss: 0.00047169182542711494\n",
      "[17, 300] loss: 0.0004633166929706931\n",
      "[18, 20] loss: 0.0004993112646043301\n",
      "[18, 40] loss: 0.00044242555601522326\n",
      "[18, 60] loss: 0.00046257992926985027\n",
      "[18, 80] loss: 0.0004836373822763562\n",
      "[18, 100] loss: 0.0003778768596239388\n",
      "[18, 120] loss: 0.0003960926798172295\n",
      "[18, 140] loss: 0.00032333443919196724\n",
      "[18, 160] loss: 0.0004171619233675301\n",
      "[18, 180] loss: 0.0004535283138975501\n",
      "[18, 200] loss: 0.00043490933580324055\n",
      "[18, 220] loss: 0.0004238413339480758\n",
      "[18, 240] loss: 0.0004769295295700431\n",
      "[18, 260] loss: 0.0005484476867131889\n",
      "[18, 280] loss: 0.00051686380058527\n",
      "[18, 300] loss: 0.00040104525769129397\n",
      "[19, 20] loss: 0.00039803446223959325\n",
      "[19, 40] loss: 0.00040596999367699025\n",
      "[19, 60] loss: 0.0004694147789850831\n",
      "[19, 80] loss: 0.0003962418644223362\n",
      "[19, 100] loss: 0.00042048977827653287\n",
      "[19, 120] loss: 0.0004981260756030679\n",
      "[19, 140] loss: 0.00030863490654155614\n",
      "[19, 160] loss: 0.00048470401391386987\n",
      "[19, 180] loss: 0.0004650768549181521\n",
      "[19, 200] loss: 0.0004650196013972163\n",
      "[19, 220] loss: 0.0005965931778773666\n",
      "[19, 240] loss: 0.00038292718678712844\n",
      "[19, 260] loss: 0.0004698240947909653\n",
      "[19, 280] loss: 0.0004637232441455126\n",
      "[19, 300] loss: 0.0003855552044697106\n",
      "[20, 20] loss: 0.0004194304030388594\n",
      "[20, 40] loss: 0.0004812506679445505\n",
      "[20, 60] loss: 0.0004321975661441684\n",
      "[20, 80] loss: 0.00041577002312988043\n",
      "[20, 100] loss: 0.0004230200769379735\n",
      "[20, 120] loss: 0.00044870824925601484\n",
      "[20, 140] loss: 0.0004197105634957552\n",
      "[20, 160] loss: 0.0004347986471839249\n",
      "[20, 180] loss: 0.00037902783788740636\n",
      "[20, 200] loss: 0.00042417496116831896\n",
      "[20, 220] loss: 0.0003547236402519047\n",
      "[20, 240] loss: 0.00044363206718117\n",
      "[20, 260] loss: 0.0004220356326550245\n",
      "[20, 280] loss: 0.0004496135958470404\n",
      "[20, 300] loss: 0.00037148713134229185\n",
      "Finished Reraining\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 24, 24]             156\n",
      "         MaxPool2d-2            [-1, 6, 12, 12]               0\n",
      "            Conv2d-3             [-1, 16, 8, 8]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 4, 4]               0\n",
      "            Linear-5                   [-1, 30]           7,710\n",
      "            Linear-6                   [-1, 10]             310\n",
      "            Linear-7                   [-1, 10]             110\n",
      "================================================================\n",
      "Total params: 10,702\n",
      "Trainable params: 10,702\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 0.04\n",
      "Estimated Total Size (MB): 0.09\n",
      "----------------------------------------------------------------\n",
      "Accuracy of the network on the test images: 98.380000 %\n"
     ]
    }
   ],
   "source": [
    "len_1=30\n",
    "len_2=10\n",
    "\n",
    "print(\"Pruning fc1.................\")\n",
    "\n",
    "nodes=defaultdict(list)\n",
    "for j in range(len(net.state_dict()[\"fc1.weight\"])):  #Means j is a node of next layer, L2. Fc1 is connecting L1 and L2 layer.\n",
    "    nodes[j]=net.state_dict()[\"fc1.weight\"][j]\n",
    "\n",
    "# print(len(nodes), \" \", len(nodes[0]))\n",
    "\n",
    "# from math import sqrt\n",
    "distances=[]\n",
    "for i in nodes.keys():\n",
    "    for j in nodes.keys():\n",
    "        if(i!=j and j>i):\n",
    "            distances.append(euclidean_distance(nodes[i], nodes[j]))\n",
    "\n",
    "distances.sort()\n",
    "            \n",
    "print(\"Finding clusters of nodes.................\")\n",
    "setpoints=findsets(len_1, nodes, distances)\n",
    "\n",
    "# print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "temp_weights=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(net.state_dict()[\"fc1.weight\"][0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=net.state_dict()[\"fc1.weight\"][points]\n",
    "    row=row/len(setpoints[key])\n",
    "    temp_weights.append(row)\n",
    "# print(len(temp_weights), temp_weights[0].shape)\n",
    "\n",
    "# print(net.state_dict()[\"fc1.bias\"].shape)\n",
    "temp_bias=torch.zeros(len(temp_weights), dtype=torch.float)\n",
    "i=0\n",
    "for key in setpoints.keys():\n",
    "    for points in setpoints[key]:\n",
    "        temp_bias[i]+=net.state_dict()[\"fc1.bias\"][points]\n",
    "    temp_bias[i]/=len(setpoints[key])\n",
    "    i+=1\n",
    "# print(temp_bias.shape)\n",
    "\n",
    "print(\"Updating fc1.................\")\n",
    "net_1 = changenet(net, \"fc1\", temp_weights, temp_bias)\n",
    "\n",
    "print(net.state_dict()[\"fc1.bias\"].shape, \" -> \", net_1.state_dict()[\"fc1.bias\"].shape)\n",
    "print(net.state_dict()[\"fc1.weight\"].shape, \" -> \", net_1.state_dict()[\"fc1.weight\"].shape)\n",
    "\n",
    "net=copy.deepcopy(net_1)\n",
    "# print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "# print(net.state_dict()[\"fc1.bias\"].shape)\n",
    "\n",
    "#just to check if the copy has been done correctly\n",
    "# print(temp_weights[0],\"\\n\\n\",net.state_dict()[\"fc1.weight\"][0])    \n",
    "\n",
    "\n",
    "### Now, we have to change FC2 accordingly:\n",
    "# print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "print(\"Adjusting fc2 accordingly.................\")\n",
    "mat=net.state_dict()[\"fc2.weight\"].t()\n",
    "# print(mat.shape)\n",
    "\n",
    "temp_weight=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(mat[0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=mat[points]\n",
    "    temp_weight.append(row)\n",
    "# print(len(temp_weight), temp_weight[0].shape)\n",
    "\n",
    "newmat=torch.stack(temp_weight, dim=0)\n",
    "newmat=newmat.t()\n",
    "# print(newmat.shape)\n",
    "\n",
    "# print(net.state_dict()[\"fc2.bias\"].shape)\n",
    "\n",
    "net_2 = changenet(net, \"fc2\", newmat, net.state_dict()[\"fc2.bias\"])\n",
    "net=copy.deepcopy(net_2)\n",
    "\n",
    "print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "print(net.state_dict()[\"fc3.weight\"].shape)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, len(net.state_dict()[\"fc1.weight\"]))\n",
    "        self.fc2 = nn.Linear(len(net.state_dict()[\"fc2.weight\"][0]), len(net.state_dict()[\"fc2.weight\"]))\n",
    "        self.fc3 = nn.Linear(len(net.state_dict()[\"fc3.weight\"][0]), 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    \n",
    "from torchsummary import summary\n",
    "device=torch.device(\"cpu\")\n",
    "model=Net().to(device)\n",
    "summary(model, input_size=(1, 28, 28), device=\"cpu\")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "\n",
    "print(\"Pruning fc2.................\")\n",
    "from collections import defaultdict\n",
    "nodes=defaultdict(list)\n",
    "for j in range(len(net.state_dict()[\"fc2.weight\"])):  #Means j is a node of next layer, L2.\n",
    "    nodes[j]=net.state_dict()[\"fc2.weight\"][j]\n",
    "\n",
    "# print(len(nodes), \" \", len(nodes[0]))\n",
    "\n",
    "\n",
    "distances=[]\n",
    "for i in nodes.keys():\n",
    "    for j in nodes.keys():\n",
    "        if(i!=j and j>i):\n",
    "            distances.append(euclidean_distance(nodes[i], nodes[j]))\n",
    "            \n",
    "distances.sort()\n",
    "# print(len(distances))\n",
    "\n",
    "print(\"Finding clusters of nodes.................\")\n",
    "setpoints=findsets(len_2, nodes, distances)\n",
    "\n",
    "# print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "temp_weight=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(net.state_dict()[\"fc2.weight\"][0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=net.state_dict()[\"fc2.weight\"][points]\n",
    "    row=row/len(setpoints[key])\n",
    "    temp_weight.append(row)\n",
    "# print(len(temp_weight), temp_weight[0].shape)\n",
    "\n",
    "# print(net.state_dict()[\"fc2.bias\"].shape)\n",
    "temp_bias=torch.zeros(len(temp_weight), dtype=torch.float)\n",
    "i=0\n",
    "for key in setpoints.keys():\n",
    "    for points in setpoints[key]:\n",
    "        temp_bias[i]+=net.state_dict()[\"fc2.bias\"][points]\n",
    "    temp_bias[i]/=len(setpoints[key])\n",
    "    i+=1\n",
    "# print(temp_bias.shape)\n",
    "\n",
    "print(\"Updating fc2.................\")\n",
    "net_3 = changenet(net, \"fc2\", temp_weight, temp_bias)\n",
    "net=copy.deepcopy(net_3)\n",
    "\n",
    "mat=net.state_dict()[\"fc3.weight\"].t()\n",
    "# print(mat.shape)\n",
    "\n",
    "temp_weight=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(mat[0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=mat[points]\n",
    "    temp_weight.append(row)\n",
    "# print(len(temp_weight), temp_weight[0].shape)\n",
    "\n",
    "newmat=torch.stack(temp_weight, dim=0)\n",
    "newmat=newmat.t()\n",
    "# print(newmat.shape)\n",
    "\n",
    "print(\"Adjusting fc3 accordingly.................\")\n",
    "net_4 = changenet(net, \"fc3\", newmat, net.state_dict()[\"fc3.bias\"])\n",
    "net=copy.deepcopy(net_4)\n",
    "\n",
    "print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "print(net.state_dict()[\"fc3.weight\"].shape)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, len(net.state_dict()[\"fc1.weight\"]))\n",
    "        self.fc2 = nn.Linear(len(net.state_dict()[\"fc2.weight\"][0]), len(net.state_dict()[\"fc2.weight\"]))\n",
    "        self.fc3 = nn.Linear(len(net.state_dict()[\"fc3.weight\"][0]), 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "i=0\n",
    "for parameter in net.parameters():\n",
    "    i+=1\n",
    "    if(i<5):\n",
    "        parameter.requires_grad=False\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.1307,), (0.3081,))])\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=200,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=200,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('0', '1', '2', '3',\n",
    "           '4', '5', '6', '7', '8', '9')\n",
    "\n",
    "# import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        # print(inputs.shape)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    # print every 2000 mini-batches\n",
    "            print(\"[{}, {}] loss: {}\".format\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Reraining')\n",
    "\n",
    "\n",
    "from torchsummary import summary\n",
    "device=torch.device(\"cpu\")\n",
    "model=Net().to(device)\n",
    "summary(model, input_size=(1, 28, 28), device=\"cpu\")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"LeNET_30_10_MNIST_Model_My_Exiperiment_4_Fine_Tuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning fc1.................\n",
      "Finding clusters of nodes.................\n",
      "desired len= 15\n",
      "cut_off= 1.2030386460265161\n",
      "iteration= 1  length= 9  difference= -6  change rate= 0.0012030386460265162\n",
      "cut_off= 1.195820414150357\n",
      "iteration= 2  length= 10  difference= -5  change rate= 0.0012030386460265162\n",
      "cut_off= 1.1898052209202243\n",
      "iteration= 3  length= 10  difference= -5  change rate= 0.0012030386460265162\n",
      "cut_off= 1.1837900276900917\n",
      "iteration= 4  length= 10  difference= -5  change rate= 0.0012030386460265162\n",
      "cut_off= 1.177774834459959\n",
      "iteration= 5  length= 10  difference= -5  change rate= 0.0012030386460265162\n",
      "cut_off= 1.1717596412298263\n",
      "iteration= 6  length= 10  difference= -5  change rate= 0.0012030386460265162\n",
      "cut_off= 1.1657444479996937\n",
      "iteration= 7  length= 10  difference= -5  change rate= 0.0012030386460265162\n",
      "cut_off= 1.159729254769561\n",
      "iteration= 8  length= 10  difference= -5  change rate= 0.0012030386460265162\n",
      "cut_off= 1.1537140615394283\n",
      "iteration= 9  length= 12  difference= -3  change rate= 0.0012030386460265162\n",
      "cut_off= 1.1501049456013488\n",
      "iteration= 10  length= 12  difference= -3  change rate= 0.0012030386460265162\n",
      "cut_off= 1.1464958296632692\n",
      "iteration= 11  length= 7  difference= -8  change rate= 0.0012030386460265162\n",
      "cut_off= 1.136871520495057\n",
      "iteration= 12  length= 9  difference= -6  change rate= 0.0012030386460265162\n",
      "cut_off= 1.129653288618898\n",
      "iteration= 13  length= 9  difference= -6  change rate= 0.0012030386460265162\n",
      "cut_off= 1.1224350567427388\n",
      "iteration= 14  length= 9  difference= -6  change rate= 0.0012030386460265162\n",
      "cut_off= 1.1152168248665797\n",
      "iteration= 15  length= 10  difference= -5  change rate= 0.0012030386460265162\n",
      "cut_off= 1.109201631636447\n",
      "iteration= 16  length= 10  difference= -5  change rate= 0.0012030386460265162\n",
      "cut_off= 1.1031864384063144\n",
      "iteration= 17  length= 10  difference= -5  change rate= 0.0012030386460265162\n",
      "cut_off= 1.0971712451761817\n",
      "iteration= 18  length= 11  difference= -4  change rate= 0.0012030386460265162\n",
      "cut_off= 1.0923590905920757\n",
      "iteration= 19  length= 11  difference= -4  change rate= 0.0012030386460265162\n",
      "cut_off= 1.0875469360079697\n",
      "iteration= 20  length= 12  difference= -3  change rate= 0.0012030386460265162\n",
      "cut_off= 1.0839378200698901\n",
      "iteration= 21  length= 13  difference= -2  change rate= 0.0012030386460265162\n",
      "cut_off= 1.081531742777837\n",
      "iteration= 22  length= 13  difference= -2  change rate= 0.0012030386460265162\n",
      "cut_off= 1.079125665485784\n",
      "iteration= 23  length= 14  difference= -1  change rate= 0.0012030386460265162\n",
      "cut_off= 1.0779226268397575\n",
      "iteration= 24  length= 14  difference= -1  change rate= 0.0012030386460265162\n",
      "cut_off= 1.076719588193731\n",
      "iteration= 25  length= 15  difference= -1  change rate= 0.0012030386460265162\n",
      "Updating fc1.................\n",
      "torch.Size([30])  ->  torch.Size([15])\n",
      "torch.Size([30, 256])  ->  torch.Size([15, 256])\n",
      "Adjusting fc2 accordingly.................\n",
      "torch.Size([15, 256])\n",
      "torch.Size([10, 15])\n",
      "torch.Size([10, 10])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 24, 24]             156\n",
      "         MaxPool2d-2            [-1, 6, 12, 12]               0\n",
      "            Conv2d-3             [-1, 16, 8, 8]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 4, 4]               0\n",
      "            Linear-5                   [-1, 15]           3,855\n",
      "            Linear-6                   [-1, 10]             160\n",
      "            Linear-7                   [-1, 10]             110\n",
      "================================================================\n",
      "Total params: 6,697\n",
      "Trainable params: 6,697\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 0.07\n",
      "----------------------------------------------------------------\n",
      "Accuracy of the network on the test images: 80.650000 %\n",
      "Pruning fc2.................\n",
      "Finding clusters of nodes.................\n",
      "desired len= 5\n",
      "cut_off= 1.957089482276726\n",
      "iteration= 1  length= 2  difference= -3  change rate= 0.001957089482276726\n",
      "cut_off= 1.9512182138298957\n",
      "iteration= 2  length= 2  difference= -3  change rate= 0.001957089482276726\n",
      "cut_off= 1.9453469453830654\n",
      "iteration= 3  length= 2  difference= -3  change rate= 0.001957089482276726\n",
      "cut_off= 1.9394756769362351\n",
      "iteration= 4  length= 2  difference= -3  change rate= 0.001957089482276726\n",
      "cut_off= 1.9336044084894048\n",
      "iteration= 5  length= 2  difference= -3  change rate= 0.001957089482276726\n",
      "cut_off= 1.9277331400425746\n",
      "iteration= 6  length= 2  difference= -3  change rate= 0.001957089482276726\n",
      "cut_off= 1.9218618715957443\n",
      "iteration= 7  length= 2  difference= -3  change rate= 0.001957089482276726\n",
      "cut_off= 1.915990603148914\n",
      "iteration= 8  length= 2  difference= -3  change rate= 0.001957089482276726\n",
      "cut_off= 1.9101193347020837\n",
      "iteration= 9  length= 2  difference= -3  change rate= 0.001957089482276726\n",
      "cut_off= 1.9042480662552534\n",
      "iteration= 10  length= 2  difference= -3  change rate= 0.001957089482276726\n",
      "cut_off= 1.8983767978084232\n",
      "iteration= 11  length= 2  difference= -3  change rate= 0.001957089482276726\n",
      "cut_off= 1.8925055293615929\n",
      "iteration= 12  length= 2  difference= -3  change rate= 0.001957089482276726\n",
      "cut_off= 1.8866342609147626\n",
      "iteration= 13  length= 2  difference= -3  change rate= 0.001957089482276726\n",
      "cut_off= 1.8807629924679323\n",
      "iteration= 14  length= 2  difference= -3  change rate= 0.001957089482276726\n",
      "cut_off= 1.874891724021102\n",
      "iteration= 15  length= 2  difference= -3  change rate= 0.001957089482276726\n",
      "cut_off= 1.8690204555742718\n",
      "iteration= 16  length= 2  difference= -3  change rate= 0.001957089482276726\n",
      "cut_off= 1.8631491871274415\n",
      "iteration= 17  length= 2  difference= -3  change rate= 0.001957089482276726\n",
      "cut_off= 1.8572779186806112\n",
      "iteration= 18  length= 2  difference= -3  change rate= 0.001957089482276726\n",
      "cut_off= 1.851406650233781\n",
      "iteration= 19  length= 2  difference= -3  change rate= 0.001957089482276726\n",
      "cut_off= 1.8455353817869506\n",
      "iteration= 20  length= 2  difference= -3  change rate= 0.001957089482276726\n",
      "cut_off= 1.8396641133401204\n",
      "iteration= 21  length= 2  difference= -3  change rate= 0.001957089482276726\n",
      "cut_off= 1.83379284489329\n",
      "iteration= 22  length= 2  difference= -3  change rate= 0.001957089482276726\n",
      "cut_off= 1.8279215764464598\n",
      "iteration= 23  length= 2  difference= -3  change rate= 0.001957089482276726\n",
      "cut_off= 1.8220503079996295\n",
      "iteration= 24  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.8181361290350762\n",
      "iteration= 25  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.8142219500705228\n",
      "iteration= 26  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.8103077711059694\n",
      "iteration= 27  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.806393592141416\n",
      "iteration= 28  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.8024794131768627\n",
      "iteration= 29  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.7985652342123093\n",
      "iteration= 30  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.794651055247756\n",
      "iteration= 31  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.7907368762832025\n",
      "iteration= 32  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.7868226973186492\n",
      "iteration= 33  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.7829085183540958\n",
      "iteration= 34  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.7789943393895424\n",
      "iteration= 35  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.775080160424989\n",
      "iteration= 36  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.7711659814604357\n",
      "iteration= 37  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.7672518024958823\n",
      "iteration= 38  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.763337623531329\n",
      "iteration= 39  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.7594234445667756\n",
      "iteration= 40  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.7555092656022222\n",
      "iteration= 41  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.7515950866376688\n",
      "iteration= 42  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.7476809076731155\n",
      "iteration= 43  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.743766728708562\n",
      "iteration= 44  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.7398525497440087\n",
      "iteration= 45  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.7359383707794553\n",
      "iteration= 46  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.732024191814902\n",
      "iteration= 47  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.7281100128503486\n",
      "iteration= 48  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.7241958338857952\n",
      "iteration= 49  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.7202816549212419\n",
      "iteration= 50  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.7163674759566885\n",
      "iteration= 51  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.712453296992135\n",
      "iteration= 52  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.7085391180275817\n",
      "iteration= 53  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.7046249390630284\n",
      "iteration= 54  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.700710760098475\n",
      "iteration= 55  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.6967965811339216\n",
      "iteration= 56  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.6928824021693683\n",
      "iteration= 57  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.6889682232048149\n",
      "iteration= 58  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.6850540442402615\n",
      "iteration= 59  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.6811398652757081\n",
      "iteration= 60  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.6772256863111548\n",
      "iteration= 61  length= 3  difference= -2  change rate= 0.001957089482276726\n",
      "cut_off= 1.6733115073466014\n",
      "iteration= 62  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.6713544178643247\n",
      "iteration= 63  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.669397328382048\n",
      "iteration= 64  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.6674402388997713\n",
      "iteration= 65  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.6654831494174946\n",
      "iteration= 66  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.663526059935218\n",
      "iteration= 67  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.6615689704529413\n",
      "iteration= 68  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.6596118809706646\n",
      "iteration= 69  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.657654791488388\n",
      "iteration= 70  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.6556977020061112\n",
      "iteration= 71  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.6537406125238345\n",
      "iteration= 72  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.6517835230415578\n",
      "iteration= 73  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.6498264335592812\n",
      "iteration= 74  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.6478693440770045\n",
      "iteration= 75  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.6459122545947278\n",
      "iteration= 76  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.643955165112451\n",
      "iteration= 77  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.6419980756301744\n",
      "iteration= 78  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.6400409861478977\n",
      "iteration= 79  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.638083896665621\n",
      "iteration= 80  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.6361268071833444\n",
      "iteration= 81  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.6341697177010677\n",
      "iteration= 82  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.632212628218791\n",
      "iteration= 83  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.6302555387365143\n",
      "iteration= 84  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.6282984492542376\n",
      "iteration= 85  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.626341359771961\n",
      "iteration= 86  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.6243842702896842\n",
      "iteration= 87  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.6224271808074076\n",
      "iteration= 88  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.6204700913251309\n",
      "iteration= 89  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.6185130018428542\n",
      "iteration= 90  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.6165559123605775\n",
      "iteration= 91  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.6145988228783008\n",
      "iteration= 92  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.6126417333960241\n",
      "iteration= 93  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.6106846439137474\n",
      "iteration= 94  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.6087275544314708\n",
      "iteration= 95  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.606770464949194\n",
      "iteration= 96  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.6048133754669174\n",
      "iteration= 97  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.6028562859846407\n",
      "iteration= 98  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.600899196502364\n",
      "iteration= 99  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5989421070200873\n",
      "iteration= 100  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5969850175378106\n",
      "iteration= 101  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.595027928055534\n",
      "iteration= 102  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5930708385732573\n",
      "iteration= 103  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5911137490909806\n",
      "iteration= 104  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.589156659608704\n",
      "iteration= 105  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5871995701264272\n",
      "iteration= 106  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5852424806441505\n",
      "iteration= 107  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5832853911618738\n",
      "iteration= 108  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5813283016795971\n",
      "iteration= 109  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5793712121973205\n",
      "iteration= 110  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5774141227150438\n",
      "iteration= 111  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.575457033232767\n",
      "iteration= 112  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5734999437504904\n",
      "iteration= 113  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5715428542682137\n",
      "iteration= 114  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.569585764785937\n",
      "iteration= 115  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5676286753036603\n",
      "iteration= 116  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5656715858213837\n",
      "iteration= 117  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.563714496339107\n",
      "iteration= 118  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5617574068568303\n",
      "iteration= 119  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5598003173745536\n",
      "iteration= 120  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.557843227892277\n",
      "iteration= 121  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5558861384100002\n",
      "iteration= 122  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5539290489277235\n",
      "iteration= 123  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5519719594454469\n",
      "iteration= 124  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5500148699631702\n",
      "iteration= 125  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5480577804808935\n",
      "iteration= 126  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5461006909986168\n",
      "iteration= 127  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5441436015163401\n",
      "iteration= 128  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5421865120340634\n",
      "iteration= 129  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5402294225517867\n",
      "iteration= 130  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.53827233306951\n",
      "iteration= 131  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5363152435872334\n",
      "iteration= 132  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5343581541049567\n",
      "iteration= 133  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.53240106462268\n",
      "iteration= 134  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5304439751404033\n",
      "iteration= 135  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5284868856581266\n",
      "iteration= 136  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.52652979617585\n",
      "iteration= 137  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5245727066935733\n",
      "iteration= 138  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5226156172112966\n",
      "iteration= 139  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5206585277290199\n",
      "iteration= 140  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5187014382467432\n",
      "iteration= 141  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5167443487644665\n",
      "iteration= 142  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5147872592821898\n",
      "iteration= 143  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5128301697999131\n",
      "iteration= 144  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5108730803176365\n",
      "iteration= 145  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5089159908353598\n",
      "iteration= 146  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.506958901353083\n",
      "iteration= 147  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5050018118708064\n",
      "iteration= 148  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.5030447223885297\n",
      "iteration= 149  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.501087632906253\n",
      "iteration= 150  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.4991305434239763\n",
      "iteration= 151  length= 4  difference= -1  change rate= 0.001957089482276726\n",
      "cut_off= 1.4971734539416997\n",
      "iteration= 152  length= 5  difference= -1  change rate= 0.001957089482276726\n",
      "Updating fc2.................\n",
      "Adjusting fc3 accordingly.................\n",
      "torch.Size([15, 256])\n",
      "torch.Size([5, 15])\n",
      "torch.Size([10, 5])\n",
      "Accuracy of the network on the test images: 39.010000 %\n",
      "[1, 20] loss: 0.018284274220466613\n",
      "[1, 40] loss: 0.011074675410985948\n",
      "[1, 60] loss: 0.0085258669257164\n",
      "[1, 80] loss: 0.006834855675697327\n",
      "[1, 100] loss: 0.005806968331336975\n",
      "[1, 120] loss: 0.0051477825492620465\n",
      "[1, 140] loss: 0.004712144061923027\n",
      "[1, 160] loss: 0.004022136971354485\n",
      "[1, 180] loss: 0.003952825129032135\n",
      "[1, 200] loss: 0.003588077738881111\n",
      "[1, 220] loss: 0.0039954534769058225\n",
      "[1, 240] loss: 0.0033093459755182265\n",
      "[1, 260] loss: 0.00325617091357708\n",
      "[1, 280] loss: 0.0031723248064517975\n",
      "[1, 300] loss: 0.0030970079600811003\n",
      "[2, 20] loss: 0.0032283103540539744\n",
      "[2, 40] loss: 0.0027501016333699225\n",
      "[2, 60] loss: 0.0030846091732382773\n",
      "[2, 80] loss: 0.002785392090678215\n",
      "[2, 100] loss: 0.0026212051659822463\n",
      "[2, 120] loss: 0.0025062380358576775\n",
      "[2, 140] loss: 0.0023963370844721794\n",
      "[2, 160] loss: 0.002478797622025013\n",
      "[2, 180] loss: 0.0025271915942430495\n",
      "[2, 200] loss: 0.0023566377833485605\n",
      "[2, 220] loss: 0.0023035441562533378\n",
      "[2, 240] loss: 0.002265921913087368\n",
      "[2, 260] loss: 0.0022210888490080834\n",
      "[2, 280] loss: 0.0022599250823259354\n",
      "[2, 300] loss: 0.0021993427723646162\n",
      "[3, 20] loss: 0.002089239917695522\n",
      "[3, 40] loss: 0.002291412554681301\n",
      "[3, 60] loss: 0.002038092538714409\n",
      "[3, 80] loss: 0.001990848109126091\n",
      "[3, 100] loss: 0.0020101612247526647\n",
      "[3, 120] loss: 0.0023939462527632713\n",
      "[3, 140] loss: 0.002022169940173626\n",
      "[3, 160] loss: 0.0019425206556916237\n",
      "[3, 180] loss: 0.0021082128956913947\n",
      "[3, 200] loss: 0.001966842330992222\n",
      "[3, 220] loss: 0.0019318795539438724\n",
      "[3, 240] loss: 0.0021424814648926256\n",
      "[3, 260] loss: 0.001804512407630682\n",
      "[3, 280] loss: 0.0020509016662836077\n",
      "[3, 300] loss: 0.0019422449097037315\n",
      "[4, 20] loss: 0.002014833077788353\n",
      "[4, 40] loss: 0.0017820350863039494\n",
      "[4, 60] loss: 0.0017628370486199856\n",
      "[4, 80] loss: 0.0017810460589826108\n",
      "[4, 100] loss: 0.001839800588786602\n",
      "[4, 120] loss: 0.0016234081499278544\n",
      "[4, 140] loss: 0.0016673397533595563\n",
      "[4, 160] loss: 0.0018182751275599002\n",
      "[4, 180] loss: 0.0015733110420405865\n",
      "[4, 200] loss: 0.0015898439139127732\n",
      "[4, 220] loss: 0.00170191715285182\n",
      "[4, 240] loss: 0.0016915971376001834\n",
      "[4, 260] loss: 0.00170146456733346\n",
      "[4, 280] loss: 0.0017533824555575847\n",
      "[4, 300] loss: 0.0019806456975638865\n",
      "[5, 20] loss: 0.0016264876015484333\n",
      "[5, 40] loss: 0.001648379284888506\n",
      "[5, 60] loss: 0.0014587482884526252\n",
      "[5, 80] loss: 0.0016140890643000603\n",
      "[5, 100] loss: 0.001559349823743105\n",
      "[5, 120] loss: 0.0017782669588923454\n",
      "[5, 140] loss: 0.0016489925608038903\n",
      "[5, 160] loss: 0.0015687873400747777\n",
      "[5, 180] loss: 0.0014068250730633735\n",
      "[5, 200] loss: 0.0015060385428369045\n",
      "[5, 220] loss: 0.001462797399610281\n",
      "[5, 240] loss: 0.0014014365542680024\n",
      "[5, 260] loss: 0.0016824203617870808\n",
      "[5, 280] loss: 0.0016470546796917916\n",
      "[5, 300] loss: 0.0016494647860527038\n",
      "[6, 20] loss: 0.0014244510047137738\n",
      "[6, 40] loss: 0.0015376992858946324\n",
      "[6, 60] loss: 0.0016069333665072918\n",
      "[6, 80] loss: 0.0014841743260622024\n",
      "[6, 100] loss: 0.0014905349537730217\n",
      "[6, 120] loss: 0.0014029629454016686\n",
      "[6, 140] loss: 0.0014005519021302463\n",
      "[6, 160] loss: 0.0012736107036471368\n",
      "[6, 180] loss: 0.0014897412955760957\n",
      "[6, 200] loss: 0.001532894480973482\n",
      "[6, 220] loss: 0.0013770522587001324\n",
      "[6, 240] loss: 0.001659811243414879\n",
      "[6, 260] loss: 0.0014341003112494945\n",
      "[6, 280] loss: 0.0013029280006885528\n",
      "[6, 300] loss: 0.0015742903463542462\n",
      "[7, 20] loss: 0.0012967405952513218\n",
      "[7, 40] loss: 0.0014101779200136663\n",
      "[7, 60] loss: 0.0014572035893797874\n",
      "[7, 80] loss: 0.0013649349994957448\n",
      "[7, 100] loss: 0.0014256262965500355\n",
      "[7, 120] loss: 0.0015885420329868794\n",
      "[7, 140] loss: 0.0012753430977463722\n",
      "[7, 160] loss: 0.0011980166882276536\n",
      "[7, 180] loss: 0.0013265728391706943\n",
      "[7, 200] loss: 0.0012879814095795154\n",
      "[7, 220] loss: 0.0017536784149706365\n",
      "[7, 240] loss: 0.0013368991017341614\n",
      "[7, 260] loss: 0.0013629210516810416\n",
      "[7, 280] loss: 0.0014602760579437016\n",
      "[7, 300] loss: 0.0012117238398641349\n",
      "[8, 20] loss: 0.001556703206151724\n",
      "[8, 40] loss: 0.0013801383301615714\n",
      "[8, 60] loss: 0.0011996365711092949\n",
      "[8, 80] loss: 0.001285277247428894\n",
      "[8, 100] loss: 0.00126758349314332\n",
      "[8, 120] loss: 0.001228451807051897\n",
      "[8, 140] loss: 0.001298792064189911\n",
      "[8, 160] loss: 0.0014199315533041954\n",
      "[8, 180] loss: 0.0013717994280159473\n",
      "[8, 200] loss: 0.0014284297786653043\n",
      "[8, 220] loss: 0.0012688958216458559\n",
      "[8, 240] loss: 0.0013776913993060588\n",
      "[8, 260] loss: 0.001283324971795082\n",
      "[8, 280] loss: 0.0013214576840400697\n",
      "[8, 300] loss: 0.001244268411770463\n",
      "[9, 20] loss: 0.0014099008645862342\n",
      "[9, 40] loss: 0.0012169174402952194\n",
      "[9, 60] loss: 0.001169297557324171\n",
      "[9, 80] loss: 0.0011627632305026055\n",
      "[9, 100] loss: 0.0012439759187400342\n",
      "[9, 120] loss: 0.0012811398189514875\n",
      "[9, 140] loss: 0.0012326115313917398\n",
      "[9, 160] loss: 0.0010427577309310436\n",
      "[9, 180] loss: 0.0011529120076447725\n",
      "[9, 200] loss: 0.0012409220337867737\n",
      "[9, 220] loss: 0.001332589454948902\n",
      "[9, 240] loss: 0.001211106177419424\n",
      "[9, 260] loss: 0.001243172561749816\n",
      "[9, 280] loss: 0.0012092538010329008\n",
      "[9, 300] loss: 0.0012142075076699258\n",
      "[10, 20] loss: 0.0011894408799707889\n",
      "[10, 40] loss: 0.0011614974234253168\n",
      "[10, 60] loss: 0.00127953171543777\n",
      "[10, 80] loss: 0.0012349626608192921\n",
      "[10, 100] loss: 0.0012192215621471404\n",
      "[10, 120] loss: 0.0012079478651285172\n",
      "[10, 140] loss: 0.0012378990668803454\n",
      "[10, 160] loss: 0.0010648994408547878\n",
      "[10, 180] loss: 0.00113724734634161\n",
      "[10, 200] loss: 0.001094769075512886\n",
      "[10, 220] loss: 0.0010434449901804328\n",
      "[10, 240] loss: 0.001233366847038269\n",
      "[10, 260] loss: 0.0012639696896076203\n",
      "[10, 280] loss: 0.0012123800739645958\n",
      "[10, 300] loss: 0.0010426660478115083\n",
      "[11, 20] loss: 0.0012344741486012935\n",
      "[11, 40] loss: 0.0011032514926046133\n",
      "[11, 60] loss: 0.0010359466560184956\n",
      "[11, 80] loss: 0.001218032483011484\n",
      "[11, 100] loss: 0.0012222225293517114\n",
      "[11, 120] loss: 0.0011775440685451032\n",
      "[11, 140] loss: 0.0012977690622210502\n",
      "[11, 160] loss: 0.0011563303675502538\n",
      "[11, 180] loss: 0.0013180569931864738\n",
      "[11, 200] loss: 0.0012902581840753555\n",
      "[11, 220] loss: 0.0011238975077867508\n",
      "[11, 240] loss: 0.0010268021635711194\n",
      "[11, 260] loss: 0.0011816088538616895\n",
      "[11, 280] loss: 0.0011596522610634566\n",
      "[11, 300] loss: 0.0009926952309906483\n",
      "[12, 20] loss: 0.0011226966213434934\n",
      "[12, 40] loss: 0.0011889435686171055\n",
      "[12, 60] loss: 0.0010832021050155164\n",
      "[12, 80] loss: 0.001124398184940219\n",
      "[12, 100] loss: 0.0009530326146632433\n",
      "[12, 120] loss: 0.0010259178131818772\n",
      "[12, 140] loss: 0.0011164050232619048\n",
      "[12, 160] loss: 0.0011227849703282118\n",
      "[12, 180] loss: 0.0010629756320267917\n",
      "[12, 200] loss: 0.0012709882017225027\n",
      "[12, 220] loss: 0.001214541556313634\n",
      "[12, 240] loss: 0.00108828960172832\n",
      "[12, 260] loss: 0.00109942876547575\n",
      "[12, 280] loss: 0.0011434459742158652\n",
      "[12, 300] loss: 0.0011995749901980162\n",
      "[13, 20] loss: 0.0010801490470767022\n",
      "[13, 40] loss: 0.0011714143212884665\n",
      "[13, 60] loss: 0.0011275261342525483\n",
      "[13, 80] loss: 0.0011570794116705656\n",
      "[13, 100] loss: 0.001090417727828026\n",
      "[13, 120] loss: 0.0012179007716476918\n",
      "[13, 140] loss: 0.001089917717501521\n",
      "[13, 160] loss: 0.0010361204240471125\n",
      "[13, 180] loss: 0.0011317453999072314\n",
      "[13, 200] loss: 0.001104349970817566\n",
      "[13, 220] loss: 0.001027722554281354\n",
      "[13, 240] loss: 0.0009871154855936766\n",
      "[13, 260] loss: 0.0011114411614835263\n",
      "[13, 280] loss: 0.0010841996278613806\n",
      "[13, 300] loss: 0.0009177217725664377\n",
      "[14, 20] loss: 0.0011216815672814846\n",
      "[14, 40] loss: 0.0009852007292211055\n",
      "[14, 60] loss: 0.0010570819396525622\n",
      "[14, 80] loss: 0.0010485489722341299\n",
      "[14, 100] loss: 0.0012655392065644264\n",
      "[14, 120] loss: 0.001040554828941822\n",
      "[14, 140] loss: 0.0010268558170646429\n",
      "[14, 160] loss: 0.0010532682985067367\n",
      "[14, 180] loss: 0.0010249320957809688\n",
      "[14, 200] loss: 0.0009673063019290567\n",
      "[14, 220] loss: 0.0011041418332606555\n",
      "[14, 240] loss: 0.0010370107609778642\n",
      "[14, 260] loss: 0.0010293845012784005\n",
      "[14, 280] loss: 0.0010638739708811044\n",
      "[14, 300] loss: 0.0011121245287358762\n",
      "[15, 20] loss: 0.0009376947525888682\n",
      "[15, 40] loss: 0.0010564321260899305\n",
      "[15, 60] loss: 0.0010464879106730223\n",
      "[15, 80] loss: 0.0008772084806114435\n",
      "[15, 100] loss: 0.0009211364835500718\n",
      "[15, 120] loss: 0.0010040300674736499\n",
      "[15, 140] loss: 0.0009740534164011478\n",
      "[15, 160] loss: 0.0009924003444612027\n",
      "[15, 180] loss: 0.0009455007836222649\n",
      "[15, 200] loss: 0.0011485690865665674\n",
      "[15, 220] loss: 0.0011187856551259756\n",
      "[15, 240] loss: 0.0011437503304332496\n",
      "[15, 260] loss: 0.0011526243332773446\n",
      "[15, 280] loss: 0.0011805690843611956\n",
      "[15, 300] loss: 0.0010863860100507735\n",
      "[16, 20] loss: 0.0011355775389820337\n",
      "[16, 40] loss: 0.0010505263190716506\n",
      "[16, 60] loss: 0.0010771531108766793\n",
      "[16, 80] loss: 0.0009401276838034391\n",
      "[16, 100] loss: 0.0009456218909472227\n",
      "[16, 120] loss: 0.0011100226193666459\n",
      "[16, 140] loss: 0.0009458402544260025\n",
      "[16, 160] loss: 0.0011253000423312187\n",
      "[16, 180] loss: 0.0010118859149515628\n",
      "[16, 200] loss: 0.0009816189575940371\n",
      "[16, 220] loss: 0.0008622621446847915\n",
      "[16, 240] loss: 0.001062596632167697\n",
      "[16, 260] loss: 0.0009696035441011191\n",
      "[16, 280] loss: 0.0009203444961458445\n",
      "[16, 300] loss: 0.0010362099390476942\n",
      "[17, 20] loss: 0.0009746530093252658\n",
      "[17, 40] loss: 0.001039106659591198\n",
      "[17, 60] loss: 0.0010920973625034094\n",
      "[17, 80] loss: 0.0009593739453703166\n",
      "[17, 100] loss: 0.0011253434680402279\n",
      "[17, 120] loss: 0.0010100558549165726\n",
      "[17, 140] loss: 0.0008832672871649266\n",
      "[17, 160] loss: 0.0008033512588590384\n",
      "[17, 180] loss: 0.0010758708529174327\n",
      "[17, 200] loss: 0.0010171090383082628\n",
      "[17, 220] loss: 0.00098238829895854\n",
      "[17, 240] loss: 0.000937696348875761\n",
      "[17, 260] loss: 0.0009680239409208298\n",
      "[17, 280] loss: 0.0009496166314929724\n",
      "[17, 300] loss: 0.001098955126479268\n",
      "[18, 20] loss: 0.0010853451117873191\n",
      "[18, 40] loss: 0.0010547050535678864\n",
      "[18, 60] loss: 0.0009733264986425638\n",
      "[18, 80] loss: 0.0009683278389275074\n",
      "[18, 100] loss: 0.0008904592227190733\n",
      "[18, 120] loss: 0.0010424002949148416\n",
      "[18, 140] loss: 0.000992742370814085\n",
      "[18, 160] loss: 0.0009625821020454168\n",
      "[18, 180] loss: 0.0010109462924301625\n",
      "[18, 200] loss: 0.0009237347077578306\n",
      "[18, 220] loss: 0.0009655915796756745\n",
      "[18, 240] loss: 0.0009965112786740065\n",
      "[18, 260] loss: 0.0009194257073104382\n",
      "[18, 280] loss: 0.0009458583928644657\n",
      "[18, 300] loss: 0.0009613560773432255\n",
      "[19, 20] loss: 0.001003566265106201\n",
      "[19, 40] loss: 0.0008681545164436102\n",
      "[19, 60] loss: 0.0008774153403937816\n",
      "[19, 80] loss: 0.0008289348352700472\n",
      "[19, 100] loss: 0.0008739292565733194\n",
      "[19, 120] loss: 0.0010125550795346498\n",
      "[19, 140] loss: 0.0008252308899536729\n",
      "[19, 160] loss: 0.0009658121932297945\n",
      "[19, 180] loss: 0.0008827102109789848\n",
      "[19, 200] loss: 0.000995621506124735\n",
      "[19, 220] loss: 0.0011114193741232157\n",
      "[19, 240] loss: 0.0010304990001022815\n",
      "[19, 260] loss: 0.0009675816129893065\n",
      "[19, 280] loss: 0.0010183234587311744\n",
      "[19, 300] loss: 0.0010241545364260674\n",
      "[20, 20] loss: 0.0008846902623772621\n",
      "[20, 40] loss: 0.0009702147729694844\n",
      "[20, 60] loss: 0.0008565668994560837\n",
      "[20, 80] loss: 0.0007934576142579318\n",
      "[20, 100] loss: 0.0009958399590104818\n",
      "[20, 120] loss: 0.0010124079985544085\n",
      "[20, 140] loss: 0.0009592484962195158\n",
      "[20, 160] loss: 0.0008595546633005142\n",
      "[20, 180] loss: 0.0010682730339467525\n",
      "[20, 200] loss: 0.0011359315849840642\n",
      "[20, 220] loss: 0.0009281658101826906\n",
      "[20, 240] loss: 0.0009713861234486104\n",
      "[20, 260] loss: 0.0010156446620821953\n",
      "[20, 280] loss: 0.0009277680199593306\n",
      "[20, 300] loss: 0.0009341816361993551\n",
      "Finished Reraining\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 24, 24]             156\n",
      "         MaxPool2d-2            [-1, 6, 12, 12]               0\n",
      "            Conv2d-3             [-1, 16, 8, 8]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 4, 4]               0\n",
      "            Linear-5                   [-1, 15]           3,855\n",
      "            Linear-6                    [-1, 5]              80\n",
      "            Linear-7                   [-1, 10]              60\n",
      "================================================================\n",
      "Total params: 6,567\n",
      "Trainable params: 6,567\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 0.07\n",
      "----------------------------------------------------------------\n",
      "Accuracy of the network on the test images: 97.480000 %\n"
     ]
    }
   ],
   "source": [
    "len_1=15\n",
    "len_2=5\n",
    "\n",
    "print(\"Pruning fc1.................\")\n",
    "\n",
    "nodes=defaultdict(list)\n",
    "for j in range(len(net.state_dict()[\"fc1.weight\"])):  #Means j is a node of next layer, L2. Fc1 is connecting L1 and L2 layer.\n",
    "    nodes[j]=net.state_dict()[\"fc1.weight\"][j]\n",
    "\n",
    "# print(len(nodes), \" \", len(nodes[0]))\n",
    "\n",
    "# from math import sqrt\n",
    "distances=[]\n",
    "for i in nodes.keys():\n",
    "    for j in nodes.keys():\n",
    "        if(i!=j and j>i):\n",
    "            distances.append(euclidean_distance(nodes[i], nodes[j]))\n",
    "\n",
    "distances.sort()\n",
    "            \n",
    "print(\"Finding clusters of nodes.................\")\n",
    "setpoints=findsets(len_1, nodes, distances)\n",
    "\n",
    "# print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "temp_weights=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(net.state_dict()[\"fc1.weight\"][0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=net.state_dict()[\"fc1.weight\"][points]\n",
    "    row=row/len(setpoints[key])\n",
    "    temp_weights.append(row)\n",
    "# print(len(temp_weights), temp_weights[0].shape)\n",
    "\n",
    "# print(net.state_dict()[\"fc1.bias\"].shape)\n",
    "temp_bias=torch.zeros(len(temp_weights), dtype=torch.float)\n",
    "i=0\n",
    "for key in setpoints.keys():\n",
    "    for points in setpoints[key]:\n",
    "        temp_bias[i]+=net.state_dict()[\"fc1.bias\"][points]\n",
    "    temp_bias[i]/=len(setpoints[key])\n",
    "    i+=1\n",
    "# print(temp_bias.shape)\n",
    "\n",
    "print(\"Updating fc1.................\")\n",
    "net_1 = changenet(net, \"fc1\", temp_weights, temp_bias)\n",
    "\n",
    "print(net.state_dict()[\"fc1.bias\"].shape, \" -> \", net_1.state_dict()[\"fc1.bias\"].shape)\n",
    "print(net.state_dict()[\"fc1.weight\"].shape, \" -> \", net_1.state_dict()[\"fc1.weight\"].shape)\n",
    "\n",
    "net=copy.deepcopy(net_1)\n",
    "# print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "# print(net.state_dict()[\"fc1.bias\"].shape)\n",
    "\n",
    "#just to check if the copy has been done correctly\n",
    "# print(temp_weights[0],\"\\n\\n\",net.state_dict()[\"fc1.weight\"][0])    \n",
    "\n",
    "\n",
    "### Now, we have to change FC2 accordingly:\n",
    "# print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "print(\"Adjusting fc2 accordingly.................\")\n",
    "mat=net.state_dict()[\"fc2.weight\"].t()\n",
    "# print(mat.shape)\n",
    "\n",
    "temp_weight=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(mat[0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=mat[points]\n",
    "    temp_weight.append(row)\n",
    "# print(len(temp_weight), temp_weight[0].shape)\n",
    "\n",
    "newmat=torch.stack(temp_weight, dim=0)\n",
    "newmat=newmat.t()\n",
    "# print(newmat.shape)\n",
    "\n",
    "# print(net.state_dict()[\"fc2.bias\"].shape)\n",
    "\n",
    "net_2 = changenet(net, \"fc2\", newmat, net.state_dict()[\"fc2.bias\"])\n",
    "net=copy.deepcopy(net_2)\n",
    "\n",
    "print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "print(net.state_dict()[\"fc3.weight\"].shape)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, len(net.state_dict()[\"fc1.weight\"]))\n",
    "        self.fc2 = nn.Linear(len(net.state_dict()[\"fc2.weight\"][0]), len(net.state_dict()[\"fc2.weight\"]))\n",
    "        self.fc3 = nn.Linear(len(net.state_dict()[\"fc3.weight\"][0]), 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    \n",
    "from torchsummary import summary\n",
    "device=torch.device(\"cpu\")\n",
    "model=Net().to(device)\n",
    "summary(model, input_size=(1, 28, 28), device=\"cpu\")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "\n",
    "print(\"Pruning fc2.................\")\n",
    "from collections import defaultdict\n",
    "nodes=defaultdict(list)\n",
    "for j in range(len(net.state_dict()[\"fc2.weight\"])):  #Means j is a node of next layer, L2.\n",
    "    nodes[j]=net.state_dict()[\"fc2.weight\"][j]\n",
    "\n",
    "# print(len(nodes), \" \", len(nodes[0]))\n",
    "\n",
    "\n",
    "distances=[]\n",
    "for i in nodes.keys():\n",
    "    for j in nodes.keys():\n",
    "        if(i!=j and j>i):\n",
    "            distances.append(euclidean_distance(nodes[i], nodes[j]))\n",
    "            \n",
    "distances.sort()\n",
    "# print(len(distances))\n",
    "\n",
    "print(\"Finding clusters of nodes.................\")\n",
    "setpoints=findsets(len_2, nodes, distances)\n",
    "\n",
    "# print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "temp_weight=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(net.state_dict()[\"fc2.weight\"][0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=net.state_dict()[\"fc2.weight\"][points]\n",
    "    row=row/len(setpoints[key])\n",
    "    temp_weight.append(row)\n",
    "# print(len(temp_weight), temp_weight[0].shape)\n",
    "\n",
    "# print(net.state_dict()[\"fc2.bias\"].shape)\n",
    "temp_bias=torch.zeros(len(temp_weight), dtype=torch.float)\n",
    "i=0\n",
    "for key in setpoints.keys():\n",
    "    for points in setpoints[key]:\n",
    "        temp_bias[i]+=net.state_dict()[\"fc2.bias\"][points]\n",
    "    temp_bias[i]/=len(setpoints[key])\n",
    "    i+=1\n",
    "# print(temp_bias.shape)\n",
    "\n",
    "print(\"Updating fc2.................\")\n",
    "net_3 = changenet(net, \"fc2\", temp_weight, temp_bias)\n",
    "net=copy.deepcopy(net_3)\n",
    "\n",
    "mat=net.state_dict()[\"fc3.weight\"].t()\n",
    "# print(mat.shape)\n",
    "\n",
    "temp_weight=[]\n",
    "for key in setpoints.keys():\n",
    "    row=torch.zeros(len(mat[0]), dtype=torch.float)\n",
    "    for points in setpoints[key]:\n",
    "        row+=mat[points]\n",
    "    temp_weight.append(row)\n",
    "# print(len(temp_weight), temp_weight[0].shape)\n",
    "\n",
    "newmat=torch.stack(temp_weight, dim=0)\n",
    "newmat=newmat.t()\n",
    "# print(newmat.shape)\n",
    "\n",
    "print(\"Adjusting fc3 accordingly.................\")\n",
    "net_4 = changenet(net, \"fc3\", newmat, net.state_dict()[\"fc3.bias\"])\n",
    "net=copy.deepcopy(net_4)\n",
    "\n",
    "print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "print(net.state_dict()[\"fc3.weight\"].shape)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, len(net.state_dict()[\"fc1.weight\"]))\n",
    "        self.fc2 = nn.Linear(len(net.state_dict()[\"fc2.weight\"][0]), len(net.state_dict()[\"fc2.weight\"]))\n",
    "        self.fc3 = nn.Linear(len(net.state_dict()[\"fc3.weight\"][0]), 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "i=0\n",
    "for parameter in net.parameters():\n",
    "    i+=1\n",
    "    if(i<5):\n",
    "        parameter.requires_grad=False\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.1307,), (0.3081,))])\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=200,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=200,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('0', '1', '2', '3',\n",
    "           '4', '5', '6', '7', '8', '9')\n",
    "\n",
    "# import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        # print(inputs.shape)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    # print every 2000 mini-batches\n",
    "            print(\"[{}, {}] loss: {}\".format\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Reraining')\n",
    "\n",
    "\n",
    "from torchsummary import summary\n",
    "device=torch.device(\"cpu\")\n",
    "model=Net().to(device)\n",
    "summary(model, input_size=(1, 28, 28), device=\"cpu\")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"LeNET_15_5_MNIST_Model_My_Exiperiment_4_Fine_Tuned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources:\n",
    "[https://towardsdatascience.com/how-to-cluster-in-high-dimensions-4ef693bacc6] [1/11/2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv1",
   "language": "python",
   "name": "myenv1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
