{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 300)\n",
    "        self.fc2 = nn.Linear(300, 100)\n",
    "        self.fc3 = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(\"LeNET_300_100_MNIST_Model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 24, 24]             156\n",
      "         MaxPool2d-2            [-1, 6, 12, 12]               0\n",
      "            Conv2d-3             [-1, 16, 8, 8]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 4, 4]               0\n",
      "            Linear-5                  [-1, 300]          77,100\n",
      "            Linear-6                  [-1, 100]          30,100\n",
      "            Linear-7                   [-1, 10]           1,010\n",
      "================================================================\n",
      "Total params: 110,782\n",
      "Trainable params: 110,782\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.05\n",
      "Params size (MB): 0.42\n",
      "Estimated Total Size (MB): 0.47\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "device=torch.device(\"cpu\")\n",
    "model=Net().to(device)\n",
    "summary(model, input_size=(1, 28, 28), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight \t torch.Size([6, 1, 5, 5])\n",
      "conv1.weight \t tensor([[[[ 0.1954,  0.0121,  0.1640,  0.1464,  0.2705],\n",
      "          [ 0.1304, -0.0403,  0.1433,  0.0456, -0.0522],\n",
      "          [-0.2085, -0.1837, -0.1483, -0.0032, -0.1035],\n",
      "          [-0.0852, -0.0686,  0.1133, -0.1955, -0.1933],\n",
      "          [-0.0814, -0.1062, -0.2126, -0.1033,  0.0747]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1493,  0.1061, -0.1931, -0.0537, -0.1221],\n",
      "          [ 0.1064, -0.1001, -0.1260, -0.1717, -0.0048],\n",
      "          [-0.0145, -0.1327, -0.0277, -0.1975,  0.1304],\n",
      "          [-0.1494, -0.0456, -0.0669, -0.0927, -0.0431],\n",
      "          [ 0.2032,  0.1092, -0.0361, -0.0539, -0.1006]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1150, -0.0196, -0.0178, -0.1776, -0.1723],\n",
      "          [ 0.2551,  0.1801,  0.1082, -0.1142, -0.1189],\n",
      "          [ 0.0085, -0.0342, -0.0729, -0.1232,  0.0946],\n",
      "          [ 0.1271,  0.1823,  0.1615,  0.0363,  0.2306],\n",
      "          [ 0.2858,  0.2635, -0.0239,  0.1917, -0.0294]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2501,  0.1590,  0.1105,  0.1619, -0.1553],\n",
      "          [-0.0840,  0.0108,  0.2862, -0.0134, -0.1037],\n",
      "          [-0.0597,  0.2434,  0.2784,  0.2254,  0.3075],\n",
      "          [ 0.0174,  0.2404,  0.3834,  0.3639,  0.0302],\n",
      "          [ 0.2627, -0.0067,  0.2235,  0.3650,  0.1813]]],\n",
      "\n",
      "\n",
      "        [[[-0.1263, -0.0693, -0.1679, -0.2231,  0.0816],\n",
      "          [-0.0607, -0.0285, -0.0377, -0.1271, -0.1272],\n",
      "          [ 0.2056,  0.2435, -0.0953,  0.2570,  0.0789],\n",
      "          [ 0.2866,  0.1053,  0.1949,  0.3653,  0.3196],\n",
      "          [ 0.2184,  0.2387,  0.2585,  0.1190,  0.3265]]],\n",
      "\n",
      "\n",
      "        [[[-0.0839, -0.0380, -0.0515,  0.1580,  0.1544],\n",
      "          [ 0.0305,  0.2044, -0.1041,  0.0227,  0.1643],\n",
      "          [-0.0531,  0.2450,  0.0948,  0.2567, -0.1435],\n",
      "          [ 0.2376,  0.0989,  0.0405,  0.1566,  0.0509],\n",
      "          [ 0.0340,  0.1445,  0.0654, -0.2096, -0.0504]]]])\n",
      "conv1.bias \t torch.Size([6])\n",
      "conv1.bias \t tensor([0.0889, 0.2020, 0.0691, 0.1976, 0.1579, 0.0756])\n",
      "conv2.weight \t torch.Size([16, 6, 5, 5])\n",
      "conv2.weight \t tensor([[[[-0.0274,  0.0668,  0.0488,  0.0398, -0.0665],\n",
      "          [-0.0608,  0.0753, -0.0379, -0.0708, -0.0499],\n",
      "          [ 0.0213, -0.0393,  0.0602,  0.0631, -0.0172],\n",
      "          [-0.0192, -0.0213,  0.0593,  0.0295, -0.0479],\n",
      "          [ 0.0122,  0.0283, -0.0171, -0.0418,  0.0804]],\n",
      "\n",
      "         [[ 0.0871, -0.0707,  0.0819,  0.0117,  0.0575],\n",
      "          [-0.0282,  0.0007,  0.0180, -0.0617, -0.0293],\n",
      "          [ 0.0198,  0.0782,  0.0392, -0.0338, -0.0277],\n",
      "          [ 0.0431, -0.0100,  0.0603, -0.0399,  0.0026],\n",
      "          [-0.0332,  0.0662,  0.0012,  0.0095, -0.0582]],\n",
      "\n",
      "         [[ 0.0561,  0.0449,  0.0354, -0.0410,  0.0272],\n",
      "          [ 0.0724,  0.0942, -0.0040,  0.0277,  0.0081],\n",
      "          [ 0.0270, -0.0307, -0.0064, -0.0385,  0.0159],\n",
      "          [ 0.0504,  0.0809,  0.0430,  0.0777,  0.0367],\n",
      "          [-0.0646,  0.0218, -0.0101,  0.0375,  0.0262]],\n",
      "\n",
      "         [[-0.0235, -0.0858,  0.0660, -0.0673, -0.0697],\n",
      "          [ 0.0078,  0.0719, -0.0181, -0.0195,  0.0016],\n",
      "          [-0.0454,  0.0570, -0.0294, -0.0274, -0.0372],\n",
      "          [ 0.1082,  0.1210,  0.0632,  0.0684,  0.0632],\n",
      "          [-0.0152,  0.0922,  0.0799,  0.1105, -0.0550]],\n",
      "\n",
      "         [[-0.0672, -0.0104,  0.0473,  0.0385,  0.0964],\n",
      "          [ 0.0294,  0.0533, -0.0258,  0.0533,  0.0414],\n",
      "          [ 0.0365,  0.0543,  0.0292, -0.0066,  0.0188],\n",
      "          [ 0.0268, -0.0114,  0.0575,  0.1129, -0.0054],\n",
      "          [ 0.0972,  0.0768,  0.1025, -0.0427, -0.0169]],\n",
      "\n",
      "         [[-0.0726, -0.0107,  0.0061,  0.0363, -0.0062],\n",
      "          [-0.0734,  0.0782, -0.0339,  0.0575, -0.0311],\n",
      "          [-0.0074,  0.0626, -0.0644,  0.0099, -0.0562],\n",
      "          [-0.0196,  0.0570, -0.0007,  0.0815,  0.0461],\n",
      "          [ 0.0594,  0.0185, -0.0351,  0.0521,  0.0984]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0114,  0.1024,  0.0786,  0.0144, -0.0073],\n",
      "          [ 0.0595,  0.0455, -0.0794, -0.0819,  0.0102],\n",
      "          [-0.0503,  0.0029, -0.0508, -0.0293, -0.0326],\n",
      "          [-0.0022, -0.0103,  0.1001,  0.0145,  0.0315],\n",
      "          [ 0.0466,  0.0812,  0.0668, -0.0131,  0.0648]],\n",
      "\n",
      "         [[ 0.0362, -0.0251,  0.0047,  0.0651, -0.0518],\n",
      "          [-0.0333, -0.0493, -0.0060, -0.0515,  0.0144],\n",
      "          [-0.0453, -0.0071,  0.0713, -0.0002,  0.0601],\n",
      "          [ 0.0812,  0.0047,  0.0654,  0.0468, -0.0322],\n",
      "          [ 0.0833, -0.0038,  0.0879,  0.0529, -0.0114]],\n",
      "\n",
      "         [[ 0.0401, -0.0260,  0.0052, -0.0704,  0.0453],\n",
      "          [-0.0636, -0.0824, -0.0109, -0.0080,  0.1137],\n",
      "          [ 0.0415, -0.0511, -0.0592,  0.0319,  0.0749],\n",
      "          [-0.0010, -0.0853,  0.0453,  0.0482,  0.0497],\n",
      "          [ 0.0315, -0.0261,  0.0280, -0.0704,  0.0084]],\n",
      "\n",
      "         [[ 0.0275, -0.0780, -0.0226,  0.1107,  0.0456],\n",
      "          [ 0.0677, -0.0909,  0.0061,  0.0381,  0.1153],\n",
      "          [-0.0139,  0.0046, -0.0138,  0.0801, -0.0193],\n",
      "          [-0.0538,  0.0012,  0.0109,  0.0946,  0.0835],\n",
      "          [-0.0782, -0.0925,  0.0232, -0.0251,  0.0054]],\n",
      "\n",
      "         [[ 0.0406, -0.0635,  0.0678,  0.0119,  0.0286],\n",
      "          [ 0.0131,  0.0114, -0.0431, -0.0450,  0.0757],\n",
      "          [ 0.0367,  0.0135, -0.0189, -0.0541,  0.0548],\n",
      "          [-0.0035,  0.0002,  0.0537, -0.0344, -0.0208],\n",
      "          [ 0.0619, -0.0228, -0.0419, -0.0491, -0.0564]],\n",
      "\n",
      "         [[ 0.0369, -0.0360, -0.0599,  0.0695,  0.0653],\n",
      "          [ 0.0340,  0.0286,  0.0532,  0.0393,  0.0815],\n",
      "          [ 0.0569, -0.0509,  0.0329, -0.0111,  0.0541],\n",
      "          [ 0.0452,  0.0620,  0.0273,  0.0446, -0.0114],\n",
      "          [-0.0536,  0.0362,  0.0610, -0.0087,  0.0545]]],\n",
      "\n",
      "\n",
      "        [[[-0.0435, -0.0409,  0.0214, -0.0245, -0.0470],\n",
      "          [-0.0648,  0.0276,  0.0549,  0.0553, -0.0518],\n",
      "          [ 0.0363, -0.0539,  0.0507, -0.0488, -0.0804],\n",
      "          [-0.0775, -0.0526,  0.0312,  0.0551,  0.0234],\n",
      "          [-0.0068,  0.0559, -0.0245,  0.0723, -0.0541]],\n",
      "\n",
      "         [[-0.0349,  0.0069, -0.0183, -0.0539, -0.0567],\n",
      "          [ 0.0241,  0.0163, -0.0367, -0.0296,  0.0207],\n",
      "          [-0.0484,  0.0468,  0.0486, -0.0618,  0.0803],\n",
      "          [-0.0575,  0.0382, -0.0458,  0.0376, -0.0709],\n",
      "          [ 0.0544,  0.0047,  0.0612,  0.0189, -0.0036]],\n",
      "\n",
      "         [[ 0.0300,  0.0635, -0.0530, -0.0549,  0.0241],\n",
      "          [-0.0594, -0.0401,  0.0664, -0.0185, -0.0817],\n",
      "          [-0.0298,  0.0741,  0.0713, -0.0260,  0.0608],\n",
      "          [ 0.0465,  0.0736,  0.0003, -0.0390,  0.0363],\n",
      "          [ 0.0037, -0.0807, -0.0299, -0.0517,  0.0294]],\n",
      "\n",
      "         [[-0.0792,  0.0780,  0.0514, -0.0699, -0.0856],\n",
      "          [-0.0144, -0.0430,  0.0017,  0.0204,  0.0092],\n",
      "          [ 0.0030,  0.0179,  0.0450, -0.0480,  0.0482],\n",
      "          [ 0.0107,  0.0552,  0.0846,  0.0534, -0.0309],\n",
      "          [-0.0794, -0.0152, -0.0460,  0.0496,  0.0278]],\n",
      "\n",
      "         [[-0.0479, -0.0191,  0.0219,  0.0451, -0.0755],\n",
      "          [-0.0379,  0.0345, -0.0048,  0.0316, -0.0598],\n",
      "          [-0.0453,  0.0268,  0.0861,  0.0482,  0.0782],\n",
      "          [ 0.0281,  0.0489,  0.0117, -0.0046,  0.0457],\n",
      "          [-0.0529, -0.0806,  0.0494,  0.0352,  0.0617]],\n",
      "\n",
      "         [[-0.0768,  0.0607,  0.0444,  0.0540, -0.0495],\n",
      "          [ 0.0513, -0.0188, -0.0549, -0.0502, -0.0427],\n",
      "          [ 0.0179, -0.0705, -0.0647,  0.0449,  0.0746],\n",
      "          [-0.0253, -0.0430, -0.0533,  0.0573,  0.0787],\n",
      "          [-0.0562, -0.0676,  0.0715, -0.0026,  0.0565]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0867,  0.0743,  0.0552, -0.0527,  0.0324],\n",
      "          [ 0.0953, -0.0199, -0.0295, -0.0403,  0.0669],\n",
      "          [-0.0332, -0.0047,  0.0819,  0.0500, -0.0737],\n",
      "          [ 0.0702,  0.0296,  0.0512, -0.0141, -0.0785],\n",
      "          [ 0.0105, -0.0372,  0.0275, -0.0444,  0.0801]],\n",
      "\n",
      "         [[ 0.0696,  0.0756, -0.0469, -0.0089,  0.0436],\n",
      "          [-0.0002,  0.0689,  0.0646, -0.0738,  0.0002],\n",
      "          [ 0.0474,  0.0280,  0.0370, -0.0493,  0.0114],\n",
      "          [ 0.0923,  0.0150, -0.0433,  0.0001,  0.0055],\n",
      "          [ 0.0284,  0.0790, -0.0025,  0.0587,  0.0567]],\n",
      "\n",
      "         [[ 0.0074, -0.0313, -0.0270,  0.0253,  0.1055],\n",
      "          [ 0.0361, -0.0577, -0.0685,  0.0318,  0.1180],\n",
      "          [-0.0353,  0.0548, -0.0407,  0.0525,  0.0153],\n",
      "          [ 0.0303,  0.0579, -0.0119, -0.0442, -0.0267],\n",
      "          [-0.0016,  0.0065,  0.0044, -0.0504,  0.0356]],\n",
      "\n",
      "         [[-0.0432, -0.0143,  0.0811,  0.1546,  0.0607],\n",
      "          [-0.0778, -0.0240, -0.0319, -0.0030,  0.1579],\n",
      "          [-0.0280, -0.0699, -0.0876, -0.0119,  0.0790],\n",
      "          [-0.0983,  0.0210, -0.0514,  0.0689,  0.0750],\n",
      "          [ 0.0074, -0.0144, -0.0070,  0.1365,  0.0485]],\n",
      "\n",
      "         [[-0.0079,  0.0315,  0.0655,  0.1064,  0.0607],\n",
      "          [-0.0207,  0.0698, -0.0483,  0.0416, -0.0130],\n",
      "          [-0.0263, -0.0218, -0.0671, -0.0247, -0.0565],\n",
      "          [-0.0670,  0.0891, -0.0003,  0.0927,  0.0647],\n",
      "          [ 0.0704,  0.1173,  0.1078,  0.0087,  0.0593]],\n",
      "\n",
      "         [[-0.0422, -0.0288,  0.0488, -0.0428,  0.0470],\n",
      "          [ 0.0696,  0.0237, -0.0314,  0.0103,  0.0643],\n",
      "          [ 0.0073,  0.0481,  0.0067, -0.0726,  0.1036],\n",
      "          [-0.0580,  0.0370,  0.0404,  0.0295,  0.1155],\n",
      "          [-0.0567,  0.0523, -0.0587,  0.1055,  0.0410]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0494,  0.0188, -0.0594,  0.0070, -0.0301],\n",
      "          [-0.0539,  0.0506, -0.0009,  0.0335, -0.0584],\n",
      "          [-0.0223, -0.0533, -0.0312,  0.0398,  0.0861],\n",
      "          [ 0.1027,  0.0827, -0.0508, -0.0525,  0.0070],\n",
      "          [-0.0051, -0.0598, -0.0588,  0.0543, -0.0164]],\n",
      "\n",
      "         [[-0.0394, -0.0533,  0.0378,  0.0225, -0.0490],\n",
      "          [ 0.0349,  0.0437, -0.0357,  0.0521,  0.0238],\n",
      "          [-0.0905, -0.0332, -0.0659,  0.0634, -0.0678],\n",
      "          [-0.0556,  0.0413,  0.0085,  0.0435, -0.0020],\n",
      "          [ 0.0443, -0.0254, -0.0296, -0.0663,  0.0819]],\n",
      "\n",
      "         [[-0.0185, -0.0457,  0.1023, -0.0410,  0.0640],\n",
      "          [ 0.0264,  0.0874,  0.0540,  0.0342,  0.0361],\n",
      "          [-0.0413,  0.0394, -0.0428,  0.0182,  0.0852],\n",
      "          [-0.0026, -0.0659,  0.0330,  0.0022, -0.0459],\n",
      "          [ 0.0110,  0.0995,  0.0537,  0.0596,  0.0756]],\n",
      "\n",
      "         [[ 0.1012,  0.1081,  0.1025,  0.0072,  0.0945],\n",
      "          [ 0.1049,  0.0643, -0.0273, -0.0367, -0.0208],\n",
      "          [ 0.1000, -0.0200,  0.0096, -0.0624, -0.0181],\n",
      "          [ 0.0792,  0.0939,  0.0946, -0.0568,  0.0760],\n",
      "          [-0.0009,  0.0744,  0.0837,  0.0012,  0.0194]],\n",
      "\n",
      "         [[ 0.0291,  0.1435,  0.1299,  0.0036,  0.0871],\n",
      "          [ 0.1035,  0.1228,  0.0380,  0.0254, -0.0240],\n",
      "          [ 0.0477, -0.0669, -0.0055,  0.0057,  0.0287],\n",
      "          [-0.0513, -0.0424,  0.0483, -0.0601,  0.0486],\n",
      "          [ 0.0921,  0.1021,  0.0908,  0.0888,  0.0490]],\n",
      "\n",
      "         [[-0.0384, -0.0154,  0.0436, -0.0105,  0.0451],\n",
      "          [ 0.0901,  0.0776, -0.0301,  0.0690, -0.0309],\n",
      "          [ 0.1104,  0.0425,  0.0419, -0.0453,  0.0458],\n",
      "          [-0.0307, -0.0534, -0.0394,  0.0236,  0.0465],\n",
      "          [-0.0692, -0.0183,  0.0089, -0.0206,  0.0389]]],\n",
      "\n",
      "\n",
      "        [[[-0.0020,  0.0751,  0.0134,  0.0531,  0.0574],\n",
      "          [ 0.0035, -0.0578,  0.0161,  0.0412,  0.0589],\n",
      "          [-0.0216, -0.0487,  0.0395,  0.0251,  0.0705],\n",
      "          [-0.0222, -0.0647, -0.0208, -0.0473, -0.0246],\n",
      "          [-0.0302,  0.0293,  0.0256, -0.0031, -0.0733]],\n",
      "\n",
      "         [[ 0.0202,  0.0780,  0.0265,  0.0221,  0.0742],\n",
      "          [-0.0200,  0.0266, -0.0203, -0.0096, -0.0161],\n",
      "          [ 0.0744,  0.0783,  0.0429, -0.0358,  0.0033],\n",
      "          [ 0.0600, -0.0126,  0.0445, -0.0565,  0.0733],\n",
      "          [-0.0548, -0.0381, -0.0142,  0.0790,  0.0888]],\n",
      "\n",
      "         [[-0.0486, -0.0391, -0.0214,  0.0725,  0.0748],\n",
      "          [-0.0770, -0.0661,  0.0356, -0.0094, -0.0375],\n",
      "          [-0.0385,  0.0706, -0.0204, -0.0250, -0.0701],\n",
      "          [-0.0112, -0.0123,  0.0035,  0.0503, -0.0716],\n",
      "          [ 0.0283, -0.0026, -0.0314, -0.0128, -0.0613]],\n",
      "\n",
      "         [[-0.0692, -0.0151, -0.0098,  0.0471,  0.0380],\n",
      "          [-0.0333, -0.0265,  0.0236,  0.1058, -0.0391],\n",
      "          [ 0.0353,  0.0279,  0.0909,  0.0711, -0.0662],\n",
      "          [-0.0403,  0.0075,  0.0402, -0.0218,  0.0152],\n",
      "          [ 0.0320, -0.0144, -0.0312,  0.0275, -0.0524]],\n",
      "\n",
      "         [[-0.0635, -0.0759, -0.0257,  0.0932,  0.0480],\n",
      "          [-0.0533, -0.0012,  0.0481,  0.0972, -0.0115],\n",
      "          [ 0.0317,  0.0682, -0.0040,  0.0312,  0.0618],\n",
      "          [-0.0353,  0.0874,  0.0021, -0.0651, -0.0505],\n",
      "          [-0.0716, -0.0393,  0.0481, -0.0397, -0.0488]],\n",
      "\n",
      "         [[ 0.0703, -0.0039, -0.0368,  0.0487,  0.0421],\n",
      "          [-0.0564,  0.0273, -0.0645,  0.0598, -0.0491],\n",
      "          [ 0.0688, -0.0356,  0.0441,  0.0353, -0.0540],\n",
      "          [-0.0733,  0.0374, -0.0255,  0.0311, -0.0593],\n",
      "          [-0.0586, -0.0194, -0.0267,  0.0013,  0.0008]]]])\n",
      "conv2.bias \t torch.Size([16])\n",
      "conv2.bias \t tensor([ 0.0678, -0.0424, -0.0553, -0.0554, -0.0523, -0.0426,  0.0439, -0.0724,\n",
      "         0.0329, -0.0029,  0.0769,  0.0866,  0.0797, -0.0330, -0.0008, -0.0292])\n",
      "fc1.weight \t torch.Size([300, 256])\n",
      "fc1.weight \t tensor([[ 0.0075, -0.0228,  0.0441,  ...,  0.0379,  0.0472, -0.0569],\n",
      "        [-0.0543,  0.0214,  0.0101,  ...,  0.0456, -0.0507,  0.0105],\n",
      "        [-0.0553, -0.0464, -0.0453,  ...,  0.0590,  0.0510, -0.0612],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0726,  0.0488,  ...,  0.0495, -0.0552,  0.0553],\n",
      "        [ 0.0282,  0.0514, -0.0187,  ..., -0.0511,  0.0008, -0.0110],\n",
      "        [ 0.0377,  0.0453, -0.0087,  ..., -0.0149,  0.0576,  0.0590]])\n",
      "fc1.bias \t torch.Size([300])\n",
      "fc1.bias \t tensor([-0.0613, -0.0096,  0.0004,  0.0227, -0.0270,  0.0271, -0.0524, -0.0336,\n",
      "         0.0488, -0.0171,  0.0535, -0.0261,  0.0042,  0.0027, -0.0281,  0.0008,\n",
      "        -0.0528, -0.0025,  0.0006, -0.0046, -0.0006,  0.0142, -0.0409,  0.0599,\n",
      "         0.0513, -0.0374,  0.0186,  0.0505,  0.0519, -0.0291, -0.0098,  0.0555,\n",
      "        -0.0124, -0.0360,  0.0028,  0.0044, -0.0460,  0.0139, -0.0303,  0.0069,\n",
      "        -0.0449, -0.0036,  0.0203,  0.0664,  0.0219, -0.0148,  0.0184,  0.0326,\n",
      "         0.0358, -0.0465, -0.0083, -0.0321, -0.0350, -0.0389, -0.0196,  0.0551,\n",
      "        -0.0545,  0.0617, -0.0530,  0.0079, -0.0598,  0.0029, -0.0224,  0.0247,\n",
      "        -0.0024, -0.0387, -0.0484, -0.0210, -0.0130, -0.0341,  0.0596, -0.0330,\n",
      "        -0.0460, -0.0284, -0.0112, -0.0368, -0.0115, -0.0361, -0.0175,  0.0584,\n",
      "         0.0427,  0.0172, -0.0470,  0.0225,  0.0001, -0.0539, -0.0198, -0.0206,\n",
      "        -0.0474,  0.0300, -0.0206,  0.0304,  0.0077,  0.0543,  0.0369, -0.0293,\n",
      "        -0.0006, -0.0548,  0.0090, -0.0386, -0.0286, -0.0236,  0.0253, -0.0543,\n",
      "         0.0479, -0.0293, -0.0566, -0.0318, -0.0421, -0.0502, -0.0179,  0.0356,\n",
      "        -0.0113, -0.0156,  0.0410,  0.0208,  0.0515, -0.0513,  0.0613, -0.0179,\n",
      "        -0.0052, -0.0395, -0.0129, -0.0348, -0.0474, -0.0036, -0.0013, -0.0562,\n",
      "        -0.0417,  0.0283, -0.0018,  0.0319, -0.0062,  0.0619, -0.0023, -0.0154,\n",
      "         0.0603, -0.0449, -0.0415, -0.0597,  0.0250, -0.0214,  0.0036, -0.0540,\n",
      "        -0.0414,  0.0038, -0.0557,  0.0536,  0.0662, -0.0447, -0.0171,  0.0515,\n",
      "        -0.0230,  0.0575, -0.0358,  0.0426,  0.0329, -0.0349,  0.0057, -0.0044,\n",
      "         0.0258,  0.0143, -0.0044, -0.0573, -0.0268,  0.0394,  0.0515,  0.0587,\n",
      "         0.0462,  0.0249,  0.0384, -0.0013,  0.0533,  0.0363,  0.0159,  0.0579,\n",
      "         0.0479,  0.0252,  0.0516,  0.0314,  0.0345,  0.0142, -0.0303, -0.0408,\n",
      "        -0.0300, -0.0522,  0.0357, -0.0150,  0.0452,  0.0489,  0.0024,  0.0146,\n",
      "         0.0366, -0.0234,  0.0065,  0.0575, -0.0268, -0.0289,  0.0387,  0.0149,\n",
      "        -0.0175,  0.0521, -0.0654,  0.0326, -0.0079, -0.0122,  0.0475,  0.0591,\n",
      "         0.0233,  0.0336,  0.0452, -0.0177, -0.0461,  0.0099,  0.0045,  0.0245,\n",
      "         0.0306, -0.0502,  0.0449, -0.0544,  0.0600, -0.0209, -0.0216, -0.0098,\n",
      "         0.0146, -0.0193, -0.0481, -0.0541,  0.0361, -0.0071, -0.0160,  0.0270,\n",
      "         0.0237,  0.0131,  0.0492, -0.0054, -0.0510,  0.0219, -0.0348,  0.0611,\n",
      "        -0.0599, -0.0110, -0.0619,  0.0599,  0.0491, -0.0079,  0.0456, -0.0130,\n",
      "         0.0630,  0.0108, -0.0462, -0.0473, -0.0256, -0.0485, -0.0188,  0.0455,\n",
      "        -0.0275,  0.0550, -0.0004,  0.0118,  0.0539,  0.0278, -0.0377,  0.0516,\n",
      "        -0.0471, -0.0175, -0.0171, -0.0404,  0.0351, -0.0343, -0.0453, -0.0176,\n",
      "         0.0073, -0.0034, -0.0159,  0.0162,  0.0569, -0.0132,  0.0238,  0.0627,\n",
      "        -0.0387,  0.0533,  0.0147,  0.0207, -0.0230,  0.0267,  0.0347, -0.0476,\n",
      "         0.0110, -0.0175, -0.0011, -0.0376,  0.0536,  0.0385,  0.0583, -0.0534,\n",
      "         0.0111, -0.0582, -0.0494, -0.0061])\n",
      "fc2.weight \t torch.Size([100, 300])\n",
      "fc2.weight \t tensor([[-0.0052, -0.0047,  0.0493,  ...,  0.0129, -0.0062,  0.0570],\n",
      "        [ 0.0247,  0.0198, -0.0286,  ..., -0.0296, -0.0601,  0.0437],\n",
      "        [-0.0416, -0.0223, -0.0210,  ..., -0.0089,  0.0154, -0.0125],\n",
      "        ...,\n",
      "        [ 0.0504,  0.0257,  0.0032,  ...,  0.0427, -0.0514, -0.0526],\n",
      "        [-0.0472, -0.0357,  0.0194,  ...,  0.0204, -0.0042, -0.0297],\n",
      "        [-0.0193, -0.0199,  0.0532,  ...,  0.0298,  0.0172,  0.0558]])\n",
      "fc2.bias \t torch.Size([100])\n",
      "fc2.bias \t tensor([-0.0478,  0.0164,  0.0575, -0.0453,  0.0055, -0.0306, -0.0436, -0.0382,\n",
      "        -0.0327, -0.0289, -0.0538,  0.0604, -0.0405, -0.0221,  0.0478, -0.0396,\n",
      "         0.0512,  0.0441, -0.0344, -0.0511,  0.0191,  0.0464,  0.0358, -0.0286,\n",
      "         0.0001,  0.0551, -0.0305,  0.0320, -0.0183,  0.0414, -0.0293, -0.0355,\n",
      "         0.0163,  0.0311, -0.0088,  0.0357,  0.0183,  0.0204, -0.0518, -0.0276,\n",
      "         0.0451,  0.0416, -0.0216,  0.0268,  0.0062,  0.0445, -0.0164,  0.0325,\n",
      "         0.0003,  0.0565, -0.0114, -0.0467,  0.0377, -0.0437, -0.0243,  0.0100,\n",
      "        -0.0268,  0.0646,  0.0341,  0.0212, -0.0423,  0.0461, -0.0142,  0.0245,\n",
      "         0.0349,  0.0400, -0.0025, -0.0210,  0.0286,  0.0610, -0.0223,  0.0475,\n",
      "        -0.0250,  0.0444, -0.0117, -0.0377,  0.0560, -0.0239, -0.0067, -0.0554,\n",
      "        -0.0620,  0.0282,  0.0504, -0.0132,  0.0691, -0.0250,  0.0534,  0.0594,\n",
      "         0.0506, -0.0099,  0.0007,  0.0260, -0.0104, -0.0088,  0.0347,  0.0226,\n",
      "        -0.0221, -0.0109, -0.0430,  0.0509])\n",
      "fc3.weight \t torch.Size([10, 100])\n",
      "fc3.weight \t tensor([[ 0.0795,  0.0035, -0.0997,  0.0182, -0.0530,  0.0718,  0.0049, -0.1053,\n",
      "          0.0444,  0.1244,  0.0431, -0.0615,  0.0780,  0.0683,  0.0801, -0.0896,\n",
      "          0.0897, -0.0004,  0.0601,  0.0294,  0.0928, -0.0028, -0.1443, -0.0655,\n",
      "         -0.0113, -0.0385,  0.0353, -0.1128,  0.0403, -0.1080,  0.0426, -0.0179,\n",
      "          0.0263, -0.0422,  0.0214, -0.0017,  0.1446, -0.0527, -0.0377, -0.0689,\n",
      "         -0.0049,  0.0576, -0.0811, -0.0461, -0.1153, -0.0113, -0.0519,  0.0626,\n",
      "         -0.0484,  0.0844,  0.0006, -0.0399,  0.0483,  0.0837,  0.0262,  0.1909,\n",
      "          0.0449, -0.0536,  0.1095, -0.0927,  0.1159, -0.0554,  0.0509,  0.0783,\n",
      "         -0.0922,  0.1104, -0.0776, -0.1221, -0.0252, -0.0717, -0.1541, -0.0952,\n",
      "          0.0397,  0.1199, -0.0490, -0.0769, -0.0381,  0.0953,  0.0950, -0.0460,\n",
      "         -0.0876, -0.1793,  0.0075,  0.0491,  0.0708, -0.1261,  0.0344, -0.0617,\n",
      "         -0.1861, -0.0297, -0.0681,  0.1610, -0.0233,  0.0094,  0.0118,  0.0473,\n",
      "          0.1037, -0.0226,  0.0257, -0.0547],\n",
      "        [-0.0297, -0.1611,  0.0652,  0.0664,  0.0782, -0.0990,  0.0335, -0.0624,\n",
      "         -0.0420,  0.0704, -0.0298, -0.0477, -0.0959,  0.0253,  0.0042,  0.1228,\n",
      "          0.0112,  0.1048, -0.0298, -0.0352, -0.0295, -0.0724, -0.0384,  0.0416,\n",
      "          0.0881,  0.0100,  0.0830,  0.0673, -0.0974,  0.0758, -0.1238, -0.0597,\n",
      "          0.0683, -0.0885, -0.0078,  0.0860,  0.0026,  0.0873,  0.0324, -0.0369,\n",
      "         -0.0037, -0.0351, -0.0617, -0.0377, -0.0592,  0.0970, -0.0869, -0.0950,\n",
      "         -0.0530,  0.0925, -0.0903,  0.0332, -0.1426,  0.0852, -0.0667, -0.1056,\n",
      "         -0.0120,  0.0919, -0.0790, -0.0071, -0.0939, -0.0588, -0.0807, -0.1217,\n",
      "          0.0873,  0.0708, -0.0001, -0.0626,  0.0566,  0.2118,  0.1036, -0.0475,\n",
      "         -0.0849, -0.0228, -0.0744,  0.0418, -0.0498, -0.0047, -0.0374, -0.0831,\n",
      "         -0.0305, -0.0348, -0.0757, -0.0970,  0.0672, -0.0091, -0.0343,  0.0608,\n",
      "          0.0147,  0.0956,  0.1191, -0.1359, -0.0940, -0.0450,  0.1518,  0.0159,\n",
      "          0.1147,  0.0449,  0.0051,  0.0011],\n",
      "        [-0.0560,  0.0528, -0.0126, -0.0443, -0.0210, -0.0820, -0.0298,  0.1131,\n",
      "          0.0000, -0.1054,  0.0048, -0.0970, -0.0901, -0.0121,  0.0419,  0.0632,\n",
      "         -0.0800, -0.0945,  0.0031, -0.0349,  0.0734, -0.1008, -0.1482,  0.0725,\n",
      "         -0.0082, -0.0856, -0.0252, -0.1216, -0.0362, -0.0870, -0.0487, -0.0577,\n",
      "         -0.1287, -0.0975, -0.0104, -0.0170,  0.0230,  0.0749,  0.0937,  0.0038,\n",
      "          0.1048,  0.1179,  0.0553,  0.1456, -0.0562, -0.0353, -0.0233,  0.1190,\n",
      "          0.0605, -0.1075,  0.0092, -0.0230,  0.0603,  0.0415,  0.0056, -0.1043,\n",
      "         -0.0410,  0.1277, -0.0691,  0.0893, -0.0297,  0.0444, -0.0157,  0.0850,\n",
      "          0.0591, -0.0783, -0.0688,  0.1321, -0.1360,  0.0962,  0.0934,  0.1217,\n",
      "          0.0552,  0.1016, -0.1211, -0.0320, -0.0930,  0.0344, -0.0152,  0.0525,\n",
      "          0.0148, -0.0148, -0.0496,  0.1119,  0.0282, -0.0791,  0.0832,  0.0232,\n",
      "         -0.0917,  0.0191,  0.0368, -0.0389,  0.1003,  0.0200,  0.0214, -0.1064,\n",
      "          0.0925, -0.0087, -0.0852,  0.0042],\n",
      "        [ 0.0459,  0.0069,  0.1189, -0.0167, -0.0551,  0.0398,  0.0925,  0.0074,\n",
      "          0.0627, -0.0570,  0.0970, -0.0760, -0.0171,  0.0890,  0.0447,  0.1136,\n",
      "          0.0424,  0.0897, -0.0889,  0.0859,  0.0433,  0.0774, -0.0585, -0.0083,\n",
      "          0.0123, -0.0775, -0.0537, -0.0362,  0.0513,  0.0494,  0.1099, -0.0216,\n",
      "         -0.1173,  0.1350,  0.0438, -0.0462, -0.0211,  0.0758, -0.0553, -0.0745,\n",
      "          0.0526,  0.0117,  0.0672, -0.0585,  0.0510, -0.0944,  0.1552, -0.0975,\n",
      "         -0.0155,  0.0497, -0.0548, -0.0767,  0.1434, -0.0453,  0.0973,  0.0397,\n",
      "          0.0813, -0.0500, -0.1110,  0.0536, -0.0819, -0.0591, -0.0364, -0.1230,\n",
      "         -0.0725, -0.1050,  0.0612, -0.0845,  0.1112, -0.0755,  0.0461, -0.0112,\n",
      "         -0.0048, -0.0101,  0.0154, -0.0149, -0.0924,  0.0629,  0.0695,  0.0073,\n",
      "          0.0938,  0.0261, -0.0396,  0.0956,  0.0046, -0.0709,  0.1029,  0.1808,\n",
      "         -0.0170,  0.0598, -0.0201,  0.0419,  0.0920, -0.0283,  0.0558, -0.0752,\n",
      "         -0.0772, -0.0154,  0.0108,  0.0371],\n",
      "        [-0.0701,  0.1243, -0.0453, -0.0471, -0.0608,  0.0672, -0.0456,  0.0959,\n",
      "         -0.0891,  0.0886,  0.0849,  0.0286, -0.0505,  0.0172,  0.0579,  0.0447,\n",
      "         -0.0049, -0.0081,  0.0198, -0.0124, -0.0546, -0.0567,  0.1864, -0.0744,\n",
      "          0.0803,  0.1326, -0.0781,  0.0904, -0.0650,  0.0298, -0.1398, -0.0029,\n",
      "         -0.0046, -0.0567, -0.1270,  0.0771, -0.1098, -0.0218,  0.0771, -0.0875,\n",
      "          0.0864, -0.0251,  0.0057, -0.0704, -0.1194, -0.0793,  0.0565, -0.0145,\n",
      "         -0.0346,  0.0076,  0.0882, -0.0089,  0.0245, -0.0723, -0.1311, -0.1812,\n",
      "         -0.0476, -0.0061,  0.0049, -0.1043,  0.0247, -0.1009, -0.0693, -0.0697,\n",
      "          0.1387,  0.0085,  0.0888, -0.0259,  0.0192,  0.0029, -0.1109,  0.0047,\n",
      "          0.0167, -0.0395,  0.0351, -0.0675,  0.0409, -0.0002, -0.0430,  0.0647,\n",
      "         -0.0808, -0.0710, -0.0045,  0.0547, -0.1131,  0.1176,  0.1072, -0.0589,\n",
      "          0.0123,  0.0968, -0.0659, -0.1270, -0.0547,  0.0347, -0.0892,  0.1177,\n",
      "         -0.1130,  0.0523, -0.0446, -0.0150],\n",
      "        [-0.0081,  0.0106, -0.0736, -0.0367, -0.0554, -0.0636,  0.0172,  0.0956,\n",
      "         -0.0863, -0.0319,  0.0092,  0.0223,  0.0121,  0.0511, -0.0987,  0.0004,\n",
      "          0.0668, -0.0621,  0.0609,  0.0553,  0.0553, -0.0685,  0.0650,  0.0392,\n",
      "          0.0924, -0.1250,  0.0299,  0.0848, -0.0486, -0.1024,  0.1097, -0.0693,\n",
      "          0.0278, -0.0763,  0.0937, -0.0431, -0.0397, -0.0989,  0.0733,  0.0249,\n",
      "         -0.0203,  0.1271,  0.0332, -0.1134,  0.0807, -0.0365,  0.0561, -0.0995,\n",
      "          0.0007, -0.0865,  0.0957,  0.0385, -0.0363,  0.0928, -0.0438,  0.1309,\n",
      "          0.0609, -0.0880,  0.0041, -0.0264, -0.0456,  0.0676,  0.0029, -0.0908,\n",
      "          0.0174, -0.0940,  0.0112, -0.1042,  0.0964, -0.0836,  0.0066,  0.0683,\n",
      "          0.0171, -0.0927,  0.1042, -0.0024, -0.0994, -0.0426, -0.0840, -0.0571,\n",
      "         -0.0190,  0.0750, -0.0558, -0.0991,  0.0420,  0.0430,  0.0379,  0.0335,\n",
      "          0.0537, -0.1216, -0.0177,  0.1339,  0.0439,  0.0161, -0.0266,  0.1239,\n",
      "          0.0652,  0.0585,  0.0024, -0.0647],\n",
      "        [ 0.0426,  0.1366,  0.0149,  0.0313,  0.0019,  0.0342,  0.0797,  0.1597,\n",
      "         -0.0771,  0.0276, -0.0568,  0.0626,  0.0906, -0.0149, -0.0119, -0.0851,\n",
      "         -0.1103, -0.0948,  0.0352,  0.0361,  0.0101,  0.0750,  0.0590, -0.0020,\n",
      "         -0.0181,  0.0975,  0.0501,  0.0631,  0.0967, -0.0653, -0.0206,  0.0108,\n",
      "         -0.0967,  0.0181, -0.0368, -0.1564, -0.1075, -0.0960,  0.0878,  0.0522,\n",
      "         -0.0785, -0.0269,  0.0406, -0.0685, -0.0584,  0.0319, -0.0960, -0.0355,\n",
      "         -0.0905, -0.1030,  0.0659, -0.0735, -0.0255,  0.0347, -0.1059, -0.0026,\n",
      "          0.0460,  0.0731, -0.1016, -0.0278, -0.0102,  0.0284,  0.0784, -0.0731,\n",
      "          0.0413,  0.1442,  0.0213,  0.0390, -0.0014, -0.0742,  0.1167, -0.1370,\n",
      "         -0.1309,  0.1784,  0.0306,  0.0177,  0.0351,  0.0997, -0.0651, -0.0026,\n",
      "         -0.0155, -0.1865, -0.0604, -0.0351,  0.0494,  0.0219,  0.0441, -0.1431,\n",
      "          0.0491, -0.0818, -0.0505,  0.0308,  0.0242, -0.0735,  0.1147,  0.0001,\n",
      "          0.1261,  0.0577,  0.0896, -0.0351],\n",
      "        [-0.0206, -0.1226,  0.0356, -0.0116,  0.0018, -0.0873, -0.0051, -0.0621,\n",
      "          0.0032,  0.0876, -0.0258,  0.0360,  0.0508,  0.0205, -0.0308, -0.0156,\n",
      "          0.1182,  0.1587, -0.0443,  0.1038,  0.0900,  0.0971,  0.0486, -0.0584,\n",
      "         -0.0619,  0.1111, -0.0873,  0.0305,  0.0487,  0.1227, -0.0088,  0.0845,\n",
      "          0.0785, -0.0937, -0.0624,  0.1419,  0.1296, -0.0721, -0.0663, -0.0613,\n",
      "         -0.0016, -0.0596, -0.0091,  0.0024,  0.0326, -0.0901, -0.1095,  0.1153,\n",
      "          0.1577, -0.0507, -0.0120, -0.0987, -0.1333, -0.0367, -0.0728, -0.1406,\n",
      "         -0.0030, -0.1436, -0.0760,  0.0876, -0.0071, -0.0931, -0.0833, -0.0758,\n",
      "         -0.1194,  0.0415,  0.0088, -0.0083,  0.0790, -0.1185, -0.0859,  0.0686,\n",
      "         -0.0055, -0.1396, -0.0169, -0.0843, -0.0088, -0.0199, -0.0245,  0.0113,\n",
      "          0.0524,  0.1432, -0.1314,  0.0056, -0.0549, -0.1331,  0.0864, -0.0532,\n",
      "         -0.0476, -0.0658, -0.0576,  0.1016, -0.0342,  0.1413, -0.0902,  0.0924,\n",
      "          0.0662, -0.0891, -0.0118,  0.0833],\n",
      "        [-0.0396, -0.0055, -0.0277,  0.0650,  0.0436, -0.0736, -0.0797, -0.0358,\n",
      "         -0.0834,  0.0214, -0.0478, -0.0245,  0.0703,  0.0531,  0.0775,  0.0112,\n",
      "         -0.0595,  0.0595, -0.0321,  0.0231, -0.1206, -0.0653,  0.0743,  0.0557,\n",
      "         -0.0466, -0.1264, -0.1060, -0.1179, -0.0321,  0.1047,  0.0646,  0.0161,\n",
      "          0.0802, -0.0783,  0.1232, -0.1138, -0.0923,  0.0981, -0.0035, -0.0333,\n",
      "          0.0258, -0.1039, -0.0452,  0.1040,  0.0470, -0.0814,  0.0054, -0.0447,\n",
      "          0.0201,  0.0037,  0.0486,  0.0823, -0.0364, -0.0788,  0.0171,  0.0699,\n",
      "         -0.0973, -0.0529, -0.0630,  0.0603,  0.0443, -0.0823, -0.0709,  0.1293,\n",
      "         -0.0524, -0.0527, -0.0546, -0.0626,  0.1033, -0.1295, -0.0539, -0.0705,\n",
      "         -0.0926,  0.0518,  0.0547, -0.0114,  0.0157,  0.0877,  0.0579,  0.0892,\n",
      "          0.0937,  0.0785,  0.0942, -0.0275, -0.1255,  0.0854, -0.1306, -0.0793,\n",
      "          0.1026,  0.0651, -0.0213, -0.0918,  0.0396,  0.0099,  0.0736, -0.0697,\n",
      "          0.0809,  0.1373,  0.0740,  0.0324],\n",
      "        [-0.1336, -0.0049,  0.0835,  0.0814,  0.0385,  0.0639, -0.0533, -0.1283,\n",
      "         -0.0274, -0.0968, -0.0880,  0.0850,  0.0517,  0.0464, -0.0010,  0.0037,\n",
      "         -0.0854, -0.0439, -0.0969, -0.0801, -0.0911,  0.0875,  0.1139, -0.0042,\n",
      "         -0.0341,  0.0202,  0.0509,  0.0351,  0.0059,  0.1383, -0.0375, -0.0009,\n",
      "          0.1446, -0.0065, -0.0318,  0.1019, -0.0845, -0.0476, -0.0921,  0.0089,\n",
      "          0.1081, -0.1064, -0.0294, -0.0360, -0.0079,  0.0265,  0.0658, -0.0076,\n",
      "          0.0819, -0.0207,  0.0609, -0.0676, -0.0246, -0.0117,  0.0785, -0.1663,\n",
      "         -0.0038, -0.0351, -0.1097,  0.0533,  0.1123, -0.0234, -0.0224,  0.0156,\n",
      "          0.0768, -0.1239, -0.1049, -0.0617, -0.0692, -0.0726, -0.1300,  0.1348,\n",
      "          0.0966,  0.0435, -0.0037,  0.0589,  0.0339,  0.0304, -0.0222, -0.0151,\n",
      "          0.0959,  0.0121,  0.0692, -0.0090, -0.0556,  0.0258, -0.0618, -0.0388,\n",
      "         -0.1058,  0.0235, -0.0997,  0.0612, -0.0422,  0.0670, -0.1051,  0.0867,\n",
      "         -0.0661, -0.1033, -0.0301, -0.1139]])\n",
      "fc3.bias \t torch.Size([10])\n",
      "fc3.bias \t tensor([ 0.0504,  0.1393, -0.0627, -0.0188,  0.0212, -0.0102, -0.0827, -0.0165,\n",
      "        -0.1006, -0.0129])\n"
     ]
    }
   ],
   "source": [
    "for param_tensor in net.state_dict():\n",
    "    print(param_tensor, \"\\t\", net.state_dict()[param_tensor].size())\n",
    "    print(param_tensor, \"\\t\", net.state_dict()[param_tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.1307,), (0.3081,))])\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=200,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   torch.Size([6, 1, 5, 5]) \n",
      "  Parameter containing:\n",
      "tensor([[[[ 0.1954,  0.0121,  0.1640,  0.1464,  0.2705],\n",
      "          [ 0.1304, -0.0403,  0.1433,  0.0456, -0.0522],\n",
      "          [-0.2085, -0.1837, -0.1483, -0.0032, -0.1035],\n",
      "          [-0.0852, -0.0686,  0.1133, -0.1955, -0.1933],\n",
      "          [-0.0814, -0.1062, -0.2126, -0.1033,  0.0747]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1493,  0.1061, -0.1931, -0.0537, -0.1221],\n",
      "          [ 0.1064, -0.1001, -0.1260, -0.1717, -0.0048],\n",
      "          [-0.0145, -0.1327, -0.0277, -0.1975,  0.1304],\n",
      "          [-0.1494, -0.0456, -0.0669, -0.0927, -0.0431],\n",
      "          [ 0.2032,  0.1092, -0.0361, -0.0539, -0.1006]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1150, -0.0196, -0.0178, -0.1776, -0.1723],\n",
      "          [ 0.2551,  0.1801,  0.1082, -0.1142, -0.1189],\n",
      "          [ 0.0085, -0.0342, -0.0729, -0.1232,  0.0946],\n",
      "          [ 0.1271,  0.1823,  0.1615,  0.0363,  0.2306],\n",
      "          [ 0.2858,  0.2635, -0.0239,  0.1917, -0.0294]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2501,  0.1590,  0.1105,  0.1619, -0.1553],\n",
      "          [-0.0840,  0.0108,  0.2862, -0.0134, -0.1037],\n",
      "          [-0.0597,  0.2434,  0.2784,  0.2254,  0.3075],\n",
      "          [ 0.0174,  0.2404,  0.3834,  0.3639,  0.0302],\n",
      "          [ 0.2627, -0.0067,  0.2235,  0.3650,  0.1813]]],\n",
      "\n",
      "\n",
      "        [[[-0.1263, -0.0693, -0.1679, -0.2231,  0.0816],\n",
      "          [-0.0607, -0.0285, -0.0377, -0.1271, -0.1272],\n",
      "          [ 0.2056,  0.2435, -0.0953,  0.2570,  0.0789],\n",
      "          [ 0.2866,  0.1053,  0.1949,  0.3653,  0.3196],\n",
      "          [ 0.2184,  0.2387,  0.2585,  0.1190,  0.3265]]],\n",
      "\n",
      "\n",
      "        [[[-0.0839, -0.0380, -0.0515,  0.1580,  0.1544],\n",
      "          [ 0.0305,  0.2044, -0.1041,  0.0227,  0.1643],\n",
      "          [-0.0531,  0.2450,  0.0948,  0.2567, -0.1435],\n",
      "          [ 0.2376,  0.0989,  0.0405,  0.1566,  0.0509],\n",
      "          [ 0.0340,  0.1445,  0.0654, -0.2096, -0.0504]]]],\n",
      "       requires_grad=True) \n",
      "\n",
      "\n",
      "2   torch.Size([6]) \n",
      "  Parameter containing:\n",
      "tensor([0.0889, 0.2020, 0.0691, 0.1976, 0.1579, 0.0756], requires_grad=True) \n",
      "\n",
      "\n",
      "3   torch.Size([16, 6, 5, 5]) \n",
      "  Parameter containing:\n",
      "tensor([[[[-0.0274,  0.0668,  0.0488,  0.0398, -0.0665],\n",
      "          [-0.0608,  0.0753, -0.0379, -0.0708, -0.0499],\n",
      "          [ 0.0213, -0.0393,  0.0602,  0.0631, -0.0172],\n",
      "          [-0.0192, -0.0213,  0.0593,  0.0295, -0.0479],\n",
      "          [ 0.0122,  0.0283, -0.0171, -0.0418,  0.0804]],\n",
      "\n",
      "         [[ 0.0871, -0.0707,  0.0819,  0.0117,  0.0575],\n",
      "          [-0.0282,  0.0007,  0.0180, -0.0617, -0.0293],\n",
      "          [ 0.0198,  0.0782,  0.0392, -0.0338, -0.0277],\n",
      "          [ 0.0431, -0.0100,  0.0603, -0.0399,  0.0026],\n",
      "          [-0.0332,  0.0662,  0.0012,  0.0095, -0.0582]],\n",
      "\n",
      "         [[ 0.0561,  0.0449,  0.0354, -0.0410,  0.0272],\n",
      "          [ 0.0724,  0.0942, -0.0040,  0.0277,  0.0081],\n",
      "          [ 0.0270, -0.0307, -0.0064, -0.0385,  0.0159],\n",
      "          [ 0.0504,  0.0809,  0.0430,  0.0777,  0.0367],\n",
      "          [-0.0646,  0.0218, -0.0101,  0.0375,  0.0262]],\n",
      "\n",
      "         [[-0.0235, -0.0858,  0.0660, -0.0673, -0.0697],\n",
      "          [ 0.0078,  0.0719, -0.0181, -0.0195,  0.0016],\n",
      "          [-0.0454,  0.0570, -0.0294, -0.0274, -0.0372],\n",
      "          [ 0.1082,  0.1210,  0.0632,  0.0684,  0.0632],\n",
      "          [-0.0152,  0.0922,  0.0799,  0.1105, -0.0550]],\n",
      "\n",
      "         [[-0.0672, -0.0104,  0.0473,  0.0385,  0.0964],\n",
      "          [ 0.0294,  0.0533, -0.0258,  0.0533,  0.0414],\n",
      "          [ 0.0365,  0.0543,  0.0292, -0.0066,  0.0188],\n",
      "          [ 0.0268, -0.0114,  0.0575,  0.1129, -0.0054],\n",
      "          [ 0.0972,  0.0768,  0.1025, -0.0427, -0.0169]],\n",
      "\n",
      "         [[-0.0726, -0.0107,  0.0061,  0.0363, -0.0062],\n",
      "          [-0.0734,  0.0782, -0.0339,  0.0575, -0.0311],\n",
      "          [-0.0074,  0.0626, -0.0644,  0.0099, -0.0562],\n",
      "          [-0.0196,  0.0570, -0.0007,  0.0815,  0.0461],\n",
      "          [ 0.0594,  0.0185, -0.0351,  0.0521,  0.0984]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0114,  0.1024,  0.0786,  0.0144, -0.0073],\n",
      "          [ 0.0595,  0.0455, -0.0794, -0.0819,  0.0102],\n",
      "          [-0.0503,  0.0029, -0.0508, -0.0293, -0.0326],\n",
      "          [-0.0022, -0.0103,  0.1001,  0.0145,  0.0315],\n",
      "          [ 0.0466,  0.0812,  0.0668, -0.0131,  0.0648]],\n",
      "\n",
      "         [[ 0.0362, -0.0251,  0.0047,  0.0651, -0.0518],\n",
      "          [-0.0333, -0.0493, -0.0060, -0.0515,  0.0144],\n",
      "          [-0.0453, -0.0071,  0.0713, -0.0002,  0.0601],\n",
      "          [ 0.0812,  0.0047,  0.0654,  0.0468, -0.0322],\n",
      "          [ 0.0833, -0.0038,  0.0879,  0.0529, -0.0114]],\n",
      "\n",
      "         [[ 0.0401, -0.0260,  0.0052, -0.0704,  0.0453],\n",
      "          [-0.0636, -0.0824, -0.0109, -0.0080,  0.1137],\n",
      "          [ 0.0415, -0.0511, -0.0592,  0.0319,  0.0749],\n",
      "          [-0.0010, -0.0853,  0.0453,  0.0482,  0.0497],\n",
      "          [ 0.0315, -0.0261,  0.0280, -0.0704,  0.0084]],\n",
      "\n",
      "         [[ 0.0275, -0.0780, -0.0226,  0.1107,  0.0456],\n",
      "          [ 0.0677, -0.0909,  0.0061,  0.0381,  0.1153],\n",
      "          [-0.0139,  0.0046, -0.0138,  0.0801, -0.0193],\n",
      "          [-0.0538,  0.0012,  0.0109,  0.0946,  0.0835],\n",
      "          [-0.0782, -0.0925,  0.0232, -0.0251,  0.0054]],\n",
      "\n",
      "         [[ 0.0406, -0.0635,  0.0678,  0.0119,  0.0286],\n",
      "          [ 0.0131,  0.0114, -0.0431, -0.0450,  0.0757],\n",
      "          [ 0.0367,  0.0135, -0.0189, -0.0541,  0.0548],\n",
      "          [-0.0035,  0.0002,  0.0537, -0.0344, -0.0208],\n",
      "          [ 0.0619, -0.0228, -0.0419, -0.0491, -0.0564]],\n",
      "\n",
      "         [[ 0.0369, -0.0360, -0.0599,  0.0695,  0.0653],\n",
      "          [ 0.0340,  0.0286,  0.0532,  0.0393,  0.0815],\n",
      "          [ 0.0569, -0.0509,  0.0329, -0.0111,  0.0541],\n",
      "          [ 0.0452,  0.0620,  0.0273,  0.0446, -0.0114],\n",
      "          [-0.0536,  0.0362,  0.0610, -0.0087,  0.0545]]],\n",
      "\n",
      "\n",
      "        [[[-0.0435, -0.0409,  0.0214, -0.0245, -0.0470],\n",
      "          [-0.0648,  0.0276,  0.0549,  0.0553, -0.0518],\n",
      "          [ 0.0363, -0.0539,  0.0507, -0.0488, -0.0804],\n",
      "          [-0.0775, -0.0526,  0.0312,  0.0551,  0.0234],\n",
      "          [-0.0068,  0.0559, -0.0245,  0.0723, -0.0541]],\n",
      "\n",
      "         [[-0.0349,  0.0069, -0.0183, -0.0539, -0.0567],\n",
      "          [ 0.0241,  0.0163, -0.0367, -0.0296,  0.0207],\n",
      "          [-0.0484,  0.0468,  0.0486, -0.0618,  0.0803],\n",
      "          [-0.0575,  0.0382, -0.0458,  0.0376, -0.0709],\n",
      "          [ 0.0544,  0.0047,  0.0612,  0.0189, -0.0036]],\n",
      "\n",
      "         [[ 0.0300,  0.0635, -0.0530, -0.0549,  0.0241],\n",
      "          [-0.0594, -0.0401,  0.0664, -0.0185, -0.0817],\n",
      "          [-0.0298,  0.0741,  0.0713, -0.0260,  0.0608],\n",
      "          [ 0.0465,  0.0736,  0.0003, -0.0390,  0.0363],\n",
      "          [ 0.0037, -0.0807, -0.0299, -0.0517,  0.0294]],\n",
      "\n",
      "         [[-0.0792,  0.0780,  0.0514, -0.0699, -0.0856],\n",
      "          [-0.0144, -0.0430,  0.0017,  0.0204,  0.0092],\n",
      "          [ 0.0030,  0.0179,  0.0450, -0.0480,  0.0482],\n",
      "          [ 0.0107,  0.0552,  0.0846,  0.0534, -0.0309],\n",
      "          [-0.0794, -0.0152, -0.0460,  0.0496,  0.0278]],\n",
      "\n",
      "         [[-0.0479, -0.0191,  0.0219,  0.0451, -0.0755],\n",
      "          [-0.0379,  0.0345, -0.0048,  0.0316, -0.0598],\n",
      "          [-0.0453,  0.0268,  0.0861,  0.0482,  0.0782],\n",
      "          [ 0.0281,  0.0489,  0.0117, -0.0046,  0.0457],\n",
      "          [-0.0529, -0.0806,  0.0494,  0.0352,  0.0617]],\n",
      "\n",
      "         [[-0.0768,  0.0607,  0.0444,  0.0540, -0.0495],\n",
      "          [ 0.0513, -0.0188, -0.0549, -0.0502, -0.0427],\n",
      "          [ 0.0179, -0.0705, -0.0647,  0.0449,  0.0746],\n",
      "          [-0.0253, -0.0430, -0.0533,  0.0573,  0.0787],\n",
      "          [-0.0562, -0.0676,  0.0715, -0.0026,  0.0565]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0867,  0.0743,  0.0552, -0.0527,  0.0324],\n",
      "          [ 0.0953, -0.0199, -0.0295, -0.0403,  0.0669],\n",
      "          [-0.0332, -0.0047,  0.0819,  0.0500, -0.0737],\n",
      "          [ 0.0702,  0.0296,  0.0512, -0.0141, -0.0785],\n",
      "          [ 0.0105, -0.0372,  0.0275, -0.0444,  0.0801]],\n",
      "\n",
      "         [[ 0.0696,  0.0756, -0.0469, -0.0089,  0.0436],\n",
      "          [-0.0002,  0.0689,  0.0646, -0.0738,  0.0002],\n",
      "          [ 0.0474,  0.0280,  0.0370, -0.0493,  0.0114],\n",
      "          [ 0.0923,  0.0150, -0.0433,  0.0001,  0.0055],\n",
      "          [ 0.0284,  0.0790, -0.0025,  0.0587,  0.0567]],\n",
      "\n",
      "         [[ 0.0074, -0.0313, -0.0270,  0.0253,  0.1055],\n",
      "          [ 0.0361, -0.0577, -0.0685,  0.0318,  0.1180],\n",
      "          [-0.0353,  0.0548, -0.0407,  0.0525,  0.0153],\n",
      "          [ 0.0303,  0.0579, -0.0119, -0.0442, -0.0267],\n",
      "          [-0.0016,  0.0065,  0.0044, -0.0504,  0.0356]],\n",
      "\n",
      "         [[-0.0432, -0.0143,  0.0811,  0.1546,  0.0607],\n",
      "          [-0.0778, -0.0240, -0.0319, -0.0030,  0.1579],\n",
      "          [-0.0280, -0.0699, -0.0876, -0.0119,  0.0790],\n",
      "          [-0.0983,  0.0210, -0.0514,  0.0689,  0.0750],\n",
      "          [ 0.0074, -0.0144, -0.0070,  0.1365,  0.0485]],\n",
      "\n",
      "         [[-0.0079,  0.0315,  0.0655,  0.1064,  0.0607],\n",
      "          [-0.0207,  0.0698, -0.0483,  0.0416, -0.0130],\n",
      "          [-0.0263, -0.0218, -0.0671, -0.0247, -0.0565],\n",
      "          [-0.0670,  0.0891, -0.0003,  0.0927,  0.0647],\n",
      "          [ 0.0704,  0.1173,  0.1078,  0.0087,  0.0593]],\n",
      "\n",
      "         [[-0.0422, -0.0288,  0.0488, -0.0428,  0.0470],\n",
      "          [ 0.0696,  0.0237, -0.0314,  0.0103,  0.0643],\n",
      "          [ 0.0073,  0.0481,  0.0067, -0.0726,  0.1036],\n",
      "          [-0.0580,  0.0370,  0.0404,  0.0295,  0.1155],\n",
      "          [-0.0567,  0.0523, -0.0587,  0.1055,  0.0410]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0494,  0.0188, -0.0594,  0.0070, -0.0301],\n",
      "          [-0.0539,  0.0506, -0.0009,  0.0335, -0.0584],\n",
      "          [-0.0223, -0.0533, -0.0312,  0.0398,  0.0861],\n",
      "          [ 0.1027,  0.0827, -0.0508, -0.0525,  0.0070],\n",
      "          [-0.0051, -0.0598, -0.0588,  0.0543, -0.0164]],\n",
      "\n",
      "         [[-0.0394, -0.0533,  0.0378,  0.0225, -0.0490],\n",
      "          [ 0.0349,  0.0437, -0.0357,  0.0521,  0.0238],\n",
      "          [-0.0905, -0.0332, -0.0659,  0.0634, -0.0678],\n",
      "          [-0.0556,  0.0413,  0.0085,  0.0435, -0.0020],\n",
      "          [ 0.0443, -0.0254, -0.0296, -0.0663,  0.0819]],\n",
      "\n",
      "         [[-0.0185, -0.0457,  0.1023, -0.0410,  0.0640],\n",
      "          [ 0.0264,  0.0874,  0.0540,  0.0342,  0.0361],\n",
      "          [-0.0413,  0.0394, -0.0428,  0.0182,  0.0852],\n",
      "          [-0.0026, -0.0659,  0.0330,  0.0022, -0.0459],\n",
      "          [ 0.0110,  0.0995,  0.0537,  0.0596,  0.0756]],\n",
      "\n",
      "         [[ 0.1012,  0.1081,  0.1025,  0.0072,  0.0945],\n",
      "          [ 0.1049,  0.0643, -0.0273, -0.0367, -0.0208],\n",
      "          [ 0.1000, -0.0200,  0.0096, -0.0624, -0.0181],\n",
      "          [ 0.0792,  0.0939,  0.0946, -0.0568,  0.0760],\n",
      "          [-0.0009,  0.0744,  0.0837,  0.0012,  0.0194]],\n",
      "\n",
      "         [[ 0.0291,  0.1435,  0.1299,  0.0036,  0.0871],\n",
      "          [ 0.1035,  0.1228,  0.0380,  0.0254, -0.0240],\n",
      "          [ 0.0477, -0.0669, -0.0055,  0.0057,  0.0287],\n",
      "          [-0.0513, -0.0424,  0.0483, -0.0601,  0.0486],\n",
      "          [ 0.0921,  0.1021,  0.0908,  0.0888,  0.0490]],\n",
      "\n",
      "         [[-0.0384, -0.0154,  0.0436, -0.0105,  0.0451],\n",
      "          [ 0.0901,  0.0776, -0.0301,  0.0690, -0.0309],\n",
      "          [ 0.1104,  0.0425,  0.0419, -0.0453,  0.0458],\n",
      "          [-0.0307, -0.0534, -0.0394,  0.0236,  0.0465],\n",
      "          [-0.0692, -0.0183,  0.0089, -0.0206,  0.0389]]],\n",
      "\n",
      "\n",
      "        [[[-0.0020,  0.0751,  0.0134,  0.0531,  0.0574],\n",
      "          [ 0.0035, -0.0578,  0.0161,  0.0412,  0.0589],\n",
      "          [-0.0216, -0.0487,  0.0395,  0.0251,  0.0705],\n",
      "          [-0.0222, -0.0647, -0.0208, -0.0473, -0.0246],\n",
      "          [-0.0302,  0.0293,  0.0256, -0.0031, -0.0733]],\n",
      "\n",
      "         [[ 0.0202,  0.0780,  0.0265,  0.0221,  0.0742],\n",
      "          [-0.0200,  0.0266, -0.0203, -0.0096, -0.0161],\n",
      "          [ 0.0744,  0.0783,  0.0429, -0.0358,  0.0033],\n",
      "          [ 0.0600, -0.0126,  0.0445, -0.0565,  0.0733],\n",
      "          [-0.0548, -0.0381, -0.0142,  0.0790,  0.0888]],\n",
      "\n",
      "         [[-0.0486, -0.0391, -0.0214,  0.0725,  0.0748],\n",
      "          [-0.0770, -0.0661,  0.0356, -0.0094, -0.0375],\n",
      "          [-0.0385,  0.0706, -0.0204, -0.0250, -0.0701],\n",
      "          [-0.0112, -0.0123,  0.0035,  0.0503, -0.0716],\n",
      "          [ 0.0283, -0.0026, -0.0314, -0.0128, -0.0613]],\n",
      "\n",
      "         [[-0.0692, -0.0151, -0.0098,  0.0471,  0.0380],\n",
      "          [-0.0333, -0.0265,  0.0236,  0.1058, -0.0391],\n",
      "          [ 0.0353,  0.0279,  0.0909,  0.0711, -0.0662],\n",
      "          [-0.0403,  0.0075,  0.0402, -0.0218,  0.0152],\n",
      "          [ 0.0320, -0.0144, -0.0312,  0.0275, -0.0524]],\n",
      "\n",
      "         [[-0.0635, -0.0759, -0.0257,  0.0932,  0.0480],\n",
      "          [-0.0533, -0.0012,  0.0481,  0.0972, -0.0115],\n",
      "          [ 0.0317,  0.0682, -0.0040,  0.0312,  0.0618],\n",
      "          [-0.0353,  0.0874,  0.0021, -0.0651, -0.0505],\n",
      "          [-0.0716, -0.0393,  0.0481, -0.0397, -0.0488]],\n",
      "\n",
      "         [[ 0.0703, -0.0039, -0.0368,  0.0487,  0.0421],\n",
      "          [-0.0564,  0.0273, -0.0645,  0.0598, -0.0491],\n",
      "          [ 0.0688, -0.0356,  0.0441,  0.0353, -0.0540],\n",
      "          [-0.0733,  0.0374, -0.0255,  0.0311, -0.0593],\n",
      "          [-0.0586, -0.0194, -0.0267,  0.0013,  0.0008]]]],\n",
      "       requires_grad=True) \n",
      "\n",
      "\n",
      "4   torch.Size([16]) \n",
      "  Parameter containing:\n",
      "tensor([ 0.0678, -0.0424, -0.0553, -0.0554, -0.0523, -0.0426,  0.0439, -0.0724,\n",
      "         0.0329, -0.0029,  0.0769,  0.0866,  0.0797, -0.0330, -0.0008, -0.0292],\n",
      "       requires_grad=True) \n",
      "\n",
      "\n",
      "5   torch.Size([300, 256]) \n",
      "  Parameter containing:\n",
      "tensor([[ 0.0075, -0.0228,  0.0441,  ...,  0.0379,  0.0472, -0.0569],\n",
      "        [-0.0543,  0.0214,  0.0101,  ...,  0.0456, -0.0507,  0.0105],\n",
      "        [-0.0553, -0.0464, -0.0453,  ...,  0.0590,  0.0510, -0.0612],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0726,  0.0488,  ...,  0.0495, -0.0552,  0.0553],\n",
      "        [ 0.0282,  0.0514, -0.0187,  ..., -0.0511,  0.0008, -0.0110],\n",
      "        [ 0.0377,  0.0453, -0.0087,  ..., -0.0149,  0.0576,  0.0590]],\n",
      "       requires_grad=True) \n",
      "\n",
      "\n",
      "6   torch.Size([300]) \n",
      "  Parameter containing:\n",
      "tensor([-0.0613, -0.0096,  0.0004,  0.0227, -0.0270,  0.0271, -0.0524, -0.0336,\n",
      "         0.0488, -0.0171,  0.0535, -0.0261,  0.0042,  0.0027, -0.0281,  0.0008,\n",
      "        -0.0528, -0.0025,  0.0006, -0.0046, -0.0006,  0.0142, -0.0409,  0.0599,\n",
      "         0.0513, -0.0374,  0.0186,  0.0505,  0.0519, -0.0291, -0.0098,  0.0555,\n",
      "        -0.0124, -0.0360,  0.0028,  0.0044, -0.0460,  0.0139, -0.0303,  0.0069,\n",
      "        -0.0449, -0.0036,  0.0203,  0.0664,  0.0219, -0.0148,  0.0184,  0.0326,\n",
      "         0.0358, -0.0465, -0.0083, -0.0321, -0.0350, -0.0389, -0.0196,  0.0551,\n",
      "        -0.0545,  0.0617, -0.0530,  0.0079, -0.0598,  0.0029, -0.0224,  0.0247,\n",
      "        -0.0024, -0.0387, -0.0484, -0.0210, -0.0130, -0.0341,  0.0596, -0.0330,\n",
      "        -0.0460, -0.0284, -0.0112, -0.0368, -0.0115, -0.0361, -0.0175,  0.0584,\n",
      "         0.0427,  0.0172, -0.0470,  0.0225,  0.0001, -0.0539, -0.0198, -0.0206,\n",
      "        -0.0474,  0.0300, -0.0206,  0.0304,  0.0077,  0.0543,  0.0369, -0.0293,\n",
      "        -0.0006, -0.0548,  0.0090, -0.0386, -0.0286, -0.0236,  0.0253, -0.0543,\n",
      "         0.0479, -0.0293, -0.0566, -0.0318, -0.0421, -0.0502, -0.0179,  0.0356,\n",
      "        -0.0113, -0.0156,  0.0410,  0.0208,  0.0515, -0.0513,  0.0613, -0.0179,\n",
      "        -0.0052, -0.0395, -0.0129, -0.0348, -0.0474, -0.0036, -0.0013, -0.0562,\n",
      "        -0.0417,  0.0283, -0.0018,  0.0319, -0.0062,  0.0619, -0.0023, -0.0154,\n",
      "         0.0603, -0.0449, -0.0415, -0.0597,  0.0250, -0.0214,  0.0036, -0.0540,\n",
      "        -0.0414,  0.0038, -0.0557,  0.0536,  0.0662, -0.0447, -0.0171,  0.0515,\n",
      "        -0.0230,  0.0575, -0.0358,  0.0426,  0.0329, -0.0349,  0.0057, -0.0044,\n",
      "         0.0258,  0.0143, -0.0044, -0.0573, -0.0268,  0.0394,  0.0515,  0.0587,\n",
      "         0.0462,  0.0249,  0.0384, -0.0013,  0.0533,  0.0363,  0.0159,  0.0579,\n",
      "         0.0479,  0.0252,  0.0516,  0.0314,  0.0345,  0.0142, -0.0303, -0.0408,\n",
      "        -0.0300, -0.0522,  0.0357, -0.0150,  0.0452,  0.0489,  0.0024,  0.0146,\n",
      "         0.0366, -0.0234,  0.0065,  0.0575, -0.0268, -0.0289,  0.0387,  0.0149,\n",
      "        -0.0175,  0.0521, -0.0654,  0.0326, -0.0079, -0.0122,  0.0475,  0.0591,\n",
      "         0.0233,  0.0336,  0.0452, -0.0177, -0.0461,  0.0099,  0.0045,  0.0245,\n",
      "         0.0306, -0.0502,  0.0449, -0.0544,  0.0600, -0.0209, -0.0216, -0.0098,\n",
      "         0.0146, -0.0193, -0.0481, -0.0541,  0.0361, -0.0071, -0.0160,  0.0270,\n",
      "         0.0237,  0.0131,  0.0492, -0.0054, -0.0510,  0.0219, -0.0348,  0.0611,\n",
      "        -0.0599, -0.0110, -0.0619,  0.0599,  0.0491, -0.0079,  0.0456, -0.0130,\n",
      "         0.0630,  0.0108, -0.0462, -0.0473, -0.0256, -0.0485, -0.0188,  0.0455,\n",
      "        -0.0275,  0.0550, -0.0004,  0.0118,  0.0539,  0.0278, -0.0377,  0.0516,\n",
      "        -0.0471, -0.0175, -0.0171, -0.0404,  0.0351, -0.0343, -0.0453, -0.0176,\n",
      "         0.0073, -0.0034, -0.0159,  0.0162,  0.0569, -0.0132,  0.0238,  0.0627,\n",
      "        -0.0387,  0.0533,  0.0147,  0.0207, -0.0230,  0.0267,  0.0347, -0.0476,\n",
      "         0.0110, -0.0175, -0.0011, -0.0376,  0.0536,  0.0385,  0.0583, -0.0534,\n",
      "         0.0111, -0.0582, -0.0494, -0.0061], requires_grad=True) \n",
      "\n",
      "\n",
      "7   torch.Size([100, 300]) \n",
      "  Parameter containing:\n",
      "tensor([[-0.0052, -0.0047,  0.0493,  ...,  0.0129, -0.0062,  0.0570],\n",
      "        [ 0.0247,  0.0198, -0.0286,  ..., -0.0296, -0.0601,  0.0437],\n",
      "        [-0.0416, -0.0223, -0.0210,  ..., -0.0089,  0.0154, -0.0125],\n",
      "        ...,\n",
      "        [ 0.0504,  0.0257,  0.0032,  ...,  0.0427, -0.0514, -0.0526],\n",
      "        [-0.0472, -0.0357,  0.0194,  ...,  0.0204, -0.0042, -0.0297],\n",
      "        [-0.0193, -0.0199,  0.0532,  ...,  0.0298,  0.0172,  0.0558]],\n",
      "       requires_grad=True) \n",
      "\n",
      "\n",
      "8   torch.Size([100]) \n",
      "  Parameter containing:\n",
      "tensor([-0.0478,  0.0164,  0.0575, -0.0453,  0.0055, -0.0306, -0.0436, -0.0382,\n",
      "        -0.0327, -0.0289, -0.0538,  0.0604, -0.0405, -0.0221,  0.0478, -0.0396,\n",
      "         0.0512,  0.0441, -0.0344, -0.0511,  0.0191,  0.0464,  0.0358, -0.0286,\n",
      "         0.0001,  0.0551, -0.0305,  0.0320, -0.0183,  0.0414, -0.0293, -0.0355,\n",
      "         0.0163,  0.0311, -0.0088,  0.0357,  0.0183,  0.0204, -0.0518, -0.0276,\n",
      "         0.0451,  0.0416, -0.0216,  0.0268,  0.0062,  0.0445, -0.0164,  0.0325,\n",
      "         0.0003,  0.0565, -0.0114, -0.0467,  0.0377, -0.0437, -0.0243,  0.0100,\n",
      "        -0.0268,  0.0646,  0.0341,  0.0212, -0.0423,  0.0461, -0.0142,  0.0245,\n",
      "         0.0349,  0.0400, -0.0025, -0.0210,  0.0286,  0.0610, -0.0223,  0.0475,\n",
      "        -0.0250,  0.0444, -0.0117, -0.0377,  0.0560, -0.0239, -0.0067, -0.0554,\n",
      "        -0.0620,  0.0282,  0.0504, -0.0132,  0.0691, -0.0250,  0.0534,  0.0594,\n",
      "         0.0506, -0.0099,  0.0007,  0.0260, -0.0104, -0.0088,  0.0347,  0.0226,\n",
      "        -0.0221, -0.0109, -0.0430,  0.0509], requires_grad=True) \n",
      "\n",
      "\n",
      "9   torch.Size([10, 100]) \n",
      "  Parameter containing:\n",
      "tensor([[ 0.0795,  0.0035, -0.0997,  0.0182, -0.0530,  0.0718,  0.0049, -0.1053,\n",
      "          0.0444,  0.1244,  0.0431, -0.0615,  0.0780,  0.0683,  0.0801, -0.0896,\n",
      "          0.0897, -0.0004,  0.0601,  0.0294,  0.0928, -0.0028, -0.1443, -0.0655,\n",
      "         -0.0113, -0.0385,  0.0353, -0.1128,  0.0403, -0.1080,  0.0426, -0.0179,\n",
      "          0.0263, -0.0422,  0.0214, -0.0017,  0.1446, -0.0527, -0.0377, -0.0689,\n",
      "         -0.0049,  0.0576, -0.0811, -0.0461, -0.1153, -0.0113, -0.0519,  0.0626,\n",
      "         -0.0484,  0.0844,  0.0006, -0.0399,  0.0483,  0.0837,  0.0262,  0.1909,\n",
      "          0.0449, -0.0536,  0.1095, -0.0927,  0.1159, -0.0554,  0.0509,  0.0783,\n",
      "         -0.0922,  0.1104, -0.0776, -0.1221, -0.0252, -0.0717, -0.1541, -0.0952,\n",
      "          0.0397,  0.1199, -0.0490, -0.0769, -0.0381,  0.0953,  0.0950, -0.0460,\n",
      "         -0.0876, -0.1793,  0.0075,  0.0491,  0.0708, -0.1261,  0.0344, -0.0617,\n",
      "         -0.1861, -0.0297, -0.0681,  0.1610, -0.0233,  0.0094,  0.0118,  0.0473,\n",
      "          0.1037, -0.0226,  0.0257, -0.0547],\n",
      "        [-0.0297, -0.1611,  0.0652,  0.0664,  0.0782, -0.0990,  0.0335, -0.0624,\n",
      "         -0.0420,  0.0704, -0.0298, -0.0477, -0.0959,  0.0253,  0.0042,  0.1228,\n",
      "          0.0112,  0.1048, -0.0298, -0.0352, -0.0295, -0.0724, -0.0384,  0.0416,\n",
      "          0.0881,  0.0100,  0.0830,  0.0673, -0.0974,  0.0758, -0.1238, -0.0597,\n",
      "          0.0683, -0.0885, -0.0078,  0.0860,  0.0026,  0.0873,  0.0324, -0.0369,\n",
      "         -0.0037, -0.0351, -0.0617, -0.0377, -0.0592,  0.0970, -0.0869, -0.0950,\n",
      "         -0.0530,  0.0925, -0.0903,  0.0332, -0.1426,  0.0852, -0.0667, -0.1056,\n",
      "         -0.0120,  0.0919, -0.0790, -0.0071, -0.0939, -0.0588, -0.0807, -0.1217,\n",
      "          0.0873,  0.0708, -0.0001, -0.0626,  0.0566,  0.2118,  0.1036, -0.0475,\n",
      "         -0.0849, -0.0228, -0.0744,  0.0418, -0.0498, -0.0047, -0.0374, -0.0831,\n",
      "         -0.0305, -0.0348, -0.0757, -0.0970,  0.0672, -0.0091, -0.0343,  0.0608,\n",
      "          0.0147,  0.0956,  0.1191, -0.1359, -0.0940, -0.0450,  0.1518,  0.0159,\n",
      "          0.1147,  0.0449,  0.0051,  0.0011],\n",
      "        [-0.0560,  0.0528, -0.0126, -0.0443, -0.0210, -0.0820, -0.0298,  0.1131,\n",
      "          0.0000, -0.1054,  0.0048, -0.0970, -0.0901, -0.0121,  0.0419,  0.0632,\n",
      "         -0.0800, -0.0945,  0.0031, -0.0349,  0.0734, -0.1008, -0.1482,  0.0725,\n",
      "         -0.0082, -0.0856, -0.0252, -0.1216, -0.0362, -0.0870, -0.0487, -0.0577,\n",
      "         -0.1287, -0.0975, -0.0104, -0.0170,  0.0230,  0.0749,  0.0937,  0.0038,\n",
      "          0.1048,  0.1179,  0.0553,  0.1456, -0.0562, -0.0353, -0.0233,  0.1190,\n",
      "          0.0605, -0.1075,  0.0092, -0.0230,  0.0603,  0.0415,  0.0056, -0.1043,\n",
      "         -0.0410,  0.1277, -0.0691,  0.0893, -0.0297,  0.0444, -0.0157,  0.0850,\n",
      "          0.0591, -0.0783, -0.0688,  0.1321, -0.1360,  0.0962,  0.0934,  0.1217,\n",
      "          0.0552,  0.1016, -0.1211, -0.0320, -0.0930,  0.0344, -0.0152,  0.0525,\n",
      "          0.0148, -0.0148, -0.0496,  0.1119,  0.0282, -0.0791,  0.0832,  0.0232,\n",
      "         -0.0917,  0.0191,  0.0368, -0.0389,  0.1003,  0.0200,  0.0214, -0.1064,\n",
      "          0.0925, -0.0087, -0.0852,  0.0042],\n",
      "        [ 0.0459,  0.0069,  0.1189, -0.0167, -0.0551,  0.0398,  0.0925,  0.0074,\n",
      "          0.0627, -0.0570,  0.0970, -0.0760, -0.0171,  0.0890,  0.0447,  0.1136,\n",
      "          0.0424,  0.0897, -0.0889,  0.0859,  0.0433,  0.0774, -0.0585, -0.0083,\n",
      "          0.0123, -0.0775, -0.0537, -0.0362,  0.0513,  0.0494,  0.1099, -0.0216,\n",
      "         -0.1173,  0.1350,  0.0438, -0.0462, -0.0211,  0.0758, -0.0553, -0.0745,\n",
      "          0.0526,  0.0117,  0.0672, -0.0585,  0.0510, -0.0944,  0.1552, -0.0975,\n",
      "         -0.0155,  0.0497, -0.0548, -0.0767,  0.1434, -0.0453,  0.0973,  0.0397,\n",
      "          0.0813, -0.0500, -0.1110,  0.0536, -0.0819, -0.0591, -0.0364, -0.1230,\n",
      "         -0.0725, -0.1050,  0.0612, -0.0845,  0.1112, -0.0755,  0.0461, -0.0112,\n",
      "         -0.0048, -0.0101,  0.0154, -0.0149, -0.0924,  0.0629,  0.0695,  0.0073,\n",
      "          0.0938,  0.0261, -0.0396,  0.0956,  0.0046, -0.0709,  0.1029,  0.1808,\n",
      "         -0.0170,  0.0598, -0.0201,  0.0419,  0.0920, -0.0283,  0.0558, -0.0752,\n",
      "         -0.0772, -0.0154,  0.0108,  0.0371],\n",
      "        [-0.0701,  0.1243, -0.0453, -0.0471, -0.0608,  0.0672, -0.0456,  0.0959,\n",
      "         -0.0891,  0.0886,  0.0849,  0.0286, -0.0505,  0.0172,  0.0579,  0.0447,\n",
      "         -0.0049, -0.0081,  0.0198, -0.0124, -0.0546, -0.0567,  0.1864, -0.0744,\n",
      "          0.0803,  0.1326, -0.0781,  0.0904, -0.0650,  0.0298, -0.1398, -0.0029,\n",
      "         -0.0046, -0.0567, -0.1270,  0.0771, -0.1098, -0.0218,  0.0771, -0.0875,\n",
      "          0.0864, -0.0251,  0.0057, -0.0704, -0.1194, -0.0793,  0.0565, -0.0145,\n",
      "         -0.0346,  0.0076,  0.0882, -0.0089,  0.0245, -0.0723, -0.1311, -0.1812,\n",
      "         -0.0476, -0.0061,  0.0049, -0.1043,  0.0247, -0.1009, -0.0693, -0.0697,\n",
      "          0.1387,  0.0085,  0.0888, -0.0259,  0.0192,  0.0029, -0.1109,  0.0047,\n",
      "          0.0167, -0.0395,  0.0351, -0.0675,  0.0409, -0.0002, -0.0430,  0.0647,\n",
      "         -0.0808, -0.0710, -0.0045,  0.0547, -0.1131,  0.1176,  0.1072, -0.0589,\n",
      "          0.0123,  0.0968, -0.0659, -0.1270, -0.0547,  0.0347, -0.0892,  0.1177,\n",
      "         -0.1130,  0.0523, -0.0446, -0.0150],\n",
      "        [-0.0081,  0.0106, -0.0736, -0.0367, -0.0554, -0.0636,  0.0172,  0.0956,\n",
      "         -0.0863, -0.0319,  0.0092,  0.0223,  0.0121,  0.0511, -0.0987,  0.0004,\n",
      "          0.0668, -0.0621,  0.0609,  0.0553,  0.0553, -0.0685,  0.0650,  0.0392,\n",
      "          0.0924, -0.1250,  0.0299,  0.0848, -0.0486, -0.1024,  0.1097, -0.0693,\n",
      "          0.0278, -0.0763,  0.0937, -0.0431, -0.0397, -0.0989,  0.0733,  0.0249,\n",
      "         -0.0203,  0.1271,  0.0332, -0.1134,  0.0807, -0.0365,  0.0561, -0.0995,\n",
      "          0.0007, -0.0865,  0.0957,  0.0385, -0.0363,  0.0928, -0.0438,  0.1309,\n",
      "          0.0609, -0.0880,  0.0041, -0.0264, -0.0456,  0.0676,  0.0029, -0.0908,\n",
      "          0.0174, -0.0940,  0.0112, -0.1042,  0.0964, -0.0836,  0.0066,  0.0683,\n",
      "          0.0171, -0.0927,  0.1042, -0.0024, -0.0994, -0.0426, -0.0840, -0.0571,\n",
      "         -0.0190,  0.0750, -0.0558, -0.0991,  0.0420,  0.0430,  0.0379,  0.0335,\n",
      "          0.0537, -0.1216, -0.0177,  0.1339,  0.0439,  0.0161, -0.0266,  0.1239,\n",
      "          0.0652,  0.0585,  0.0024, -0.0647],\n",
      "        [ 0.0426,  0.1366,  0.0149,  0.0313,  0.0019,  0.0342,  0.0797,  0.1597,\n",
      "         -0.0771,  0.0276, -0.0568,  0.0626,  0.0906, -0.0149, -0.0119, -0.0851,\n",
      "         -0.1103, -0.0948,  0.0352,  0.0361,  0.0101,  0.0750,  0.0590, -0.0020,\n",
      "         -0.0181,  0.0975,  0.0501,  0.0631,  0.0967, -0.0653, -0.0206,  0.0108,\n",
      "         -0.0967,  0.0181, -0.0368, -0.1564, -0.1075, -0.0960,  0.0878,  0.0522,\n",
      "         -0.0785, -0.0269,  0.0406, -0.0685, -0.0584,  0.0319, -0.0960, -0.0355,\n",
      "         -0.0905, -0.1030,  0.0659, -0.0735, -0.0255,  0.0347, -0.1059, -0.0026,\n",
      "          0.0460,  0.0731, -0.1016, -0.0278, -0.0102,  0.0284,  0.0784, -0.0731,\n",
      "          0.0413,  0.1442,  0.0213,  0.0390, -0.0014, -0.0742,  0.1167, -0.1370,\n",
      "         -0.1309,  0.1784,  0.0306,  0.0177,  0.0351,  0.0997, -0.0651, -0.0026,\n",
      "         -0.0155, -0.1865, -0.0604, -0.0351,  0.0494,  0.0219,  0.0441, -0.1431,\n",
      "          0.0491, -0.0818, -0.0505,  0.0308,  0.0242, -0.0735,  0.1147,  0.0001,\n",
      "          0.1261,  0.0577,  0.0896, -0.0351],\n",
      "        [-0.0206, -0.1226,  0.0356, -0.0116,  0.0018, -0.0873, -0.0051, -0.0621,\n",
      "          0.0032,  0.0876, -0.0258,  0.0360,  0.0508,  0.0205, -0.0308, -0.0156,\n",
      "          0.1182,  0.1587, -0.0443,  0.1038,  0.0900,  0.0971,  0.0486, -0.0584,\n",
      "         -0.0619,  0.1111, -0.0873,  0.0305,  0.0487,  0.1227, -0.0088,  0.0845,\n",
      "          0.0785, -0.0937, -0.0624,  0.1419,  0.1296, -0.0721, -0.0663, -0.0613,\n",
      "         -0.0016, -0.0596, -0.0091,  0.0024,  0.0326, -0.0901, -0.1095,  0.1153,\n",
      "          0.1577, -0.0507, -0.0120, -0.0987, -0.1333, -0.0367, -0.0728, -0.1406,\n",
      "         -0.0030, -0.1436, -0.0760,  0.0876, -0.0071, -0.0931, -0.0833, -0.0758,\n",
      "         -0.1194,  0.0415,  0.0088, -0.0083,  0.0790, -0.1185, -0.0859,  0.0686,\n",
      "         -0.0055, -0.1396, -0.0169, -0.0843, -0.0088, -0.0199, -0.0245,  0.0113,\n",
      "          0.0524,  0.1432, -0.1314,  0.0056, -0.0549, -0.1331,  0.0864, -0.0532,\n",
      "         -0.0476, -0.0658, -0.0576,  0.1016, -0.0342,  0.1413, -0.0902,  0.0924,\n",
      "          0.0662, -0.0891, -0.0118,  0.0833],\n",
      "        [-0.0396, -0.0055, -0.0277,  0.0650,  0.0436, -0.0736, -0.0797, -0.0358,\n",
      "         -0.0834,  0.0214, -0.0478, -0.0245,  0.0703,  0.0531,  0.0775,  0.0112,\n",
      "         -0.0595,  0.0595, -0.0321,  0.0231, -0.1206, -0.0653,  0.0743,  0.0557,\n",
      "         -0.0466, -0.1264, -0.1060, -0.1179, -0.0321,  0.1047,  0.0646,  0.0161,\n",
      "          0.0802, -0.0783,  0.1232, -0.1138, -0.0923,  0.0981, -0.0035, -0.0333,\n",
      "          0.0258, -0.1039, -0.0452,  0.1040,  0.0470, -0.0814,  0.0054, -0.0447,\n",
      "          0.0201,  0.0037,  0.0486,  0.0823, -0.0364, -0.0788,  0.0171,  0.0699,\n",
      "         -0.0973, -0.0529, -0.0630,  0.0603,  0.0443, -0.0823, -0.0709,  0.1293,\n",
      "         -0.0524, -0.0527, -0.0546, -0.0626,  0.1033, -0.1295, -0.0539, -0.0705,\n",
      "         -0.0926,  0.0518,  0.0547, -0.0114,  0.0157,  0.0877,  0.0579,  0.0892,\n",
      "          0.0937,  0.0785,  0.0942, -0.0275, -0.1255,  0.0854, -0.1306, -0.0793,\n",
      "          0.1026,  0.0651, -0.0213, -0.0918,  0.0396,  0.0099,  0.0736, -0.0697,\n",
      "          0.0809,  0.1373,  0.0740,  0.0324],\n",
      "        [-0.1336, -0.0049,  0.0835,  0.0814,  0.0385,  0.0639, -0.0533, -0.1283,\n",
      "         -0.0274, -0.0968, -0.0880,  0.0850,  0.0517,  0.0464, -0.0010,  0.0037,\n",
      "         -0.0854, -0.0439, -0.0969, -0.0801, -0.0911,  0.0875,  0.1139, -0.0042,\n",
      "         -0.0341,  0.0202,  0.0509,  0.0351,  0.0059,  0.1383, -0.0375, -0.0009,\n",
      "          0.1446, -0.0065, -0.0318,  0.1019, -0.0845, -0.0476, -0.0921,  0.0089,\n",
      "          0.1081, -0.1064, -0.0294, -0.0360, -0.0079,  0.0265,  0.0658, -0.0076,\n",
      "          0.0819, -0.0207,  0.0609, -0.0676, -0.0246, -0.0117,  0.0785, -0.1663,\n",
      "         -0.0038, -0.0351, -0.1097,  0.0533,  0.1123, -0.0234, -0.0224,  0.0156,\n",
      "          0.0768, -0.1239, -0.1049, -0.0617, -0.0692, -0.0726, -0.1300,  0.1348,\n",
      "          0.0966,  0.0435, -0.0037,  0.0589,  0.0339,  0.0304, -0.0222, -0.0151,\n",
      "          0.0959,  0.0121,  0.0692, -0.0090, -0.0556,  0.0258, -0.0618, -0.0388,\n",
      "         -0.1058,  0.0235, -0.0997,  0.0612, -0.0422,  0.0670, -0.1051,  0.0867,\n",
      "         -0.0661, -0.1033, -0.0301, -0.1139]], requires_grad=True) \n",
      "\n",
      "\n",
      "10   torch.Size([10]) \n",
      "  Parameter containing:\n",
      "tensor([ 0.0504,  0.1393, -0.0627, -0.0188,  0.0212, -0.0102, -0.0827, -0.0165,\n",
      "        -0.1006, -0.0129], requires_grad=True) \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for parameter in net.parameters():\n",
    "    i+=1\n",
    "    print(i,\" \",parameter.shape,\"\\n \",parameter,\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 89.750000 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### First we have to convert the nodes to points in some d dimenstion. Where d is the number of nodes in the next layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300, 256])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net.state_dict()[\"fc1.weight\"]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can not prune the layer with 256 nodes. We have to prune the layer with 300 nodes. So, that depends on the outgoing edges weights means fc2. Because, if we consider the incoming edges two nodes with similar kind of incoming weights might not have a similar kind of effect on the next layer. But, two nodes having similar kind of outgoing edges will have same effect on the next layer. Example: if node1 has incoming edge i1, and outgoing edge o1. And node2 have incoming edge form same previous incoming node as i2, and same outgoing edge weight as o2. Then if we club them up, the net effect will be some function of f(i1+i2)* o1. assuming o1 and o2 are very similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 300])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print((net.state_dict()[\"fc2.weight\"]).shape)\n",
    "print(type(net.state_dict()[\"fc2.weight\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After changing the dimension of the layer with 300 nodes, to somehting less than 300. We also have to assing the incoming weight edges accordingly, and assign the outgoing edges equals to be mostly the avg of the nodes in same cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, first we need to form a space of dimension 100, with 300 points depending on fc2 weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0052,  0.0247, -0.0416,  ...,  0.0504, -0.0472, -0.0193],\n",
      "        [-0.0047,  0.0198, -0.0223,  ...,  0.0257, -0.0357, -0.0199],\n",
      "        [ 0.0493, -0.0286, -0.0210,  ...,  0.0032,  0.0194,  0.0532],\n",
      "        ...,\n",
      "        [ 0.0129, -0.0296, -0.0089,  ...,  0.0427,  0.0204,  0.0298],\n",
      "        [-0.0062, -0.0601,  0.0154,  ..., -0.0514, -0.0042,  0.0172],\n",
      "        [ 0.0570,  0.0437, -0.0125,  ..., -0.0526, -0.0297,  0.0558]])\n",
      "torch.Size([300, 100])\n"
     ]
    }
   ],
   "source": [
    "mat=net.state_dict()[\"fc2.weight\"].t()\n",
    "print(mat)\n",
    "print(mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300   100\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "nodes=defaultdict(list)\n",
    "for j in range(len(net.state_dict()[\"fc2.weight\"][0])):\n",
    "    ele=[]\n",
    "    for i in range(len(net.state_dict()[\"fc2.weight\"])):\n",
    "        ele.append(net.state_dict()[\"fc2.weight\"][i][j].item())\n",
    "    nodes[j]=ele\n",
    "\n",
    "print(len(nodes), \" \", len(nodes[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(nodes[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have nodes as a dictionary, where key is the node id, and values are the outgoing edges. So, now we have to find such node_ids who are having almost similar outgoing edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the Euclidean distance between two vectors\n",
    "def euclidean_distance(row1, row2):\n",
    "\tdistance = 0.0\n",
    "\tfor i in range(len(row1)-1):\n",
    "\t\tdistance += (row1[i] - row2[i])**2\n",
    "\treturn sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "distances=[]\n",
    "for i in nodes.keys():\n",
    "    for j in nodes.keys():\n",
    "        if(i!=j and j>i):\n",
    "            distances.append(euclidean_distance(nodes[i], nodes[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44850\n"
     ]
    }
   ],
   "source": [
    "distances.sort()\n",
    "print(len(distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "# plt.plot([x for x in range(len(distances))], distances) \n",
    "# plt.ylabel(\"Distances\")\n",
    "# plt.show() \n",
    "x=[k for k in range(len(distances))]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(x, distances)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take 0.41 as cut off and check "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also doesn't look like a good idea. But still let's try pruning with both the distance and check if anything improves after fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster=defaultdict(bool)\n",
    "setpoints=defaultdict(set)\n",
    "for i in nodes.keys():\n",
    "    cluster[i]=False\n",
    "    setpoints[i]={i}\n",
    "    \n",
    "# print(cluster)\n",
    "\n",
    "for i in nodes.keys():\n",
    "    for j in nodes.keys():\n",
    "        if(i!=j and j>i and cluster[i]==False and cluster[j]==False):\n",
    "            if(euclidean_distance(nodes[i], nodes[j])<0.45):\n",
    "                setpoints[i].add(j)\n",
    "                del setpoints[j]\n",
    "                cluster[j]=True\n",
    "    cluster[i]=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  ->  {0, 291, 228, 262, 8, 296, 10, 14, 50, 117, 182, 213, 121, 220}\n",
      "1  ->  {32, 1, 160, 163, 290, 38, 102, 169, 141, 52, 53, 212, 94}\n",
      "2  ->  {2, 259, 132, 138, 267, 273, 22, 30, 159, 31, 289, 164, 54, 195, 68, 71, 209, 216, 90, 226, 227, 104, 127}\n",
      "3  ->  {3, 229, 297, 12, 268, 111, 271, 179, 116, 21, 150, 122, 223}\n",
      "4  ->  {4, 101, 198, 261, 200, 238, 113, 114, 177, 86, 27}\n",
      "5  ->  {5, 18, 23, 250, 60}\n",
      "6  ->  {288, 292, 37, 6, 168, 205, 270, 175, 210, 119, 154, 219, 221}\n",
      "7  ->  {128, 129, 130, 257, 7, 135, 264, 15, 143, 144, 146, 147, 274, 277, 152, 25, 153, 280, 28, 29, 157, 158, 286, 161, 34, 35, 287, 294, 40, 43, 171, 172, 49, 180, 55, 183, 58, 187, 61, 63, 66, 69, 70, 197, 72, 203, 78, 81, 82, 211, 85, 89, 92, 100, 230, 235, 108, 237, 115, 243, 245, 125}\n",
      "9  ->  {131, 263, 9, 137, 11, 266, 13, 142, 272, 145, 149, 279, 282, 285, 36, 166, 42, 170, 173, 59, 191, 73, 202, 204, 207, 83, 214, 217, 222, 95, 224, 99, 103, 231, 234, 109, 240, 244, 120, 249, 251, 126, 255}\n",
      "16  ->  {64, 193, 225, 258, 106, 298, 45, 46, 79, 16, 110, 241, 20, 247, 91, 253, 190}\n",
      "17  ->  {77, 48, 17, 284, 118, 281, 283, 124, 93}\n",
      "19  ->  {174, 242, 178, 19, 276}\n",
      "24  ->  {33, 196, 199, 136, 44, 176, 51, 246, 278, 24, 56, 189}\n",
      "26  ->  {80, 26}\n",
      "39  ->  {162, 295, 47, 39}\n",
      "41  ->  {41, 299, 185, 156, 254}\n",
      "57  ->  {57}\n",
      "62  ->  {256, 62}\n",
      "65  ->  {65, 265}\n",
      "67  ->  {192, 218, 98, 67}\n",
      "74  ->  {74}\n",
      "75  ->  {75}\n",
      "76  ->  {76}\n",
      "84  ->  {84}\n",
      "87  ->  {194, 87}\n",
      "88  ->  {88}\n",
      "96  ->  {96}\n",
      "97  ->  {97}\n",
      "105  ->  {105, 239}\n",
      "107  ->  {107}\n",
      "112  ->  {112}\n",
      "123  ->  {123}\n",
      "133  ->  {133}\n",
      "134  ->  {134}\n",
      "139  ->  {233, 139}\n",
      "140  ->  {140, 167}\n",
      "148  ->  {148}\n",
      "151  ->  {151}\n",
      "155  ->  {155}\n",
      "165  ->  {165}\n",
      "181  ->  {181}\n",
      "184  ->  {184}\n",
      "186  ->  {186}\n",
      "188  ->  {188}\n",
      "201  ->  {201}\n",
      "206  ->  {206}\n",
      "208  ->  {208}\n",
      "215  ->  {215}\n",
      "232  ->  {232}\n",
      "236  ->  {236, 269}\n",
      "248  ->  {248}\n",
      "252  ->  {252}\n",
      "260  ->  {260}\n",
      "275  ->  {275}\n",
      "293  ->  {293}\n"
     ]
    }
   ],
   "source": [
    "for key in setpoints.keys():\n",
    "    print(key,\" -> \",setpoints[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "print(len(setpoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "temp=[]\n",
    "for node in setpoints.keys():\n",
    "    row=torch.zeros(len(net.state_dict()[\"fc1.weight\"][0]), dtype=torch.float)\n",
    "    for val in setpoints[node]:\n",
    "        row+=net.state_dict()[\"fc1.weight\"][val]\n",
    "    temp.append(row)\n",
    "print(len(temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have i many nodes in place of 300. Now, we will first fix the incoming weights this i many nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([300, 256])\n",
      "torch.Size([55, 256])\n"
     ]
    }
   ],
   "source": [
    "print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "net.state_dict()[\"fc1.weight\"].resize_((len(temp), len(temp[0])))\n",
    "print(net.state_dict()[\"fc1.weight\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(temp)):\n",
    "    for j in range(len(temp[0])):\n",
    "        net.state_dict()[\"fc1.weight\"][i][j]=temp[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([55, 256])\n"
     ]
    }
   ],
   "source": [
    "print(net.state_dict()[\"fc1.weight\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "temp=[]\n",
    "for node in setpoints.keys():\n",
    "    ele=0\n",
    "    for val in setpoints[node]:\n",
    "        ele+=net.state_dict()[\"fc1.bias\"][val]\n",
    "    temp.append(ele)\n",
    "print(len(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([300])\n",
      "torch.Size([55])\n"
     ]
    }
   ],
   "source": [
    "print(net.state_dict()[\"fc1.bias\"].shape)\n",
    "net.state_dict()[\"fc1.bias\"].resize_((len(temp)))\n",
    "print(net.state_dict()[\"fc1.bias\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([55])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(temp)):\n",
    "    net.state_dict()[\"fc1.bias\"][i]=temp[i]\n",
    "print(net.state_dict()[\"fc1.bias\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have to change the outgoing weights. We can try out checking with the average of the same cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 300])\n"
     ]
    }
   ],
   "source": [
    "print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "temp=[]\n",
    "for i in range(len(net.state_dict()[\"fc2.weight\"])):\n",
    "    row=[]\n",
    "    for j in setpoints.keys():\n",
    "        ele=0\n",
    "        for val in setpoints[j]:\n",
    "            ele+=net.state_dict()[\"fc2.weight\"][i][val]\n",
    "        row.append(ele/len(setpoints[j]))\n",
    "    temp.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 55\n"
     ]
    }
   ],
   "source": [
    "print(len(temp), len(temp[0]))\n",
    "# print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 55])\n"
     ]
    }
   ],
   "source": [
    "net.state_dict()[\"fc2.weight\"].resize_(len(temp), len(temp[0]))\n",
    "for i in range(len(temp)):\n",
    "    for j in range(len(temp[0])):\n",
    "        net.state_dict()[\"fc2.weight\"][i][j]=temp[i][j]\n",
    "print(net.state_dict()[\"fc2.weight\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "print((net.state_dict()[\"fc2.bias\"]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 65.260000 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the accuracy did not decrease much, it came down to 82.5 from 89.7 even after dropping 114 nodes from layer 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try to prune the next layer which consists of 100 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 55])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net.state_dict()[\"fc2.weight\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 100])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net.state_dict()[\"fc3.weight\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100   10\n"
     ]
    }
   ],
   "source": [
    "nodes=defaultdict(list)\n",
    "for j in range(len(net.state_dict()[\"fc3.weight\"][0])):\n",
    "    ele=[]\n",
    "    for i in range(len(net.state_dict()[\"fc3.weight\"])):\n",
    "        ele.append(net.state_dict()[\"fc3.weight\"][i][j].item())\n",
    "    nodes[j]=ele\n",
    "\n",
    "print(len(nodes), \" \", len(nodes[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "distances=[]\n",
    "for i in nodes.keys():\n",
    "    for j in nodes.keys():\n",
    "        if(i!=j and j>i):\n",
    "            distances.append(euclidean_distance(nodes[i], nodes[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4950\n"
     ]
    }
   ],
   "source": [
    "distances.sort()\n",
    "print(len(distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8VOd97/HPTyuLhHYESAgJkMA2ZrPYYoyXGF/spLhZGi/NHodsbt2kt7l2k7qvOPemSZq4SVNuEm6uc5PepiaJ65rGJNiusZ04GCR2BIhFCCQh0L4htM08/WOOiKKANZjRjGb0fb9eemnOmQed3yMPXz885znnmHMOERGJLXGRLkBEREJP4S4iEoMU7iIiMUjhLiISgxTuIiIxSOEuIhKDFO4iIjFI4S4iEoMU7iIiMSghUgfOzs52hYWFkTq8iEhU2r17d5NzLmekdhEL98LCQsrLyyN1eBGRqGRmp4Npp2kZEZEYpHAXEYlBCncRkRgUVLib2TozqzSzE2b26BXavM/MDptZhZn9JLRliojI1RjxhKqZxQMbgbVALVBmZlucc4eHtCkGHgNuds61mtnU0SpYRERGFszIfTlwwjlX5ZzrA54G7h3W5uPARudcK4BzriG0ZYqIyNUIJtzzgJoh27XevqFKgBIze93M3jCzdaEqUERErl6oTqgmAMXAbcADwP8xs/Thjcxsg5mVm1l5Y2NjiA4tIhIdLvQO8M0XKtlf0zbqxwom3OuAmUO28719Q9UCW5xz/c65U8AxAmH/e5xzm5xzpc650pycES+wEhGJKV29A3zn5RMcOts+6scKJtzLgGIzKzKzJOB+YMuwNv9OYNSOmWUTmKapCmGdIiJRb8DvAEiIs1E/1ojh7pwbAB4GtgFHgJ865yrM7AkzW+812wY0m9lhYDvwV8655tEqWkQkGg34/AAkxI3+JUZB3VvGObcV2Dps3+NDXjvgc96XiIhcRr/PG7nHj4GRu4iIhIbv0rTM6Eevwl1EJEz6B6dlNHIXEYkdgydUExXuIiKxw+cPjNzjNS0jIhI7Bk+oJo6FpZAiIhIaA5dWy2jkLiISMwYuTcto5C4iEjMGR+46oSoiEkMGtM5dRCT2DE7LaJ27iEgMuXRCVXPuIiKx43cXMWlaRkQkZgzeFVKrZUREYki/X3eFFBGJOT5v5J6o1TIiIrFjcM49XiN3EZHY0aeRu4hI7Onu9RFnMCFR4S4iEjO6egeYnJSAmaZlRERixoXeASYnB/Xo6mumcBcRCZOu3gFSJyjcRURiSlfvACkKdxGR2NLW3U/axMSwHEvhLiISJvXtF5meNiEsx1K4i4iEQU+/j6auPmakTQzL8RTuIiJhUNvaDcCMdIW7iEjMaOjsBRTuIiIxpePiAABTJmq1jIhIzGi50AfAlAlaLSMiEjN2VDWTMSmRvLE0LWNm68ys0sxOmNmjl3n/w2bWaGb7vK+HQl+qiEh08vkdLx85z+riHOLC8BQmgBEnf8wsHtgIrAVqgTIz2+KcOzys6Wbn3MOjUKOISFQ7eq6DC30+bivJCdsxgxm5LwdOOOeqnHN9wNPAvaNblohI7Khv6wGgODclbMcMJtzzgJoh27XevuHeY2YHzOznZjYzJNWJiMSAwWWQ6ROTwnbMUJ1Q/Q+g0Dm3EHgR+NHlGpnZBjMrN7PyxsbGEB1aRGRsK6tuITslmZmZ4TmZCsGFex0wdCSe7+27xDnX7Jzr9TZ/ANx0uR/knNvknCt1zpXm5IRv7klEJJKO1HewMD8tLA/pGBRMuJcBxWZWZGZJwP3AlqENzGz6kM31wJHQlSgiEr0GfH6qGi+Edb4dglgt45wbMLOHgW1APPCUc67CzJ4Ayp1zW4A/N7P1wADQAnx4FGsWEYkap1u66fP5KZ6aGtbjBnUdrHNuK7B12L7Hh7x+DHgstKWJiES/3dWtAFw3PbzhritURURG0X8cOMusrElcP31KWI+rcBcRGSU9/T5+fbyJO+ZPDevJVFC4i4iMmqdePwXA7fOmhv3YCncRkVHyRlUL06ZM4Jbi7LAfW+EuIjIKevp97KxqZt2CaWGfkgGFu4jIqNh+tIHeAT+3zYvMBZsKdxGREOsb8POVXx6hKHsyq+eGf0oGFO4iIiH34x3V1LRc5IvvuI6E+MjErMJdRCSEDp/t4B9ePMaSgnTumB/+VTKDFO4iIiHSO+DjL3+2n+TEeP73ny6NyInUQQp3EZEQ+V/PH+FIfQeP3j2f6Wnhu73v5SjcRURC4ERDJz/ecZp3L8njfaWRf16Rwl1EJAQ2bj8JwKP3zI9wJQEKdxGRa7TnTCvP7q3jg6tmMTV1QqTLARTuIiLXxDnHl7ZUkJOazGfvLIl0OZco3EVErsE3XzjG/tp2Pre2hIzJ4XsA9kgU7iIib9Fz++r4p+0neM/SfO5fFvmTqEMp3EVE3oJ/21PLI0/vY15uKn/37hsjuqb9chTuIiJXqfVCH3+7pYKS3BR+9qlVJCWMvSgN6hmqIiLyO9999SSdPQP86KMLmTIhMdLlXNbY+9+NiMgY9tuTTWx6rYp3L8ljaUFGpMu5IoW7iEiQXj/RxMd/VE5e+kT+x91j42KlK1G4i4gE4RcHzvLhH+5iRvpEfvrJVeROGRsXK12J5txFRN6Ez+/Y9FoVX/vVUZYWpPPDjywnbeLYnGcfSuEuInIFJxo6+fzPD7DnTBt3XjeVf3pwKRMS4yNdVlAU7iIil/HM7loee/Ygk5Li+dZ9i7l38Ywxt5b9zSjcRUSGcM7xzReO8U/bT/C2OVl8+/4l5KQmR7qsq6ZwFxHxVDdd4Mc7TvPU66e4e8E0/uG+xVEzDTOcwl1Exr2Onn6+8vwRNpfXALB+0Qy++b5FJEbo4dahoHAXkXHL53f88PVTPPniMbr7fHzk5kI+sWYO09LG9jLHYAQV7ma2Dvg2EA/8wDn31Su0ew/wc2CZc648ZFWKiIRYVWMXn928j/217SwvzOSL77yOhfnpkS4rZEYMdzOLBzYCa4FaoMzMtjjnDg9rlwo8AuwcjUJFREKh/WI/Pyuv4VsvHSch3vjHB5bwRwunR9VKmGAEM3JfDpxwzlUBmNnTwL3A4WHtvgx8DfirkFYoIhIi/7H/LI8/d4jW7n6WFWbwrfuXkJc+MdJljYpgwj0PqBmyXQusGNrAzJYCM51zz5vZFcPdzDYAGwAKCgquvloRkbfg1WONPPlCJftr21k8M50ff3QBN+anRbqsUXXNJ1TNLA54EvjwSG2dc5uATQClpaXuWo8tInIl/T4/r1Q2sum1k5RVt1KUPZkn7r2BB5YXRPUqmGAFE+51wNDnR+V7+walAguAV7w5q2nAFjNbr5OqIhJuF/t8bC47w/dereJcRw8FmZP4izuL+fgts5mcPH4WCAbT0zKg2MyKCIT6/cCDg28659qB7MFtM3sF+O8KdhEJJ+ccz+yp4xvbKjnX0cOywgy+8I7ruOuGXJITovNCpGsxYrg75wbM7GFgG4GlkE855yrM7Amg3Dm3ZbSLFBF5M4fq2vnOy8fZVnGeBXlTePK+RayanRVzK2CuRlD/RnHObQW2Dtv3+BXa3nbtZYmIjKyu7SJ/+1wFLx05z+SkeD6/bh6fXDOHuLjxG+qDxs8ElIjEhAu9A7x05Dw/313LG1XNJMbH8ZdrS/jQzYVj9nmmkaBwF5GocKiunb/75RHeqGrB53cUZk3iIzcX8f4VsyjImhTp8sYchbuIjFnOOXaeauHJF46xq7qFlOQEHlpdxMo5WdxanKPplzehcBeRMaepq5d/3XmGZ/fVUdV4gRlpE3j07vm8r3QmmZOTIl1eVFC4i8iY0NTVy4uHz1N2qoXnD9bTO+BnRVEmH1tdxPpFM0jVfPpVUbiLSMT4/I6tB+vZXFbDb0824XeQPimRdy3J42OriyjOTY10iVFL4S4iYXe+o4fNZTVsLquhru0i+RkT+eStc/ijRTOYPy11XK9PDxWFu4iERU+/j1cqG/lpeQ2vHmvE53fcPDeLv3nnddx1/TSdHA0xhbuIjJqGzh6e23uWZ/fWcfRcB34HuVOS2bBmNveVzqQwe3KkS4xZCncRCZl+n58j9R08f6CeXx46x5mWbgAWzUzn4dvnsrggnTXFOSSMg7syRprCXUSuyYXeAX516BzbKxt46ch5evr9JMQZtxRn84GVs7ilJJv506ZEusxxR+EuIletru0iLx9t4KXD59lxspk+n5+c1GTetSSfFUWZ3DYvh/RJWo8eSQp3ERlRV+8AO6uaee1YI68db+JU0wUACrMm8YFVs1h7fS4rijK1ymUMUbiLyB9oudBHeXULJxq7eKHiPAdq2/A7mJgYz7KiTN6/cha3FGdTPDVFgT5GKdxFBOcc+2ra2LL/LNuPNlDd3H3pvfnTUvn0bXNZPDOd1cXZTEgcfw++iEYKd5FxyO93VDdfYM+ZNn5zvJGy6lbq2i6SFB/H6uJs7ltWwNKCdIpzU3UvlyilcBcZB3z+wMj8SH0HO04285sTTbRf7AcgOyWJm2Zl8Nm1Jdx1Q67uiR4jFO4iMcg5x/GGLnacbGbHyWbKqltovtAHBC4ievv8qayck8WCGWnMn5aqq0NjkMJdJAY45zjVdIEdVYEwf6OqhaauXgDy0ieypiSHO+ZPZUlBOnnpE3USdBxQuItEIb/fcbKxi71n2i4F+rmOHgCmTZnALcXZrJqdxao5WczM1FOKxiOFu0gU6On3sb+mjZ2nWth1qoX9NW109g4AgTnzlV6Qr5qdRVH2ZI3MReEuMhZd7POx50wrO6ua2Xmqhb01bfQN+DGDebmprF88gyUFGSzKT2Ou1prLZSjcRcaAi30+dlW38EZVM7tOtXCgto1+nyPO4IYZaXxw5SxWzM5iWWGGLuuXoCjcRSKgvbufsuoWdlQ180ZVM4frO3AOEuKMG/PT+Njq2ayYnUnprAw9Xk7eEoW7yChzzlHd3M2hunYO1LZRVt166XL+pIQ4lhak82d3FLOkIJ0VRZlMStJfS7l2+hSJhNiAz8/Bunb2nmljX00bu08Hrv4ESIw3FuWn85nb53Lz3GwWz0zX5fwyKhTuIteou2+APafbOFDXxq5TLZSdauFCnw+A6WkTWJSfzidvnc2SggxKclNJStCDKmT0KdxFrlK/z8+rlY385kQTB72pln6fA2Du1BTetTSPlbOzWFaYSe6UCRGuVsYrhbvICJxzNHT28tuTTfz6eBOvHWuiqauXSUnxXDd9Ch9bPZtVc7JYlJ+mlSwyZgQV7ma2Dvg2EA/8wDn31WHvfxL4DOADuoANzrnDIa5VJCzaL/az42QTB2rbOVjXTsXZDlq8+7JkTEpkdXEO6xfNYE1JNskJmi+XsWnEcDezeGAjsBaoBcrMbMuw8P6Jc+57Xvv1wJPAulGoVySkLvb5OHqug4qzHRyu7+BQXSDQB5clluSmsva6XEqmpbKsMIMFM9J0ky2JCsGM3JcDJ5xzVQBm9jRwL3Ap3J1zHUPaTwZcKIsUCZXuvgEO1AZWsrx6rIFdp1rwe5/WKRMSmD99Co+8vZib52ZzY16aVrJI1Aom3POAmiHbtcCK4Y3M7DPA54Ak4I6QVCdyjS70DrDrVAu/PdnEnjNtHKxrp2/AD0BJbgqfuHUOi2emc/30KeRn6G6JEjtCdkLVObcR2GhmDwJfBD40vI2ZbQA2ABQUFITq0CJA4IEUVY1dHDrbzoHadsqqWzha38mA35EUH8eN+YHL+G+em83C/DSyUpIjXbLIqAkm3OuAmUO28719V/I08N3LveGc2wRsAigtLdXUjVyTAZ+fQ2c7Lt1cq+xUy6U7JSYnxHHTrAw2rAmsZFlWmKkpFhlXggn3MqDYzIoIhPr9wINDG5hZsXPuuLf5DuA4IiHW7/NzoLadnaea2VnVQnn17y4WmpMzmT9aPIOlBRkszE9jdvZkEuJ1sZCMXyOGu3NuwMweBrYRWAr5lHOuwsyeAMqdc1uAh83sTqAfaOUyUzIiV+tin4+Ks+284Y3Md59updsL8+KpKbx7aT4rZmeyvCiTqam6WEhkKHMuMrMjpaWlrry8PCLHlrHH53ccqe9gX00br1Q2cLLxAqeaLlx6f15uKitnZ7JidhbLizLJ1ny5jFNmtts5VzpSO12hKhFT336RXx06x+snmtl5qpnOnsB8+czMiSzMS+fexTOYP20Ky4syyZysKz9FrobCXcLC73ccb+hiz5lWyqpb2HO6lermbgBmZU3inQtnsGpOFgvz0piVNUlLEkWukcJdRkVPv489p1vZVd3CkfoOdp1qobW7Hwg883NpQQYPrijgjvm5zJ2aEuFqRWKPwl1C4lx7D5XnOzlS38Hu0628UtlAv89hBoVZk7l9/lRWe/cv1wOcRUafwl3ekqauXsqrAw9u3nWqhb1n2i69NyNtAu9fOYtbirNZVpipx8SJRIDCXYLS1NXLi4fPU17dyt6aVqoaAytZEuONBXlp/OXaEpYXZVKSm0qGTn6KRJzCXS6rp9/H7tOtlFe3squ6mR0nm/G7wHz5ovx0/uSmmSwvymBBXppueysyBincBQg8kOJwfQdvVAVWsrxS2cCFPh9mMCcnhU/fNpd3LJzO/Gmpmi8XiQIK93GsrbuPbRXn+PXxJnafbqW+vQeAvPSJvGPhdO5eMJ0lBel6upBIFFK4jyNt3X28dryJN6qa2V3dyrGGTpwLnABdUpDOnxfncPu8qUxL06X8ItFO4R7D/P7AVMv2ow28cqyRvWda8TtITU5gyawM7rlxOrfOy2FRfpqmWkRijMI9xvQN+Hnx8Hm2VzbwSmUjTV29ACzMT+Ph2+dy67ypLJ6ZTrweFScS0xTuMaCmpZvfnmziFwfqKatuoaffT9rERNaU5HBbSQ5rSnLISdWNtkTGE4V7FBpcpvjr4028UHGOKu/uiXnpE3lgeQFrinO4pThb9zMXGccU7lHAOcfRc538+ngjvz7edGl0nhhv3DQrgw+uCjw6bu7UFM2diwigcB+znHPsOdPGz3fX8uLh85fmzounpvDA8gJuKc5mRVEWk5P1n1BE/pCSYQypaenmV4fOsaOqmQO17TR19TIxMZ47r89lTXE2q4uzmZ42MdJlikgUULhHWGNnL9sqzvH8gXp2VDUDMHdqCreW5LBydiZ33zidFI3OReQqKTUioL27n3/fV8fzBwOrW5yD2TmT+dzaEv54cR4FWZMiXaKIRDmFe5j0+/y8WtnI5vIaXq1spM/nZ15uKo+8vZh7bpxOsU6GikgIKdxHkXOOirMdbD1Yz89319LQ2Ut2SjIfWDWLdy/N44YZaZEuUURilMJ9FPT0+/juKyd5Zk8tta0XiY8z3jYni6+860ZunZdDotafi8goU7iHiM/veO1YI5vLanjlWAM9/X5uLcnhM7fPZd0N0/QACxEJK4X7NXDOcaiugxePnOeZ3bXUtV0kc3ISf3LTTO6+cRpvm5Md6RJFZJxSuL8Fg6H+jRcqefVYI2awoiiTv77nOtZen0tSgqZdRCSyFO5X4fDZDv5l52lePtpAfXsPyQlxPPL2Yj78tkJNu4jImKJwD8LZtot884VjPLOnlomJ8awpyeazd5Zw1w25ekqRiIxJCvc30dDZw3dfOcm/7DzDgM/PJ2+dw4Y1s8nUKF1ExjiF+2XUtHTznZeP8+/7zuLzO961JI+Hb59LYfbkSJcmIhIUhfsQbd19fPkXR3huXx1xZrznpnw+enMhxbmpkS5NROSqBBXuZrYO+DYQD/zAOffVYe9/DngIGAAagY86506HuNZRM+Dzs7m8hq//qpILvQN8YNUsPrFmjh4ULSJRa8RwN7N4YCOwFqgFysxsi3Pu8JBme4FS51y3mX0K+Dpw32gUHGpbD9bz9V8dpbq5m5tmZfCl9TewIE+3BRCR6BbMyH05cMI5VwVgZk8D9wKXwt05t31I+zeA94eyyNHQN+DnGy9Usum1KqanTWDjg0u558ZpunmXiMSEYMI9D6gZsl0LrHiT9h8DfnktRY22Y+c7+bOf7KXyfCfvX1nA4++8QRceiUhMCekJVTN7P1AK3HqF9zcAGwAKCgpCeeigvXT4PI88vZe4OGPjg0t5x8LpEalDRGQ0BTNcrQNmDtnO9/b9HjO7E/gCsN4513u5H+Sc2+ScK3XOlebk5LyVeq/JM7treejH5WSmJLH1z29RsItIzApm5F4GFJtZEYFQvx94cGgDM1sCfB9Y55xrCHmV16ixs5e/fvYgLx4+z5KCdH7wwVKyUpIjXZaIyKgZMdydcwNm9jCwjcBSyKeccxVm9gRQ7pzbAvw9kAL8zDshecY5t34U6w5aV+8AH3xqF1WNXXz2zhI+ffsc3U9dRGJeUHPuzrmtwNZh+x4f8vrOENcVEqebL/A3z1VwpL6D//eRZdw2b2qkSxIRCYuYvUL1n3dU8+XnjxBn8D//eIGCXUTGlZgM9+1HG/ib5yq4pTibv3/vIl1pKiLjTsyF+29PNvHQj8uZnTOZb923WCdORWRciqkziztONvORH5YxbcoEnv74SgW7iIxbMTNy33umlYd+VEZB5iSe3qBgF5HxLSZG7u3d/Wz4591kpiTx/x9aoWAXkXEvJkbuT71+isbOXp799NvInaKTpyIiUT9yd86xreIci2ems6QgI9LliIiMCVEf7jtONnP0XCfvuSk/0qWIiIwZUR3uPr/jkc37yJqcxHuW5kW6HBGRMSOqw33PmVYaO3v51G1zmJQUE6cPRERCIqrDfX9NGwDrF82IcCUiImNLVId7TUs3qRMSmKoVMiIivyeqw31vTRuzsiZFugwRkTEnasP9UF07B2rbee9SrZIRERkuasP92PlOAG7VrXxFRP5A1IZ7fXsPANkpSRGuRERk7InacD9c38GMtAmkJGsJpIjIcFEb7gdr21k0Mx3vma0iIjJEVIZ7Q2cPZ1q6WZifHulSRETGpKgM99rWiwDMm5YS4UpERMamqAz3ho7AydSpqbp4SUTkcqIy3M939ALowdciIlcQpeHeQ0KckTlJyyBFRC4nSsO9l6mpycTFaaWMiMjlRGW4N3b1kp2q56SKiFxJVIZ7T7+PiYnxkS5DRGTMispw7xvwk5QQlaWLiIRFVCZk34Cf5ASN3EVEriQqw71nwEeyRu4iIlcUVEKa2TozqzSzE2b26GXeX2Nme8xswMzeG/oyf19zVx+Zk7UMUkTkSkYMdzOLBzYCdwPXAw+Y2fXDmp0BPgz8JNQFDtfR00/7xX5dwCQi8iaCuV/ucuCEc64KwMyeBu4FDg82cM5Ve+/5R6HG39PYGbg6NS994mgfSkQkagUzLZMH1AzZrvX2XTUz22Bm5WZW3tjY+FZ+BG3d/QCkT0p8S39eRGQ8COtZSefcJudcqXOuNCcn5y39jM6eQLinTlC4i4hcSTDhXgfMHLKd7+2LiIt9PgAmJ2sppIjIlQQT7mVAsZkVmVkScD+wZXTLurKL/YFw1xWqIiJXNmK4O+cGgIeBbcAR4KfOuQoze8LM1gOY2TIzqwX+BPi+mVWMVsEKdxGRkQX1dGnn3FZg67B9jw95XUZgumbUDU7LTEhSuIuIXEnUXeZZkDmJuxdM08hdRORNBDVyH0vuumEad90wLdJliIiMaVE3chcRkZEp3EVEYpDCXUQkBincRURikMJdRCQGKdxFRGKQwl1EJAYp3EVEYpA55yJzYLNG4PRb/OPZQFMIy4kW47Hf47HPMD77PR77DFff71nOuRHvmR6xcL8WZlbunCuNdB3hNh77PR77DOOz3+OxzzB6/da0jIhIDFK4i4jEoGgN902RLiBCxmO/x2OfYXz2ezz2GUap31E55y4iIm8uWkfuIiLyJqIu3M1snZlVmtkJM3s00vVcCzN7yswazOzQkH2ZZvaimR33vmd4+83M/tHr9wEzWzrkz3zIa3/czD4Uib4Ey8xmmtl2MztsZhVm9oi3P9b7PcHMdpnZfq/fX/L2F5nZTq9/m73nFGNmyd72Ce/9wiE/6zFvf6WZ/bfI9Ch4ZhZvZnvN7Bfe9njoc7WZHTSzfWZW7u0L72fcORc1X0A8cBKYDSQB+4HrI13XNfRnDbAUODRk39eBR73XjwJf817fA/wSMGAlsNPbnwlUed8zvNcZke7bm/R5OrDUe50KHAOuHwf9NiDFe50I7PT681Pgfm//94BPea8/DXzPe30/sNl7fb33uU8Giry/D/GR7t8Iff8c8BPgF972eOhzNZA9bF9YP+MR/yVc5S9sFbBtyPZjwGORrusa+1Q4LNwrgene6+lApff6+8ADw9sBDwDfH7L/99qN9S/gOWDteOo3MAnYA6wgcPFKgrf/0uebwAPpV3mvE7x2NvwzP7TdWPwi8Gzl/wTuAH7h9SGm++zVeLlwD+tnPNqmZfKAmiHbtd6+WJLrnKv3Xp8Dcr3XV+p71P5OvH92LyEwio35fnvTE/uABuBFAiPQNufcgNdkaB8u9c97vx3IIvr6/S3g84Df284i9vsM4IAXzGy3mW3w9oX1Mx51z1AdT5xzzsxicjmTmaUAzwB/4ZzrMLNL78Vqv51zPmCxmaUDzwLzI1zSqDKzdwINzrndZnZbpOsJs9XOuTozmwq8aGZHh74Zjs94tI3c64CZQ7bzvX2x5LyZTQfwvjd4+6/U96j7nZhZIoFg/xfn3L95u2O+34Occ23AdgJTEulmNjjIGtqHS/3z3k8Dmomuft8MrDezauBpAlMz3ya2+wyAc67O+95A4H/kywnzZzzawr0MKPbOticROOmyJcI1hdoWYPCs+IcIzEkP7v+gd2Z9JdDu/RNvG3CXmWV4Z9/v8vaNSRYYov9f4Ihz7skhb8V6v3O8ETtmNpHAeYYjBEL+vV6z4f0e/H28F3jZBSZetwD3eytLioBiYFd4enF1nHOPOefynXOFBP6uvuyc+1NiuM8AZjbZzFIHXxP4bB4i3J/xSJ94eAsnKu4hsMLiJPCFSNdzjX35V6Ae6Ccwn/YxAnOM/wkcB14CMr22Bmz0+n0QKB3ycz4KnPC+PhLpfo3Q59UE5iMPAPu8r3vGQb8XAnu9fh8CHvf2zyYQVCeAnwHJ3v4J3va5Zr6bAAAAYUlEQVQJ7/3ZQ37WF7zfRyVwd6T7FmT/b+N3q2Vius9e//Z7XxWDORXuz7iuUBURiUHRNi0jIiJBULiLiMQghbuISAxSuIuIxCCFu4hIDFK4i4jEIIW7iEgMUriLiMSg/wJbqc6EA5CgIgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "\n",
    "x=[k for k in range(len(distances))]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(x, distances)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to set the cutoff as 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster=defaultdict(bool)\n",
    "setpoints=defaultdict(set)\n",
    "for i in nodes.keys():\n",
    "    cluster[i]=False\n",
    "    setpoints[i]={i}\n",
    "    \n",
    "# print(cluster)\n",
    "\n",
    "for i in nodes.keys():\n",
    "    for j in nodes.keys():\n",
    "        if(i!=j and j>i and cluster[i]==False and cluster[j]==False):\n",
    "            if(euclidean_distance(nodes[i], nodes[j])<0.3):\n",
    "                setpoints[i].add(j)\n",
    "                del setpoints[j]\n",
    "                cluster[j]=True\n",
    "    cluster[i]=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  ->  {0, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 23, 24, 26, 28, 30, 31, 33, 34, 36, 38, 39, 40, 41, 42, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 65, 66, 68, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 86, 90, 91, 92, 93, 94, 95, 97, 98, 99}\n",
      "1  ->  {64, 1, 85, 7}\n",
      "15  ->  {89, 35, 37, 69, 70, 71, 15, 17, 87, 57, 29}\n",
      "22  ->  {88, 27, 22}\n",
      "25  ->  {25}\n",
      "32  ->  {32}\n",
      "43  ->  {67, 43, 63, 47}\n",
      "81  ->  {81}\n",
      "96  ->  {96}\n"
     ]
    }
   ],
   "source": [
    "for key in setpoints.keys():\n",
    "    print(key,\" -> \",setpoints[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(setpoints))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have i many nodes in place of 100. Now, we will first fix the incoming weights this i many nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "temp=[]\n",
    "for node in setpoints.keys():\n",
    "    row=torch.zeros(len(net.state_dict()[\"fc2.weight\"][0]), dtype=torch.float)\n",
    "    for val in setpoints[node]:\n",
    "        row+=net.state_dict()[\"fc2.weight\"][val]\n",
    "    temp.append(row)\n",
    "print(len(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 55])\n",
      "torch.Size([9, 55])\n"
     ]
    }
   ],
   "source": [
    "print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "net.state_dict()[\"fc2.weight\"].resize_((len(temp), len(temp[0])))\n",
    "print(net.state_dict()[\"fc2.weight\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(temp)):\n",
    "    for j in range(len(temp[0])):\n",
    "        net.state_dict()[\"fc2.weight\"][i][j]=temp[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 55])\n"
     ]
    }
   ],
   "source": [
    "print(net.state_dict()[\"fc2.weight\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "temp=[]\n",
    "for node in setpoints.keys():\n",
    "    ele=0\n",
    "    for val in setpoints[node]:\n",
    "        ele+=net.state_dict()[\"fc2.bias\"][val]\n",
    "    temp.append(ele)\n",
    "print(len(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100])\n",
      "torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "print(net.state_dict()[\"fc2.bias\"].shape)\n",
    "net.state_dict()[\"fc2.bias\"].resize_((len(temp)))\n",
    "print(net.state_dict()[\"fc2.bias\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(temp)):\n",
    "    net.state_dict()[\"fc2.bias\"][i]=temp[i]\n",
    "print(net.state_dict()[\"fc2.bias\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100])\n"
     ]
    }
   ],
   "source": [
    "print(net.state_dict()[\"fc3.weight\"].shape)\n",
    "temp=[]\n",
    "for i in range(len(net.state_dict()[\"fc3.weight\"])):\n",
    "    row=[]\n",
    "    for j in setpoints.keys():\n",
    "        ele=0\n",
    "        for val in setpoints[j]:\n",
    "            ele+=net.state_dict()[\"fc3.weight\"][i][val]\n",
    "        row.append(ele/len(setpoints[j]))\n",
    "    temp.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 9\n"
     ]
    }
   ],
   "source": [
    "print(len(temp), len(temp[0]))\n",
    "# print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 9])\n"
     ]
    }
   ],
   "source": [
    "net.state_dict()[\"fc3.weight\"].resize_(len(temp), len(temp[0]))\n",
    "for i in range(len(temp)):\n",
    "    for j in range(len(temp[0])):\n",
    "        net.state_dict()[\"fc3.weight\"][i][j]=temp[i][j]\n",
    "print(net.state_dict()[\"fc3.weight\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print((net.state_dict()[\"fc3.bias\"]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 20.020000 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the accuracy actually come up to 76.5, the actual accuracy without any pruning was 89.7. Let's try to freeze the previous layers, and do a fine_tuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for parameter in net.parameters():\n",
    "    i+=1\n",
    "    if(i<5):\n",
    "        parameter.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.1307,), (0.3081,))])\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=200,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=200,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('0', '1', '2', '3',\n",
    "           '4', '5', '6', '7', '8', '9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   torch.Size([6, 1, 5, 5]) \n",
      "  Parameter containing:\n",
      "tensor([[[[ 0.1954,  0.0121,  0.1640,  0.1464,  0.2705],\n",
      "          [ 0.1304, -0.0403,  0.1433,  0.0456, -0.0522],\n",
      "          [-0.2085, -0.1837, -0.1483, -0.0032, -0.1035],\n",
      "          [-0.0852, -0.0686,  0.1133, -0.1955, -0.1933],\n",
      "          [-0.0814, -0.1062, -0.2126, -0.1033,  0.0747]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1493,  0.1061, -0.1931, -0.0537, -0.1221],\n",
      "          [ 0.1064, -0.1001, -0.1260, -0.1717, -0.0048],\n",
      "          [-0.0145, -0.1327, -0.0277, -0.1975,  0.1304],\n",
      "          [-0.1494, -0.0456, -0.0669, -0.0927, -0.0431],\n",
      "          [ 0.2032,  0.1092, -0.0361, -0.0539, -0.1006]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1150, -0.0196, -0.0178, -0.1776, -0.1723],\n",
      "          [ 0.2551,  0.1801,  0.1082, -0.1142, -0.1189],\n",
      "          [ 0.0085, -0.0342, -0.0729, -0.1232,  0.0946],\n",
      "          [ 0.1271,  0.1823,  0.1615,  0.0363,  0.2306],\n",
      "          [ 0.2858,  0.2635, -0.0239,  0.1917, -0.0294]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2501,  0.1590,  0.1105,  0.1619, -0.1553],\n",
      "          [-0.0840,  0.0108,  0.2862, -0.0134, -0.1037],\n",
      "          [-0.0597,  0.2434,  0.2784,  0.2254,  0.3075],\n",
      "          [ 0.0174,  0.2404,  0.3834,  0.3639,  0.0302],\n",
      "          [ 0.2627, -0.0067,  0.2235,  0.3650,  0.1813]]],\n",
      "\n",
      "\n",
      "        [[[-0.1263, -0.0693, -0.1679, -0.2231,  0.0816],\n",
      "          [-0.0607, -0.0285, -0.0377, -0.1271, -0.1272],\n",
      "          [ 0.2056,  0.2435, -0.0953,  0.2570,  0.0789],\n",
      "          [ 0.2866,  0.1053,  0.1949,  0.3653,  0.3196],\n",
      "          [ 0.2184,  0.2387,  0.2585,  0.1190,  0.3265]]],\n",
      "\n",
      "\n",
      "        [[[-0.0839, -0.0380, -0.0515,  0.1580,  0.1544],\n",
      "          [ 0.0305,  0.2044, -0.1041,  0.0227,  0.1643],\n",
      "          [-0.0531,  0.2450,  0.0948,  0.2567, -0.1435],\n",
      "          [ 0.2376,  0.0989,  0.0405,  0.1566,  0.0509],\n",
      "          [ 0.0340,  0.1445,  0.0654, -0.2096, -0.0504]]]]) \n",
      "\n",
      "\n",
      "2   torch.Size([6]) \n",
      "  Parameter containing:\n",
      "tensor([0.0889, 0.2020, 0.0691, 0.1976, 0.1579, 0.0756]) \n",
      "\n",
      "\n",
      "3   torch.Size([16, 6, 5, 5]) \n",
      "  Parameter containing:\n",
      "tensor([[[[-0.0274,  0.0668,  0.0488,  0.0398, -0.0665],\n",
      "          [-0.0608,  0.0753, -0.0379, -0.0708, -0.0499],\n",
      "          [ 0.0213, -0.0393,  0.0602,  0.0631, -0.0172],\n",
      "          [-0.0192, -0.0213,  0.0593,  0.0295, -0.0479],\n",
      "          [ 0.0122,  0.0283, -0.0171, -0.0418,  0.0804]],\n",
      "\n",
      "         [[ 0.0871, -0.0707,  0.0819,  0.0117,  0.0575],\n",
      "          [-0.0282,  0.0007,  0.0180, -0.0617, -0.0293],\n",
      "          [ 0.0198,  0.0782,  0.0392, -0.0338, -0.0277],\n",
      "          [ 0.0431, -0.0100,  0.0603, -0.0399,  0.0026],\n",
      "          [-0.0332,  0.0662,  0.0012,  0.0095, -0.0582]],\n",
      "\n",
      "         [[ 0.0561,  0.0449,  0.0354, -0.0410,  0.0272],\n",
      "          [ 0.0724,  0.0942, -0.0040,  0.0277,  0.0081],\n",
      "          [ 0.0270, -0.0307, -0.0064, -0.0385,  0.0159],\n",
      "          [ 0.0504,  0.0809,  0.0430,  0.0777,  0.0367],\n",
      "          [-0.0646,  0.0218, -0.0101,  0.0375,  0.0262]],\n",
      "\n",
      "         [[-0.0235, -0.0858,  0.0660, -0.0673, -0.0697],\n",
      "          [ 0.0078,  0.0719, -0.0181, -0.0195,  0.0016],\n",
      "          [-0.0454,  0.0570, -0.0294, -0.0274, -0.0372],\n",
      "          [ 0.1082,  0.1210,  0.0632,  0.0684,  0.0632],\n",
      "          [-0.0152,  0.0922,  0.0799,  0.1105, -0.0550]],\n",
      "\n",
      "         [[-0.0672, -0.0104,  0.0473,  0.0385,  0.0964],\n",
      "          [ 0.0294,  0.0533, -0.0258,  0.0533,  0.0414],\n",
      "          [ 0.0365,  0.0543,  0.0292, -0.0066,  0.0188],\n",
      "          [ 0.0268, -0.0114,  0.0575,  0.1129, -0.0054],\n",
      "          [ 0.0972,  0.0768,  0.1025, -0.0427, -0.0169]],\n",
      "\n",
      "         [[-0.0726, -0.0107,  0.0061,  0.0363, -0.0062],\n",
      "          [-0.0734,  0.0782, -0.0339,  0.0575, -0.0311],\n",
      "          [-0.0074,  0.0626, -0.0644,  0.0099, -0.0562],\n",
      "          [-0.0196,  0.0570, -0.0007,  0.0815,  0.0461],\n",
      "          [ 0.0594,  0.0185, -0.0351,  0.0521,  0.0984]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0114,  0.1024,  0.0786,  0.0144, -0.0073],\n",
      "          [ 0.0595,  0.0455, -0.0794, -0.0819,  0.0102],\n",
      "          [-0.0503,  0.0029, -0.0508, -0.0293, -0.0326],\n",
      "          [-0.0022, -0.0103,  0.1001,  0.0145,  0.0315],\n",
      "          [ 0.0466,  0.0812,  0.0668, -0.0131,  0.0648]],\n",
      "\n",
      "         [[ 0.0362, -0.0251,  0.0047,  0.0651, -0.0518],\n",
      "          [-0.0333, -0.0493, -0.0060, -0.0515,  0.0144],\n",
      "          [-0.0453, -0.0071,  0.0713, -0.0002,  0.0601],\n",
      "          [ 0.0812,  0.0047,  0.0654,  0.0468, -0.0322],\n",
      "          [ 0.0833, -0.0038,  0.0879,  0.0529, -0.0114]],\n",
      "\n",
      "         [[ 0.0401, -0.0260,  0.0052, -0.0704,  0.0453],\n",
      "          [-0.0636, -0.0824, -0.0109, -0.0080,  0.1137],\n",
      "          [ 0.0415, -0.0511, -0.0592,  0.0319,  0.0749],\n",
      "          [-0.0010, -0.0853,  0.0453,  0.0482,  0.0497],\n",
      "          [ 0.0315, -0.0261,  0.0280, -0.0704,  0.0084]],\n",
      "\n",
      "         [[ 0.0275, -0.0780, -0.0226,  0.1107,  0.0456],\n",
      "          [ 0.0677, -0.0909,  0.0061,  0.0381,  0.1153],\n",
      "          [-0.0139,  0.0046, -0.0138,  0.0801, -0.0193],\n",
      "          [-0.0538,  0.0012,  0.0109,  0.0946,  0.0835],\n",
      "          [-0.0782, -0.0925,  0.0232, -0.0251,  0.0054]],\n",
      "\n",
      "         [[ 0.0406, -0.0635,  0.0678,  0.0119,  0.0286],\n",
      "          [ 0.0131,  0.0114, -0.0431, -0.0450,  0.0757],\n",
      "          [ 0.0367,  0.0135, -0.0189, -0.0541,  0.0548],\n",
      "          [-0.0035,  0.0002,  0.0537, -0.0344, -0.0208],\n",
      "          [ 0.0619, -0.0228, -0.0419, -0.0491, -0.0564]],\n",
      "\n",
      "         [[ 0.0369, -0.0360, -0.0599,  0.0695,  0.0653],\n",
      "          [ 0.0340,  0.0286,  0.0532,  0.0393,  0.0815],\n",
      "          [ 0.0569, -0.0509,  0.0329, -0.0111,  0.0541],\n",
      "          [ 0.0452,  0.0620,  0.0273,  0.0446, -0.0114],\n",
      "          [-0.0536,  0.0362,  0.0610, -0.0087,  0.0545]]],\n",
      "\n",
      "\n",
      "        [[[-0.0435, -0.0409,  0.0214, -0.0245, -0.0470],\n",
      "          [-0.0648,  0.0276,  0.0549,  0.0553, -0.0518],\n",
      "          [ 0.0363, -0.0539,  0.0507, -0.0488, -0.0804],\n",
      "          [-0.0775, -0.0526,  0.0312,  0.0551,  0.0234],\n",
      "          [-0.0068,  0.0559, -0.0245,  0.0723, -0.0541]],\n",
      "\n",
      "         [[-0.0349,  0.0069, -0.0183, -0.0539, -0.0567],\n",
      "          [ 0.0241,  0.0163, -0.0367, -0.0296,  0.0207],\n",
      "          [-0.0484,  0.0468,  0.0486, -0.0618,  0.0803],\n",
      "          [-0.0575,  0.0382, -0.0458,  0.0376, -0.0709],\n",
      "          [ 0.0544,  0.0047,  0.0612,  0.0189, -0.0036]],\n",
      "\n",
      "         [[ 0.0300,  0.0635, -0.0530, -0.0549,  0.0241],\n",
      "          [-0.0594, -0.0401,  0.0664, -0.0185, -0.0817],\n",
      "          [-0.0298,  0.0741,  0.0713, -0.0260,  0.0608],\n",
      "          [ 0.0465,  0.0736,  0.0003, -0.0390,  0.0363],\n",
      "          [ 0.0037, -0.0807, -0.0299, -0.0517,  0.0294]],\n",
      "\n",
      "         [[-0.0792,  0.0780,  0.0514, -0.0699, -0.0856],\n",
      "          [-0.0144, -0.0430,  0.0017,  0.0204,  0.0092],\n",
      "          [ 0.0030,  0.0179,  0.0450, -0.0480,  0.0482],\n",
      "          [ 0.0107,  0.0552,  0.0846,  0.0534, -0.0309],\n",
      "          [-0.0794, -0.0152, -0.0460,  0.0496,  0.0278]],\n",
      "\n",
      "         [[-0.0479, -0.0191,  0.0219,  0.0451, -0.0755],\n",
      "          [-0.0379,  0.0345, -0.0048,  0.0316, -0.0598],\n",
      "          [-0.0453,  0.0268,  0.0861,  0.0482,  0.0782],\n",
      "          [ 0.0281,  0.0489,  0.0117, -0.0046,  0.0457],\n",
      "          [-0.0529, -0.0806,  0.0494,  0.0352,  0.0617]],\n",
      "\n",
      "         [[-0.0768,  0.0607,  0.0444,  0.0540, -0.0495],\n",
      "          [ 0.0513, -0.0188, -0.0549, -0.0502, -0.0427],\n",
      "          [ 0.0179, -0.0705, -0.0647,  0.0449,  0.0746],\n",
      "          [-0.0253, -0.0430, -0.0533,  0.0573,  0.0787],\n",
      "          [-0.0562, -0.0676,  0.0715, -0.0026,  0.0565]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0867,  0.0743,  0.0552, -0.0527,  0.0324],\n",
      "          [ 0.0953, -0.0199, -0.0295, -0.0403,  0.0669],\n",
      "          [-0.0332, -0.0047,  0.0819,  0.0500, -0.0737],\n",
      "          [ 0.0702,  0.0296,  0.0512, -0.0141, -0.0785],\n",
      "          [ 0.0105, -0.0372,  0.0275, -0.0444,  0.0801]],\n",
      "\n",
      "         [[ 0.0696,  0.0756, -0.0469, -0.0089,  0.0436],\n",
      "          [-0.0002,  0.0689,  0.0646, -0.0738,  0.0002],\n",
      "          [ 0.0474,  0.0280,  0.0370, -0.0493,  0.0114],\n",
      "          [ 0.0923,  0.0150, -0.0433,  0.0001,  0.0055],\n",
      "          [ 0.0284,  0.0790, -0.0025,  0.0587,  0.0567]],\n",
      "\n",
      "         [[ 0.0074, -0.0313, -0.0270,  0.0253,  0.1055],\n",
      "          [ 0.0361, -0.0577, -0.0685,  0.0318,  0.1180],\n",
      "          [-0.0353,  0.0548, -0.0407,  0.0525,  0.0153],\n",
      "          [ 0.0303,  0.0579, -0.0119, -0.0442, -0.0267],\n",
      "          [-0.0016,  0.0065,  0.0044, -0.0504,  0.0356]],\n",
      "\n",
      "         [[-0.0432, -0.0143,  0.0811,  0.1546,  0.0607],\n",
      "          [-0.0778, -0.0240, -0.0319, -0.0030,  0.1579],\n",
      "          [-0.0280, -0.0699, -0.0876, -0.0119,  0.0790],\n",
      "          [-0.0983,  0.0210, -0.0514,  0.0689,  0.0750],\n",
      "          [ 0.0074, -0.0144, -0.0070,  0.1365,  0.0485]],\n",
      "\n",
      "         [[-0.0079,  0.0315,  0.0655,  0.1064,  0.0607],\n",
      "          [-0.0207,  0.0698, -0.0483,  0.0416, -0.0130],\n",
      "          [-0.0263, -0.0218, -0.0671, -0.0247, -0.0565],\n",
      "          [-0.0670,  0.0891, -0.0003,  0.0927,  0.0647],\n",
      "          [ 0.0704,  0.1173,  0.1078,  0.0087,  0.0593]],\n",
      "\n",
      "         [[-0.0422, -0.0288,  0.0488, -0.0428,  0.0470],\n",
      "          [ 0.0696,  0.0237, -0.0314,  0.0103,  0.0643],\n",
      "          [ 0.0073,  0.0481,  0.0067, -0.0726,  0.1036],\n",
      "          [-0.0580,  0.0370,  0.0404,  0.0295,  0.1155],\n",
      "          [-0.0567,  0.0523, -0.0587,  0.1055,  0.0410]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0494,  0.0188, -0.0594,  0.0070, -0.0301],\n",
      "          [-0.0539,  0.0506, -0.0009,  0.0335, -0.0584],\n",
      "          [-0.0223, -0.0533, -0.0312,  0.0398,  0.0861],\n",
      "          [ 0.1027,  0.0827, -0.0508, -0.0525,  0.0070],\n",
      "          [-0.0051, -0.0598, -0.0588,  0.0543, -0.0164]],\n",
      "\n",
      "         [[-0.0394, -0.0533,  0.0378,  0.0225, -0.0490],\n",
      "          [ 0.0349,  0.0437, -0.0357,  0.0521,  0.0238],\n",
      "          [-0.0905, -0.0332, -0.0659,  0.0634, -0.0678],\n",
      "          [-0.0556,  0.0413,  0.0085,  0.0435, -0.0020],\n",
      "          [ 0.0443, -0.0254, -0.0296, -0.0663,  0.0819]],\n",
      "\n",
      "         [[-0.0185, -0.0457,  0.1023, -0.0410,  0.0640],\n",
      "          [ 0.0264,  0.0874,  0.0540,  0.0342,  0.0361],\n",
      "          [-0.0413,  0.0394, -0.0428,  0.0182,  0.0852],\n",
      "          [-0.0026, -0.0659,  0.0330,  0.0022, -0.0459],\n",
      "          [ 0.0110,  0.0995,  0.0537,  0.0596,  0.0756]],\n",
      "\n",
      "         [[ 0.1012,  0.1081,  0.1025,  0.0072,  0.0945],\n",
      "          [ 0.1049,  0.0643, -0.0273, -0.0367, -0.0208],\n",
      "          [ 0.1000, -0.0200,  0.0096, -0.0624, -0.0181],\n",
      "          [ 0.0792,  0.0939,  0.0946, -0.0568,  0.0760],\n",
      "          [-0.0009,  0.0744,  0.0837,  0.0012,  0.0194]],\n",
      "\n",
      "         [[ 0.0291,  0.1435,  0.1299,  0.0036,  0.0871],\n",
      "          [ 0.1035,  0.1228,  0.0380,  0.0254, -0.0240],\n",
      "          [ 0.0477, -0.0669, -0.0055,  0.0057,  0.0287],\n",
      "          [-0.0513, -0.0424,  0.0483, -0.0601,  0.0486],\n",
      "          [ 0.0921,  0.1021,  0.0908,  0.0888,  0.0490]],\n",
      "\n",
      "         [[-0.0384, -0.0154,  0.0436, -0.0105,  0.0451],\n",
      "          [ 0.0901,  0.0776, -0.0301,  0.0690, -0.0309],\n",
      "          [ 0.1104,  0.0425,  0.0419, -0.0453,  0.0458],\n",
      "          [-0.0307, -0.0534, -0.0394,  0.0236,  0.0465],\n",
      "          [-0.0692, -0.0183,  0.0089, -0.0206,  0.0389]]],\n",
      "\n",
      "\n",
      "        [[[-0.0020,  0.0751,  0.0134,  0.0531,  0.0574],\n",
      "          [ 0.0035, -0.0578,  0.0161,  0.0412,  0.0589],\n",
      "          [-0.0216, -0.0487,  0.0395,  0.0251,  0.0705],\n",
      "          [-0.0222, -0.0647, -0.0208, -0.0473, -0.0246],\n",
      "          [-0.0302,  0.0293,  0.0256, -0.0031, -0.0733]],\n",
      "\n",
      "         [[ 0.0202,  0.0780,  0.0265,  0.0221,  0.0742],\n",
      "          [-0.0200,  0.0266, -0.0203, -0.0096, -0.0161],\n",
      "          [ 0.0744,  0.0783,  0.0429, -0.0358,  0.0033],\n",
      "          [ 0.0600, -0.0126,  0.0445, -0.0565,  0.0733],\n",
      "          [-0.0548, -0.0381, -0.0142,  0.0790,  0.0888]],\n",
      "\n",
      "         [[-0.0486, -0.0391, -0.0214,  0.0725,  0.0748],\n",
      "          [-0.0770, -0.0661,  0.0356, -0.0094, -0.0375],\n",
      "          [-0.0385,  0.0706, -0.0204, -0.0250, -0.0701],\n",
      "          [-0.0112, -0.0123,  0.0035,  0.0503, -0.0716],\n",
      "          [ 0.0283, -0.0026, -0.0314, -0.0128, -0.0613]],\n",
      "\n",
      "         [[-0.0692, -0.0151, -0.0098,  0.0471,  0.0380],\n",
      "          [-0.0333, -0.0265,  0.0236,  0.1058, -0.0391],\n",
      "          [ 0.0353,  0.0279,  0.0909,  0.0711, -0.0662],\n",
      "          [-0.0403,  0.0075,  0.0402, -0.0218,  0.0152],\n",
      "          [ 0.0320, -0.0144, -0.0312,  0.0275, -0.0524]],\n",
      "\n",
      "         [[-0.0635, -0.0759, -0.0257,  0.0932,  0.0480],\n",
      "          [-0.0533, -0.0012,  0.0481,  0.0972, -0.0115],\n",
      "          [ 0.0317,  0.0682, -0.0040,  0.0312,  0.0618],\n",
      "          [-0.0353,  0.0874,  0.0021, -0.0651, -0.0505],\n",
      "          [-0.0716, -0.0393,  0.0481, -0.0397, -0.0488]],\n",
      "\n",
      "         [[ 0.0703, -0.0039, -0.0368,  0.0487,  0.0421],\n",
      "          [-0.0564,  0.0273, -0.0645,  0.0598, -0.0491],\n",
      "          [ 0.0688, -0.0356,  0.0441,  0.0353, -0.0540],\n",
      "          [-0.0733,  0.0374, -0.0255,  0.0311, -0.0593],\n",
      "          [-0.0586, -0.0194, -0.0267,  0.0013,  0.0008]]]]) \n",
      "\n",
      "\n",
      "4   torch.Size([16]) \n",
      "  Parameter containing:\n",
      "tensor([ 0.0678, -0.0424, -0.0553, -0.0554, -0.0523, -0.0426,  0.0439, -0.0724,\n",
      "         0.0329, -0.0029,  0.0769,  0.0866,  0.0797, -0.0330, -0.0008, -0.0292]) \n",
      "\n",
      "\n",
      "5   torch.Size([55, 256]) \n",
      "  Parameter containing:\n",
      "tensor([[ 0.1788,  0.0132,  0.0051,  ...,  0.1006,  0.1621,  0.0827],\n",
      "        [-0.3495,  0.1669,  0.3357,  ...,  0.1568, -0.1974,  0.2413],\n",
      "        [ 0.0000, -0.1995,  0.1894,  ...,  0.2430, -0.1410,  0.3510],\n",
      "        ...,\n",
      "        [ 0.0664,  0.0205, -0.0364,  ...,  0.0464,  0.0060,  0.0393],\n",
      "        [-0.0139, -0.0116,  0.0496,  ..., -0.0369,  0.0191, -0.0189],\n",
      "        [ 0.0527,  0.0226,  0.0221,  ..., -0.0559, -0.0571,  0.0290]],\n",
      "       requires_grad=True) \n",
      "\n",
      "\n",
      "6   torch.Size([55]) \n",
      "  Parameter containing:\n",
      "tensor([-0.0747, -0.1390, -0.1982,  0.0720,  0.0447, -0.0184, -0.0113, -0.2750,\n",
      "         0.0008, -0.2004,  0.1164,  0.0579,  0.1651,  0.0614, -0.0184, -0.0478,\n",
      "         0.0617, -0.0499, -0.0563,  0.0695, -0.0112, -0.0368, -0.0115,  0.0001,\n",
      "        -0.0141, -0.0474, -0.0006, -0.0548,  0.0318, -0.0318, -0.0113, -0.0348,\n",
      "         0.0619, -0.0023, -0.0467,  0.0837,  0.0662,  0.0515,  0.0426,  0.0394,\n",
      "         0.0142, -0.0300,  0.0357,  0.0452,  0.0521,  0.0475,  0.0233,  0.0245,\n",
      "         0.0237, -0.0853,  0.0630, -0.0256,  0.0539,  0.0162,  0.0385],\n",
      "       requires_grad=True) \n",
      "\n",
      "\n",
      "7   torch.Size([9, 55]) \n",
      "  Parameter containing:\n",
      "tensor([[ 0.1396,  0.2146,  0.0305,  0.1000, -0.2506, -0.3103, -0.0339,  0.0622,\n",
      "         -0.0685, -0.0263,  0.0544,  0.4408,  0.0812,  0.1519,  0.3024, -0.0031,\n",
      "         -0.2842,  0.2597, -0.1007, -0.1833, -0.5407, -0.2801, -0.4714, -0.2376,\n",
      "         -0.4876, -0.0819,  0.4334,  0.6832,  0.2051, -0.4018, -0.0525, -0.0527,\n",
      "         -0.6050,  0.4067,  0.3234, -0.1037,  0.3481,  0.4418,  0.1963, -0.4829,\n",
      "          0.5532,  0.2034, -0.0170,  0.0559,  0.0490, -0.2244, -0.3482, -0.4184,\n",
      "          0.4315,  0.4495, -0.3067,  0.3717,  0.5113, -0.5807, -0.5370],\n",
      "        [ 0.0097,  0.0019, -0.0139, -0.0196,  0.0101,  0.0598, -0.0038, -0.0241,\n",
      "          0.0084,  0.0562,  0.0080, -0.0103, -0.0143,  0.0767,  0.0363,  0.0024,\n",
      "          0.0214, -0.0454,  0.1184, -0.0020, -0.0106,  0.0153, -0.0624, -0.0478,\n",
      "         -0.0343,  0.1402, -0.1242,  0.1299,  0.0797, -0.0368,  0.0050,  0.1464,\n",
      "          0.1191,  0.2995, -0.0836,  0.1012,  0.0867, -0.0646, -0.0050, -0.0545,\n",
      "         -0.0142, -0.0910,  0.1194, -0.0796, -0.0221,  0.2668,  0.0656, -0.0990,\n",
      "          0.0762,  0.0320,  0.0304,  0.0604,  0.0511,  0.0426, -0.0421],\n",
      "        [-0.0121,  0.0115,  0.0693, -0.0518,  0.0139, -0.0292,  0.0106,  0.0318,\n",
      "          0.0790,  0.0094,  0.0161, -0.0587,  0.0861,  0.0146, -0.0199, -0.0331,\n",
      "         -0.0454, -0.0602,  0.1177, -0.0349,  0.3128,  0.1189,  0.1578,  0.0331,\n",
      "          0.1830,  0.0530, -0.0467,  0.1702, -0.0154, -0.0054,  0.1803, -0.1798,\n",
      "         -0.0814,  0.0167, -0.1015, -0.1418, -0.0032,  0.0980,  0.0284, -0.1491,\n",
      "         -0.0007,  0.0395, -0.0022,  0.0499,  0.1994, -0.0047, -0.0474,  0.1519,\n",
      "          0.0393, -0.1931,  0.1018, -0.0976, -0.1518, -0.1698, -0.0975],\n",
      "        [-0.0304,  0.0005, -0.0154,  0.0145,  0.0407,  0.0207,  0.0384, -0.0011,\n",
      "          0.0161,  0.0123, -0.0260, -0.0410, -0.0054,  0.0367,  0.0077,  0.0088,\n",
      "          0.0254,  0.0829,  0.0504,  0.0229,  0.0866,  0.0638, -0.0390, -0.1104,\n",
      "          0.0549,  0.0083, -0.0527,  0.0115, -0.0555,  0.1263, -0.0574,  0.1147,\n",
      "          0.0556, -0.0111, -0.0473, -0.0587,  0.1328, -0.0105, -0.0089, -0.0353,\n",
      "          0.0674,  0.1127, -0.0252,  0.0428, -0.0984,  0.0664,  0.0327, -0.0344,\n",
      "          0.1589,  0.1258,  0.1777, -0.0720,  0.0794,  0.1875, -0.1472],\n",
      "        [ 0.0118,  0.0190, -0.0048,  0.0177,  0.0223,  0.0116,  0.0026, -0.0125,\n",
      "          0.0030, -0.0053, -0.0067,  0.0030, -0.0231, -0.0174,  0.0069,  0.0123,\n",
      "         -0.0410, -0.0200, -0.0486,  0.0348,  0.0526,  0.0194,  0.0516,  0.0194,\n",
      "          0.0151,  0.0660,  0.0500, -0.0230,  0.0145,  0.0475, -0.0346, -0.0175,\n",
      "          0.0663,  0.0020,  0.0104,  0.0527,  0.0702,  0.0405,  0.0209, -0.0326,\n",
      "         -0.0139,  0.0592,  0.0493,  0.0181, -0.0599,  0.0151, -0.0432,  0.0198,\n",
      "         -0.0405,  0.0517,  0.0124,  0.0423,  0.0605, -0.0055, -0.0461],\n",
      "        [-0.0184,  0.0048, -0.0003, -0.0053,  0.0066,  0.0118,  0.0165,  0.0046,\n",
      "          0.0029, -0.0010, -0.0222,  0.0100,  0.0004,  0.0247, -0.0012, -0.0154,\n",
      "          0.0084,  0.0396, -0.0078, -0.0162,  0.0246,  0.0467,  0.0554, -0.0125,\n",
      "         -0.0301,  0.0051,  0.0339,  0.0136, -0.0030,  0.0596, -0.0769, -0.0582,\n",
      "          0.0532, -0.0576,  0.0200,  0.0394,  0.0478, -0.0173, -0.0373,  0.0571,\n",
      "         -0.0070, -0.0428, -0.0277,  0.0585,  0.0170,  0.0598, -0.0396,  0.0542,\n",
      "         -0.0144, -0.0091,  0.0729, -0.0423,  0.0424,  0.0067,  0.0153],\n",
      "        [ 0.0552, -0.0071,  0.0283, -0.0142, -0.0091,  0.0196,  0.0026,  0.0349,\n",
      "          0.0222, -0.0241, -0.0128,  0.0081,  0.0260, -0.0389, -0.0253, -0.0229,\n",
      "          0.1118,  0.0794,  0.0238, -0.0421, -0.0714, -0.0538,  0.0877,  0.0387,\n",
      "         -0.0604,  0.0066,  0.0018, -0.0665,  0.0078, -0.0237,  0.0337,  0.0550,\n",
      "          0.0046,  0.1594, -0.0726,  0.1937, -0.0184, -0.1071, -0.1554,  0.0104,\n",
      "         -0.0493,  0.0029,  0.1277,  0.1000, -0.1110,  0.1616,  0.1205,  0.0961,\n",
      "         -0.0478, -0.1203, -0.2482,  0.1049, -0.0244, -0.0902, -0.0505],\n",
      "        [-0.0034,  0.0045,  0.0087,  0.0023, -0.0317, -0.0225, -0.0018, -0.0007,\n",
      "          0.0182,  0.0020, -0.0076,  0.0179, -0.0102,  0.0316,  0.0303,  0.0005,\n",
      "         -0.0288,  0.0477,  0.0242,  0.0024,  0.0701,  0.0527, -0.0013,  0.0211,\n",
      "          0.0082, -0.0237,  0.0461, -0.0635,  0.0040, -0.0228,  0.0031, -0.0144,\n",
      "         -0.0302, -0.0221, -0.0103, -0.0433, -0.0591,  0.0620,  0.0340,  0.0522,\n",
      "         -0.0268, -0.0349, -0.0617,  0.0837, -0.0249,  0.0490,  0.0216,  0.0093,\n",
      "          0.0291,  0.0082,  0.0614, -0.0583,  0.0318, -0.0151,  0.0115],\n",
      "        [-0.0044,  0.0198, -0.0075,  0.0032,  0.0087,  0.0074, -0.0038,  0.0031,\n",
      "         -0.0113,  0.0052,  0.0115,  0.0196, -0.0083, -0.0088,  0.0190, -0.0090,\n",
      "          0.0391, -0.0199,  0.0004,  0.0185, -0.0129,  0.0458, -0.0063,  0.0122,\n",
      "         -0.0421,  0.0200,  0.0061, -0.0333, -0.0206,  0.0685,  0.0518, -0.0595,\n",
      "          0.0425, -0.0080,  0.0346,  0.0113,  0.0390,  0.0388,  0.0097,  0.0042,\n",
      "          0.0342, -0.0623,  0.0659, -0.0473,  0.0211,  0.0621, -0.0361,  0.0149,\n",
      "          0.0639,  0.0281, -0.0113, -0.0393, -0.0569,  0.0422,  0.0000]],\n",
      "       requires_grad=True) \n",
      "\n",
      "\n",
      "8   torch.Size([9]) \n",
      "  Parameter containing:\n",
      "tensor([-0.0625, -0.0119,  0.3021,  0.1184,  0.0551,  0.0163,  0.0629,  0.0282,\n",
      "        -0.0221], requires_grad=True) \n",
      "\n",
      "\n",
      "9   torch.Size([10, 9]) \n",
      "  Parameter containing:\n",
      "tensor([[ 0.0180, -0.0800, -0.0653, -0.1477, -0.0385,  0.0263, -0.0068, -0.1793,\n",
      "          0.1037],\n",
      "        [-0.0182, -0.0363,  0.0903,  0.0145,  0.0100,  0.0683, -0.0792, -0.0348,\n",
      "          0.1147],\n",
      "        [-0.0111,  0.0365,  0.0383, -0.1205, -0.0856, -0.1287,  0.1204, -0.0148,\n",
      "          0.0925],\n",
      "        [ 0.0180, -0.0323,  0.0393, -0.0372, -0.0775, -0.1173, -0.0909,  0.0261,\n",
      "         -0.0772],\n",
      "        [-0.0208,  0.1191,  0.0046,  0.0963,  0.1326, -0.0046, -0.0451, -0.0710,\n",
      "         -0.1130],\n",
      "        [ 0.0066,  0.0416, -0.0446,  0.0678, -0.1250,  0.0278, -0.1020,  0.0750,\n",
      "          0.0652],\n",
      "        [ 0.0053,  0.0899, -0.0676,  0.0571,  0.0975, -0.0967, -0.0345, -0.1865,\n",
      "          0.1261],\n",
      "        [-0.0092, -0.1093, -0.0057,  0.0105,  0.1111,  0.0785,  0.0084,  0.1432,\n",
      "          0.0662],\n",
      "        [-0.0045, -0.0021, -0.0147,  0.0197, -0.1264,  0.0802,  0.0315,  0.0785,\n",
      "          0.0809],\n",
      "        [-0.0103, -0.0077,  0.0031,  0.0144,  0.0202,  0.1446, -0.0224,  0.0121,\n",
      "         -0.0661]], requires_grad=True) \n",
      "\n",
      "\n",
      "10   torch.Size([10]) \n",
      "  Parameter containing:\n",
      "tensor([ 0.0504,  0.1393, -0.0627, -0.0188,  0.0212, -0.0102, -0.0827, -0.0165,\n",
      "        -0.1006, -0.0129], requires_grad=True) \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for parameter in net.parameters():\n",
    "    i+=1\n",
    "    print(i,\" \",parameter.shape,\"\\n \",parameter,\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 20] loss: 0.01493951117992401\n",
      "[1, 40] loss: 0.010079670310020447\n",
      "[1, 60] loss: 0.0075220798552036285\n",
      "[1, 80] loss: 0.006904089391231537\n",
      "[1, 100] loss: 0.006085632905364037\n",
      "[1, 120] loss: 0.005543911695480346\n",
      "[1, 140] loss: 0.005420042231678962\n",
      "[1, 160] loss: 0.00521805639564991\n",
      "[1, 180] loss: 0.005266212686896324\n",
      "[1, 200] loss: 0.004819429323077202\n",
      "[1, 220] loss: 0.004627482429146766\n",
      "[1, 240] loss: 0.004280118450522423\n",
      "[1, 260] loss: 0.00429269951581955\n",
      "[1, 280] loss: 0.004333766832947731\n",
      "[1, 300] loss: 0.004646014899015427\n",
      "[2, 20] loss: 0.004307595640420913\n",
      "[2, 40] loss: 0.004186353892087937\n",
      "[2, 60] loss: 0.00413302980363369\n",
      "[2, 80] loss: 0.003775287628173828\n",
      "[2, 100] loss: 0.0039047192186117173\n",
      "[2, 120] loss: 0.0036944630295038224\n",
      "[2, 140] loss: 0.0036511582136154173\n",
      "[2, 160] loss: 0.0033574295192956923\n",
      "[2, 180] loss: 0.0036726468801498414\n",
      "[2, 200] loss: 0.003505796045064926\n",
      "[2, 220] loss: 0.0033674311414361\n",
      "[2, 240] loss: 0.0034637048840522764\n",
      "[2, 260] loss: 0.003340069226920605\n",
      "[2, 280] loss: 0.003239184118807316\n",
      "[2, 300] loss: 0.003303112633526325\n",
      "Finished Reraining\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        # print(inputs.shape)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    # print every 2000 mini-batches\n",
    "            print(\"[{}, {}] loss: {}\".format\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Reraining')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"LeNET_x_y_MNIST_Model_My_Exiperiment_1_Fine_Tuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, len(net.state_dict()[\"fc1.weight\"]))\n",
    "        self.fc2 = nn.Linear(len(net.state_dict()[\"fc1.weight\"]), len(net.state_dict()[\"fc2.weight\"]))\n",
    "        self.fc3 = nn.Linear(len(net.state_dict()[\"fc2.weight\"]), 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(\"LeNET_x_y_MNIST_Model_My_Exiperiment_1_Fine_Tuned\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 24, 24]             156\n",
      "         MaxPool2d-2            [-1, 6, 12, 12]               0\n",
      "            Conv2d-3             [-1, 16, 8, 8]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 4, 4]               0\n",
      "            Linear-5                   [-1, 55]          14,135\n",
      "            Linear-6                    [-1, 9]             504\n",
      "            Linear-7                   [-1, 10]             100\n",
      "================================================================\n",
      "Total params: 17,311\n",
      "Trainable params: 17,311\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 0.07\n",
      "Estimated Total Size (MB): 0.11\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "device=torch.device(\"cpu\")\n",
    "model=Net().to(device)\n",
    "summary(model, input_size=(1, 28, 28), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, number of parametes reduced down to 86k from 110 k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 90.860000 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the accuracy improved from 89.7 to 93.4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources:\n",
    "[https://towardsdatascience.com/how-to-cluster-in-high-dimensions-4ef693bacc6] [1/11/2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
