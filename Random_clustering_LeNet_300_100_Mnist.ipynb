{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 300)\n",
    "        self.fc2 = nn.Linear(300, 100)\n",
    "        self.fc3 = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(\"LeNET_300_100_MNIST_Model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 24, 24]             156\n",
      "         MaxPool2d-2            [-1, 6, 12, 12]               0\n",
      "            Conv2d-3             [-1, 16, 8, 8]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 4, 4]               0\n",
      "            Linear-5                  [-1, 300]          77,100\n",
      "            Linear-6                  [-1, 100]          30,100\n",
      "            Linear-7                   [-1, 10]           1,010\n",
      "================================================================\n",
      "Total params: 110,782\n",
      "Trainable params: 110,782\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.05\n",
      "Params size (MB): 0.42\n",
      "Estimated Total Size (MB): 0.47\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "device=torch.device(\"cpu\")\n",
    "model=Net().to(device)\n",
    "summary(model, input_size=(1, 28, 28), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.1307,), (0.3081,))])\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=200,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 98.110000 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight \t torch.Size([6, 1, 5, 5])\n",
      "conv1.weight \t tensor([[[[-0.0192,  0.2511,  0.2183,  0.0210,  0.0190],\n",
      "          [-0.0522,  0.3645,  0.3561,  0.5513,  0.3440],\n",
      "          [ 0.0598,  0.5070,  0.6116,  0.6220,  0.2953],\n",
      "          [ 0.2985,  0.1301,  0.4567,  0.1638,  0.2149],\n",
      "          [-0.0246,  0.3206,  0.1249,  0.1288, -0.1632]]],\n",
      "\n",
      "\n",
      "        [[[-0.1775, -0.0977,  0.0400,  0.2623,  0.2931],\n",
      "          [ 0.0318, -0.1988, -0.1956,  0.1583,  0.1678],\n",
      "          [-0.2439, -0.2983, -0.0792,  0.2235,  0.3461],\n",
      "          [-0.0280, -0.2769, -0.1121,  0.0926,  0.3560],\n",
      "          [-0.1970, -0.1645,  0.1938,  0.2115,  0.1824]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1362,  0.2118, -0.2154, -0.2076, -0.2334],\n",
      "          [ 0.2467, -0.0821, -0.1670, -0.0738,  0.2066],\n",
      "          [ 0.2564,  0.1952,  0.2048,  0.3864,  0.0963],\n",
      "          [ 0.0786,  0.3546,  0.3418, -0.0168,  0.1037],\n",
      "          [ 0.0178, -0.2039, -0.1759, -0.0146, -0.0048]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0299,  0.1694, -0.0029, -0.1827, -0.0718],\n",
      "          [-0.1909, -0.1638,  0.1044, -0.2096,  0.0405],\n",
      "          [ 0.0873, -0.1777, -0.1820, -0.0258, -0.1887],\n",
      "          [ 0.0190, -0.1462, -0.0486,  0.0288, -0.2104],\n",
      "          [ 0.1727, -0.1630, -0.0454, -0.2031, -0.1915]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1378,  0.0087, -0.1978, -0.2727,  0.0345],\n",
      "          [ 0.2285, -0.0154, -0.1342, -0.2998, -0.0739],\n",
      "          [ 0.2801,  0.2191,  0.1079,  0.2947,  0.1320],\n",
      "          [ 0.3344,  0.4029,  0.3628,  0.5148,  0.0400],\n",
      "          [ 0.0682,  0.0300,  0.3382,  0.2907,  0.3091]]],\n",
      "\n",
      "\n",
      "        [[[-0.2584, -0.2308, -0.1856,  0.0330,  0.0465],\n",
      "          [-0.2978, -0.1939, -0.2057,  0.0400,  0.1692],\n",
      "          [ 0.0883, -0.1518,  0.0861, -0.1625,  0.0874],\n",
      "          [ 0.1464,  0.2543,  0.0292,  0.0581, -0.0674],\n",
      "          [ 0.3818,  0.3657,  0.2362, -0.0540,  0.1097]]]])\n",
      "conv1.bias \t torch.Size([6])\n",
      "conv1.bias \t tensor([ 0.2434, -0.0632,  0.2198,  0.1060,  0.1912,  0.0086])\n",
      "conv2.weight \t torch.Size([16, 6, 5, 5])\n",
      "conv2.weight \t tensor([[[[-0.0109, -0.0548, -0.0268,  0.0555,  0.0529],\n",
      "          [-0.0747, -0.0093, -0.0871,  0.0756,  0.0290],\n",
      "          [ 0.0085, -0.0744, -0.1693, -0.1346, -0.1455],\n",
      "          [ 0.0382, -0.0446, -0.1455, -0.0654, -0.0830],\n",
      "          [ 0.0522,  0.1614,  0.1331,  0.1559,  0.0276]],\n",
      "\n",
      "         [[-0.0135,  0.0531,  0.0238,  0.0102,  0.0312],\n",
      "          [ 0.0628, -0.0327,  0.0206, -0.0319,  0.0428],\n",
      "          [-0.0834, -0.1235, -0.0557,  0.0262, -0.0169],\n",
      "          [ 0.0244, -0.0334,  0.0382, -0.0140,  0.0345],\n",
      "          [ 0.1239, -0.0369, -0.0981, -0.0913, -0.0969]],\n",
      "\n",
      "         [[-0.0242, -0.0831,  0.0583,  0.0632, -0.0662],\n",
      "          [-0.0261, -0.0701,  0.0334, -0.0154,  0.0068],\n",
      "          [-0.0244,  0.0824, -0.1057, -0.1036,  0.0335],\n",
      "          [-0.0140,  0.1386,  0.0705,  0.0171, -0.0072],\n",
      "          [ 0.0018,  0.1739,  0.1223,  0.0542,  0.0006]],\n",
      "\n",
      "         [[ 0.0685,  0.0419, -0.0685, -0.0128, -0.0514],\n",
      "          [ 0.0531,  0.0907, -0.0022,  0.0279,  0.0706],\n",
      "          [ 0.0644,  0.0581,  0.0447,  0.0862, -0.0299],\n",
      "          [-0.0563, -0.0664,  0.0204, -0.0461, -0.0049],\n",
      "          [-0.0201, -0.0669, -0.0425, -0.0638,  0.0590]],\n",
      "\n",
      "         [[-0.0472,  0.0201, -0.0225, -0.0141, -0.0058],\n",
      "          [ 0.0624,  0.0067,  0.0042,  0.0046,  0.0419],\n",
      "          [ 0.0394,  0.0676, -0.0732, -0.1638, -0.0343],\n",
      "          [ 0.1362,  0.1999,  0.0978,  0.1239,  0.0379],\n",
      "          [ 0.0652,  0.1395,  0.1929,  0.1191,  0.0623]],\n",
      "\n",
      "         [[ 0.0314, -0.0123, -0.0633,  0.0803,  0.0407],\n",
      "          [-0.0420,  0.0859,  0.0217, -0.0667,  0.0375],\n",
      "          [ 0.0298,  0.0806,  0.0096,  0.0557, -0.0537],\n",
      "          [ 0.0555, -0.0591,  0.0920,  0.1185,  0.0150],\n",
      "          [-0.0733, -0.1120, -0.0059,  0.1112,  0.0869]]],\n",
      "\n",
      "\n",
      "        [[[-0.0222, -0.0632,  0.0230,  0.0518,  0.0471],\n",
      "          [-0.0131, -0.0666, -0.0177, -0.0039,  0.0601],\n",
      "          [ 0.0307,  0.0119,  0.1052, -0.0188,  0.0316],\n",
      "          [-0.0572, -0.0849, -0.0043,  0.1368,  0.0699],\n",
      "          [-0.0658, -0.1288, -0.1282, -0.0940, -0.0316]],\n",
      "\n",
      "         [[ 0.0440,  0.0498,  0.0480,  0.0980,  0.0044],\n",
      "          [-0.0486,  0.0267,  0.0349, -0.0436,  0.0280],\n",
      "          [-0.0089,  0.0524,  0.0789, -0.0944, -0.0586],\n",
      "          [-0.0659,  0.0035,  0.0432, -0.0714, -0.0228],\n",
      "          [ 0.0241, -0.0759, -0.0205,  0.0458, -0.0653]],\n",
      "\n",
      "         [[-0.0281,  0.0291, -0.0404,  0.0430, -0.0491],\n",
      "          [ 0.0727, -0.0770, -0.0016,  0.0005,  0.0026],\n",
      "          [-0.0638,  0.0402,  0.0268,  0.0278, -0.0408],\n",
      "          [-0.0593, -0.0857, -0.0497,  0.1150,  0.1128],\n",
      "          [-0.0520, -0.0732, -0.0377, -0.0443, -0.0022]],\n",
      "\n",
      "         [[-0.0036, -0.0737,  0.0009,  0.0342,  0.0625],\n",
      "          [ 0.0713, -0.0301, -0.0545, -0.0360, -0.0155],\n",
      "          [ 0.0323,  0.0786, -0.0489, -0.0150, -0.0732],\n",
      "          [-0.0087,  0.0101,  0.0736, -0.0299,  0.0564],\n",
      "          [ 0.0291, -0.0514,  0.0165, -0.0648, -0.0488]],\n",
      "\n",
      "         [[-0.0781,  0.0070, -0.0439,  0.0522,  0.0101],\n",
      "          [-0.0655, -0.0328,  0.0275, -0.0029, -0.0499],\n",
      "          [-0.0462,  0.0460,  0.0361,  0.1371,  0.0840],\n",
      "          [ 0.0280, -0.0768,  0.0399,  0.0632,  0.1553],\n",
      "          [ 0.0167,  0.0032, -0.0908, -0.1111, -0.0763]],\n",
      "\n",
      "         [[ 0.0044,  0.0608, -0.0532, -0.0601,  0.0587],\n",
      "          [-0.0058, -0.0142, -0.0047, -0.0417, -0.0031],\n",
      "          [-0.0824, -0.0439, -0.0758, -0.0655, -0.0323],\n",
      "          [ 0.0141, -0.0282,  0.0304,  0.0188, -0.0538],\n",
      "          [-0.0402,  0.0069,  0.0732,  0.0188, -0.0666]]],\n",
      "\n",
      "\n",
      "        [[[-0.0290, -0.0331, -0.0362, -0.0128, -0.1624],\n",
      "          [ 0.0264,  0.0704,  0.0559,  0.0057, -0.1444],\n",
      "          [ 0.0334, -0.0197,  0.0786,  0.1296, -0.0665],\n",
      "          [-0.1325, -0.0002, -0.0102,  0.0673,  0.1488],\n",
      "          [ 0.0281,  0.0752,  0.1247,  0.0654,  0.0795]],\n",
      "\n",
      "         [[ 0.0432,  0.0453, -0.0163, -0.0221, -0.0871],\n",
      "          [ 0.0297,  0.0078, -0.0213, -0.0102,  0.0096],\n",
      "          [-0.0610,  0.0428,  0.1683,  0.1447,  0.1145],\n",
      "          [ 0.0129,  0.1065,  0.1422,  0.0659,  0.0251],\n",
      "          [-0.0014,  0.0767,  0.0355,  0.0775,  0.0778]],\n",
      "\n",
      "         [[-0.0408,  0.0344,  0.0030, -0.0213, -0.0086],\n",
      "          [ 0.0332,  0.0192,  0.0254,  0.0032,  0.0026],\n",
      "          [-0.0381, -0.0148,  0.0117,  0.0037,  0.0669],\n",
      "          [ 0.0096, -0.0044,  0.0353, -0.0138,  0.0783],\n",
      "          [ 0.0304,  0.0076,  0.0405,  0.0741,  0.0048]],\n",
      "\n",
      "         [[-0.0272,  0.0014, -0.0568,  0.0614,  0.0953],\n",
      "          [ 0.0689, -0.0018,  0.0250,  0.0122,  0.0488],\n",
      "          [ 0.0131, -0.0347,  0.0192,  0.0197, -0.0680],\n",
      "          [ 0.0553, -0.0440, -0.0922, -0.0444,  0.0591],\n",
      "          [ 0.0409, -0.0933,  0.0049, -0.0250,  0.0385]],\n",
      "\n",
      "         [[ 0.0040,  0.0977,  0.0278,  0.0440, -0.1256],\n",
      "          [ 0.0426,  0.0925,  0.1221,  0.1534, -0.0139],\n",
      "          [-0.0277,  0.0244, -0.0303,  0.1574,  0.0935],\n",
      "          [-0.0314,  0.0749,  0.0602,  0.0665,  0.0982],\n",
      "          [ 0.0176,  0.0285,  0.0090,  0.0930, -0.0757]],\n",
      "\n",
      "         [[-0.0138,  0.1097,  0.0643,  0.1291,  0.1020],\n",
      "          [ 0.0214,  0.0248, -0.0334,  0.1013,  0.0531],\n",
      "          [-0.0008, -0.0636,  0.0248, -0.0394, -0.0282],\n",
      "          [ 0.1024,  0.0172,  0.0456, -0.0545,  0.0182],\n",
      "          [-0.0197,  0.1342,  0.0421,  0.0906,  0.0427]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0875,  0.0322,  0.0375,  0.0408,  0.0054],\n",
      "          [-0.0460, -0.0633, -0.0649,  0.0760, -0.0567],\n",
      "          [ 0.0322, -0.0105, -0.0606, -0.0797, -0.0679],\n",
      "          [-0.0232, -0.0553, -0.0724,  0.0120, -0.0809],\n",
      "          [ 0.0408, -0.0291, -0.0568, -0.0558, -0.0341]],\n",
      "\n",
      "         [[-0.0568, -0.0631,  0.0572, -0.0491, -0.0536],\n",
      "          [-0.0138,  0.0440,  0.0787,  0.0738,  0.0220],\n",
      "          [-0.0163,  0.0168, -0.0073,  0.0200, -0.0652],\n",
      "          [ 0.0009,  0.0010, -0.0487, -0.0715,  0.0072],\n",
      "          [-0.0719, -0.0316, -0.0134, -0.0032,  0.0724]],\n",
      "\n",
      "         [[ 0.0582, -0.0085,  0.0132, -0.0703,  0.0159],\n",
      "          [ 0.0671, -0.0448,  0.0393, -0.0356,  0.0394],\n",
      "          [ 0.0450,  0.0304, -0.0662,  0.0135,  0.0431],\n",
      "          [-0.0309,  0.0268, -0.0411, -0.0587,  0.0662],\n",
      "          [ 0.0126,  0.0711, -0.0226, -0.0170,  0.0568]],\n",
      "\n",
      "         [[ 0.0282, -0.0763, -0.0282, -0.0218, -0.0370],\n",
      "          [ 0.0586, -0.0726, -0.0211, -0.0571, -0.0420],\n",
      "          [ 0.0335,  0.0127,  0.0681,  0.0412,  0.0192],\n",
      "          [-0.0766, -0.0016, -0.0073,  0.0633, -0.0200],\n",
      "          [-0.0027, -0.0093,  0.0077, -0.0436,  0.0106]],\n",
      "\n",
      "         [[-0.0392,  0.0598, -0.0669,  0.0659, -0.0636],\n",
      "          [-0.0772, -0.0788, -0.0499, -0.0290,  0.0244],\n",
      "          [-0.0204, -0.0283,  0.0083, -0.0568,  0.0490],\n",
      "          [ 0.0234, -0.0123, -0.0521,  0.0399, -0.0175],\n",
      "          [ 0.0072, -0.0435, -0.0295, -0.0564, -0.0306]],\n",
      "\n",
      "         [[ 0.0560, -0.0579, -0.0484,  0.0134,  0.0548],\n",
      "          [-0.0322,  0.0032,  0.0593, -0.0421, -0.0552],\n",
      "          [ 0.0751,  0.0288, -0.0811, -0.0192, -0.0289],\n",
      "          [-0.0103,  0.0337, -0.0256, -0.0466,  0.0394],\n",
      "          [ 0.0175,  0.0412, -0.0659, -0.0206,  0.0141]]],\n",
      "\n",
      "\n",
      "        [[[-0.0340,  0.0957,  0.0862, -0.0030,  0.0326],\n",
      "          [ 0.0625,  0.1338,  0.0669, -0.0977,  0.0272],\n",
      "          [ 0.1258,  0.2758,  0.0864, -0.1109, -0.1041],\n",
      "          [ 0.1510,  0.1942,  0.0006, -0.1443, -0.1476],\n",
      "          [ 0.1227,  0.0747, -0.0599, -0.0265, -0.0703]],\n",
      "\n",
      "         [[ 0.0696,  0.0604,  0.0966,  0.0341, -0.0003],\n",
      "          [ 0.2600,  0.1970,  0.0654, -0.0413,  0.0700],\n",
      "          [ 0.2760,  0.1238,  0.0613,  0.0552, -0.0365],\n",
      "          [ 0.2264,  0.0426,  0.0530, -0.0057,  0.0397],\n",
      "          [ 0.0955,  0.0771,  0.0420, -0.0585, -0.0408]],\n",
      "\n",
      "         [[-0.0805, -0.0571,  0.0686,  0.0679,  0.0019],\n",
      "          [ 0.0002, -0.0732,  0.0858,  0.0114, -0.0765],\n",
      "          [-0.0982,  0.0699,  0.1299,  0.0603, -0.0301],\n",
      "          [-0.0205,  0.0617,  0.0674,  0.0328,  0.0286],\n",
      "          [-0.0963,  0.0384,  0.1049,  0.1011,  0.0627]],\n",
      "\n",
      "         [[ 0.0357,  0.0340,  0.0522,  0.0495,  0.0708],\n",
      "          [-0.0845, -0.0224, -0.0304, -0.0551, -0.0190],\n",
      "          [-0.0668,  0.0409, -0.0619, -0.0562,  0.0009],\n",
      "          [ 0.0180, -0.0264,  0.0483,  0.0653,  0.0173],\n",
      "          [ 0.0295,  0.0553,  0.0585, -0.0805,  0.0243]],\n",
      "\n",
      "         [[ 0.1076, -0.0023, -0.0163, -0.0140,  0.0564],\n",
      "          [ 0.0750,  0.0792, -0.0273,  0.0257, -0.0842],\n",
      "          [ 0.0222,  0.0533, -0.0139, -0.0419, -0.0244],\n",
      "          [ 0.0319,  0.0712,  0.0382,  0.0173,  0.0096],\n",
      "          [-0.0934,  0.0405,  0.1524,  0.0470,  0.0904]],\n",
      "\n",
      "         [[-0.0850,  0.0575,  0.0297,  0.0397,  0.0481],\n",
      "          [-0.0801, -0.0908, -0.0910, -0.0494,  0.0574],\n",
      "          [ 0.1137, -0.0567, -0.1489, -0.0140,  0.0657],\n",
      "          [ 0.0604, -0.0574, -0.0979,  0.0109,  0.0994],\n",
      "          [ 0.0521, -0.0905,  0.0108,  0.0659,  0.0968]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1651,  0.1899,  0.1213,  0.0844,  0.0381],\n",
      "          [ 0.0872,  0.0726,  0.1388,  0.1072,  0.0381],\n",
      "          [-0.0822, -0.0235, -0.0253,  0.0575,  0.0126],\n",
      "          [-0.1143, -0.0686,  0.0064,  0.0676,  0.0519],\n",
      "          [-0.0414, -0.0143, -0.0119,  0.0260,  0.0315]],\n",
      "\n",
      "         [[-0.0832, -0.0186,  0.0401, -0.0030,  0.0215],\n",
      "          [-0.0418,  0.0453,  0.0292,  0.0065,  0.0488],\n",
      "          [ 0.0127, -0.1047,  0.0074,  0.0770,  0.0699],\n",
      "          [-0.1040,  0.0111, -0.0547,  0.0259,  0.0403],\n",
      "          [-0.0534, -0.0387, -0.0023,  0.0301, -0.0905]],\n",
      "\n",
      "         [[ 0.0518,  0.1405,  0.1145,  0.0954, -0.0037],\n",
      "          [-0.0601,  0.0425, -0.0251,  0.0921, -0.0411],\n",
      "          [-0.0104, -0.0991, -0.0232, -0.0040,  0.0175],\n",
      "          [ 0.0217, -0.0569, -0.0210, -0.0877,  0.0530],\n",
      "          [ 0.0366, -0.0513,  0.0025, -0.0891,  0.0799]],\n",
      "\n",
      "         [[ 0.0528,  0.0358, -0.0843,  0.0293,  0.0443],\n",
      "          [ 0.0218,  0.0180, -0.0699, -0.0587,  0.0115],\n",
      "          [ 0.0040,  0.0050,  0.0047,  0.0408,  0.0669],\n",
      "          [ 0.0741, -0.0620,  0.0226,  0.0472,  0.0682],\n",
      "          [ 0.0717,  0.0853, -0.0000, -0.0112, -0.0270]],\n",
      "\n",
      "         [[ 0.1038,  0.1426,  0.0998,  0.0320,  0.1111],\n",
      "          [-0.1177, -0.0672,  0.0677,  0.1034, -0.0451],\n",
      "          [-0.0871, -0.1239, -0.0099, -0.0290, -0.0613],\n",
      "          [-0.0878, -0.0596, -0.0144, -0.0210,  0.0641],\n",
      "          [-0.0289,  0.0519, -0.0234,  0.0174,  0.0056]],\n",
      "\n",
      "         [[-0.0465,  0.0461,  0.0285,  0.0367,  0.0337],\n",
      "          [ 0.0520, -0.0826, -0.0852, -0.0947, -0.1000],\n",
      "          [ 0.0594,  0.0626,  0.0371,  0.0097, -0.0623],\n",
      "          [ 0.0788, -0.0128,  0.0158, -0.0668, -0.0158],\n",
      "          [-0.0014,  0.0584, -0.0293, -0.0480, -0.0613]]]])\n",
      "conv2.bias \t torch.Size([16])\n",
      "conv2.bias \t tensor([ 0.0730,  0.0296,  0.0032,  0.0657,  0.0553,  0.0152, -0.0441, -0.0667,\n",
      "         0.0277,  0.0222, -0.0358,  0.0246,  0.0430, -0.0688, -0.0241,  0.0027])\n",
      "fc1.weight \t torch.Size([300, 256])\n",
      "fc1.weight \t tensor([[ 0.0272,  0.0675,  0.0587,  ...,  0.0256, -0.0110, -0.0366],\n",
      "        [ 0.0592,  0.0532,  0.0201,  ..., -0.0201, -0.0062,  0.0536],\n",
      "        [-0.0039, -0.0355, -0.0470,  ...,  0.0263, -0.0019, -0.0098],\n",
      "        ...,\n",
      "        [ 0.0400,  0.0265, -0.0372,  ..., -0.0495,  0.0229,  0.0028],\n",
      "        [-0.0405,  0.0220, -0.0051,  ...,  0.0582, -0.0126, -0.0565],\n",
      "        [ 0.0613,  0.0368, -0.0311,  ..., -0.0378, -0.0014,  0.0345]])\n",
      "fc1.bias \t torch.Size([300])\n",
      "fc1.bias \t tensor([ 0.0125,  0.0496,  0.0088,  0.0085,  0.0095, -0.0318, -0.0080,  0.0076,\n",
      "         0.0534, -0.0552, -0.0182, -0.0311, -0.0108, -0.0078, -0.0341,  0.0239,\n",
      "        -0.0408, -0.0497, -0.0399, -0.0287,  0.0010, -0.0028,  0.0587,  0.0291,\n",
      "        -0.0397,  0.0408, -0.0342,  0.0057,  0.0011,  0.0218, -0.0139,  0.0099,\n",
      "        -0.0637, -0.0040,  0.0283, -0.0100, -0.0033,  0.0194,  0.0250,  0.0024,\n",
      "        -0.0618,  0.0368, -0.0075, -0.0286, -0.0415,  0.0529,  0.0308, -0.0437,\n",
      "         0.0435,  0.0390, -0.0456, -0.0025,  0.0445, -0.0515,  0.0301, -0.0621,\n",
      "        -0.0068,  0.0022, -0.0306,  0.0367, -0.0544, -0.0037, -0.0045,  0.0001,\n",
      "         0.0466,  0.0304,  0.0454,  0.0361,  0.0541, -0.0258, -0.0537, -0.0621,\n",
      "        -0.0620,  0.0021,  0.0354,  0.0299,  0.0376,  0.0373, -0.0519,  0.0416,\n",
      "         0.0261, -0.0177, -0.0317,  0.0305, -0.0425,  0.0313,  0.0406,  0.0041,\n",
      "         0.0194,  0.0046,  0.0000, -0.0381,  0.0463,  0.0631,  0.0508, -0.0166,\n",
      "        -0.0199, -0.0257, -0.0614, -0.0028,  0.0009, -0.0030, -0.0501, -0.0544,\n",
      "         0.0413, -0.0580,  0.0460,  0.0103,  0.0018,  0.0094,  0.0230,  0.0387,\n",
      "        -0.0001,  0.0430, -0.0575,  0.0499, -0.0169,  0.0482,  0.0148,  0.0434,\n",
      "         0.0406, -0.0329, -0.0347, -0.0067,  0.0056,  0.0384,  0.0232,  0.0367,\n",
      "        -0.0032,  0.0292, -0.0203, -0.0486,  0.0126, -0.0531,  0.0207,  0.0398,\n",
      "         0.0525, -0.0629,  0.0590, -0.0428, -0.0445, -0.0290, -0.0070, -0.0509,\n",
      "         0.0348,  0.0296, -0.0262, -0.0463,  0.0530, -0.0203,  0.0406, -0.0518,\n",
      "         0.0414,  0.0028,  0.0606,  0.0647, -0.0044,  0.0148, -0.0470,  0.0146,\n",
      "        -0.0530, -0.0190,  0.0125,  0.0080, -0.0501,  0.0331, -0.0305, -0.0425,\n",
      "         0.0532, -0.0100,  0.0302, -0.0257,  0.0368,  0.0359,  0.0030, -0.0122,\n",
      "        -0.0206, -0.0331,  0.0122, -0.0050,  0.0362, -0.0105,  0.0027, -0.0145,\n",
      "        -0.0539,  0.0082,  0.0559, -0.0274, -0.0482, -0.0504, -0.0238,  0.0578,\n",
      "         0.0111, -0.0489,  0.0005,  0.0606, -0.0305,  0.0339,  0.0619,  0.0450,\n",
      "        -0.0125,  0.0277, -0.0592, -0.0471, -0.0499, -0.0444, -0.0058,  0.0355,\n",
      "         0.0439, -0.0299, -0.0286, -0.0260, -0.0086,  0.0275,  0.0235,  0.0480,\n",
      "         0.0576, -0.0442, -0.0399,  0.0315,  0.0131, -0.0080,  0.0349,  0.0340,\n",
      "        -0.0147, -0.0120, -0.0187,  0.0264,  0.0293,  0.0585,  0.0324, -0.0166,\n",
      "        -0.0555,  0.0493, -0.0615, -0.0557,  0.0566, -0.0102,  0.0540, -0.0159,\n",
      "        -0.0254, -0.0540, -0.0359, -0.0339,  0.0491, -0.0252,  0.0568,  0.0199,\n",
      "        -0.0021, -0.0235, -0.0565,  0.0607,  0.0233, -0.0354,  0.0298,  0.0329,\n",
      "         0.0625, -0.0587,  0.0386, -0.0303,  0.0186, -0.0189,  0.0408, -0.0094,\n",
      "         0.0109, -0.0002, -0.0109, -0.0081,  0.0345, -0.0408, -0.0037, -0.0351,\n",
      "         0.0441,  0.0274, -0.0352,  0.0627, -0.0417,  0.0531, -0.0357,  0.0050,\n",
      "         0.0328, -0.0356,  0.0408, -0.0267,  0.0032, -0.0200,  0.0475, -0.0275,\n",
      "        -0.0526,  0.0087,  0.0170,  0.0063,  0.0208, -0.0253, -0.0119,  0.0515,\n",
      "        -0.0609, -0.0366,  0.0094,  0.0507])\n",
      "fc2.weight \t torch.Size([100, 300])\n",
      "fc2.weight \t tensor([[ 0.0402, -0.0434,  0.0285,  ..., -0.0308, -0.0236,  0.0146],\n",
      "        [ 0.0027,  0.0438, -0.0360,  ...,  0.0140,  0.0560,  0.0263],\n",
      "        [ 0.0155, -0.0348,  0.0268,  ...,  0.0200,  0.0367,  0.0531],\n",
      "        ...,\n",
      "        [ 0.0570, -0.0697,  0.0352,  ..., -0.0380, -0.0513, -0.0107],\n",
      "        [-0.0099,  0.0150,  0.0478,  ...,  0.0631, -0.0225,  0.0330],\n",
      "        [-0.0361,  0.0464, -0.0538,  ...,  0.0255, -0.0425, -0.0736]])\n",
      "fc2.bias \t torch.Size([100])\n",
      "fc2.bias \t tensor([ 0.0397, -0.0087, -0.0203,  0.0181,  0.0399, -0.0314, -0.0457,  0.0263,\n",
      "        -0.0335,  0.0092, -0.0015, -0.0373,  0.0526,  0.0600,  0.0099, -0.0135,\n",
      "         0.0540,  0.0312,  0.0291,  0.0140,  0.0042,  0.0081, -0.0266,  0.0049,\n",
      "         0.0078,  0.0362, -0.0094,  0.0693,  0.0406,  0.0248,  0.0119, -0.0411,\n",
      "         0.0599, -0.0495, -0.0417, -0.0585, -0.0123,  0.0157, -0.0193, -0.0215,\n",
      "         0.0462, -0.0107, -0.0284,  0.0102, -0.0230,  0.0080, -0.0122, -0.0338,\n",
      "         0.0525, -0.0359,  0.0041,  0.0639,  0.0477,  0.0078,  0.0393,  0.0211,\n",
      "        -0.0103, -0.0084, -0.0399, -0.0345, -0.0042, -0.0272,  0.0004,  0.0318,\n",
      "        -0.0283,  0.0067, -0.0566,  0.0388,  0.0067,  0.0128, -0.0366, -0.0135,\n",
      "        -0.0255, -0.0400,  0.0588, -0.0205,  0.0412,  0.0009,  0.0443,  0.0374,\n",
      "         0.0142,  0.0051,  0.0115,  0.0211,  0.0548,  0.0299,  0.0294, -0.0427,\n",
      "        -0.0211, -0.0392,  0.0204,  0.0366, -0.0392, -0.0465, -0.0501, -0.0336,\n",
      "        -0.0278,  0.0443,  0.0489, -0.0206])\n",
      "fc3.weight \t torch.Size([10, 100])\n",
      "fc3.weight \t tensor([[-0.0799, -0.0514,  0.0154,  0.0339, -0.0871, -0.0275,  0.0830, -0.0554,\n",
      "         -0.0946, -0.0866, -0.1241,  0.0442, -0.0847,  0.1099, -0.0807, -0.0870,\n",
      "         -0.0052,  0.0141, -0.1187,  0.0135, -0.0574,  0.0641,  0.0971,  0.1102,\n",
      "         -0.0481, -0.1465, -0.0263, -0.1137, -0.0913,  0.1041,  0.0754, -0.0701,\n",
      "         -0.0155,  0.1341, -0.0931, -0.0810,  0.0836,  0.0484,  0.1427, -0.1458,\n",
      "         -0.1428,  0.0642,  0.0834, -0.0122,  0.0128, -0.0866,  0.1009, -0.0585,\n",
      "          0.1132, -0.0641,  0.0977,  0.0277,  0.0624, -0.0949, -0.0213,  0.1714,\n",
      "         -0.1392, -0.0815, -0.0149,  0.1095, -0.0326, -0.0129,  0.1646,  0.0889,\n",
      "         -0.1588, -0.0397, -0.0864,  0.0607,  0.0431,  0.0588, -0.0666,  0.0588,\n",
      "          0.0749,  0.0891, -0.0775,  0.0067, -0.0723,  0.0007, -0.1620, -0.0965,\n",
      "         -0.1363,  0.0115,  0.0796,  0.0139,  0.0489, -0.0417, -0.0408,  0.1485,\n",
      "          0.0496,  0.1629, -0.0059, -0.0451, -0.0528,  0.1137, -0.0703,  0.1330,\n",
      "         -0.0167, -0.0833, -0.0043,  0.0967],\n",
      "        [ 0.0605, -0.0714, -0.1559, -0.0261, -0.0907, -0.0269,  0.0549, -0.1048,\n",
      "          0.1263, -0.1483,  0.1830, -0.1227,  0.1579,  0.0976, -0.0630, -0.0642,\n",
      "          0.0642,  0.0171,  0.0748, -0.0418, -0.0341,  0.1174,  0.1188, -0.1357,\n",
      "         -0.0569,  0.1670,  0.1514,  0.1882, -0.0166, -0.0848, -0.0153,  0.0541,\n",
      "          0.1883, -0.0972, -0.0972, -0.0510, -0.1072, -0.0235, -0.0642,  0.1352,\n",
      "          0.0150, -0.0173, -0.1752,  0.1126, -0.0674,  0.0020,  0.0317, -0.0967,\n",
      "          0.1348, -0.1442, -0.0774, -0.1404,  0.1202, -0.0748, -0.1379,  0.0576,\n",
      "          0.1114, -0.0876,  0.1180, -0.1181,  0.1069,  0.1197,  0.1634, -0.0131,\n",
      "          0.1384, -0.0552,  0.0004, -0.0252, -0.0005, -0.0646, -0.0370, -0.0633,\n",
      "         -0.0284,  0.0869, -0.1731,  0.1347, -0.1184, -0.1579, -0.0766,  0.0333,\n",
      "          0.0633, -0.0766, -0.0020,  0.0931, -0.0060, -0.0381,  0.0882,  0.0496,\n",
      "         -0.0383, -0.0410,  0.0548, -0.0701, -0.0373, -0.1803,  0.1029, -0.0843,\n",
      "         -0.0158, -0.1036,  0.0492, -0.0733],\n",
      "        [ 0.1163,  0.0529,  0.0872, -0.0351, -0.0968,  0.1147,  0.0832, -0.0014,\n",
      "         -0.0788,  0.0679,  0.0367,  0.0653,  0.2598, -0.0424, -0.0725,  0.0351,\n",
      "          0.0587,  0.0893, -0.1037, -0.0686, -0.0598, -0.0415,  0.1333,  0.0031,\n",
      "          0.0858, -0.0589, -0.0039, -0.0715,  0.0809, -0.0254,  0.0300, -0.1061,\n",
      "          0.1893,  0.0260, -0.0539,  0.0239,  0.2075, -0.0787, -0.1141,  0.0259,\n",
      "          0.0277, -0.0784, -0.0361, -0.0954,  0.1004, -0.0387, -0.0915, -0.1756,\n",
      "          0.0812,  0.0002,  0.0163,  0.1229,  0.0020, -0.0592,  0.0071,  0.0194,\n",
      "         -0.0185, -0.1658, -0.0266, -0.0476, -0.0040, -0.1298,  0.0797, -0.0132,\n",
      "         -0.0125, -0.0713,  0.0886,  0.0654, -0.1828,  0.1266, -0.0312, -0.1565,\n",
      "         -0.0008,  0.0433, -0.0532, -0.0615,  0.0067,  0.2707, -0.1773, -0.0664,\n",
      "          0.0780,  0.1225, -0.0906, -0.0346, -0.1364, -0.1227, -0.0573,  0.0918,\n",
      "         -0.1081,  0.1082, -0.0558, -0.0893,  0.0545, -0.0031,  0.0543, -0.1526,\n",
      "         -0.1887,  0.0908, -0.0388,  0.1185],\n",
      "        [-0.1174, -0.0956, -0.0778, -0.0839, -0.1300,  0.1048, -0.0927,  0.0063,\n",
      "         -0.0726, -0.1231,  0.0053,  0.0911, -0.0725, -0.1458, -0.0792,  0.0743,\n",
      "          0.0184,  0.0899,  0.2005, -0.1634, -0.0627, -0.0126, -0.0801, -0.0196,\n",
      "         -0.1274, -0.1908, -0.0943,  0.0627, -0.0222,  0.0798,  0.0219, -0.1379,\n",
      "          0.1264,  0.0201,  0.1231, -0.0776, -0.0175,  0.0741,  0.2067,  0.1731,\n",
      "          0.1828,  0.0337, -0.0757,  0.1103,  0.0470, -0.0247,  0.0363, -0.1289,\n",
      "         -0.1138,  0.1339,  0.0701,  0.0968, -0.1750, -0.0275, -0.1629, -0.1297,\n",
      "          0.1120, -0.0651, -0.0119, -0.0819, -0.0517,  0.1247, -0.0554,  0.0212,\n",
      "         -0.1113,  0.0962, -0.1201, -0.0136,  0.1305, -0.0559, -0.1068, -0.1020,\n",
      "         -0.0739,  0.0870,  0.1114, -0.0510, -0.0069,  0.1589, -0.0137, -0.0609,\n",
      "          0.0888,  0.0635, -0.0432, -0.0050, -0.0781,  0.0995, -0.0672,  0.0887,\n",
      "         -0.0514, -0.0577, -0.1168,  0.0129, -0.0206,  0.0918,  0.0148, -0.0447,\n",
      "          0.0651,  0.0980, -0.0730,  0.1064],\n",
      "        [ 0.1344, -0.0527, -0.1721,  0.0228,  0.0103, -0.0212,  0.0978, -0.0764,\n",
      "         -0.0590,  0.0773,  0.0813,  0.1136,  0.0045, -0.0662,  0.0648, -0.1574,\n",
      "          0.0122, -0.0855, -0.0298, -0.1251,  0.0770,  0.1594,  0.1165, -0.0861,\n",
      "         -0.1141, -0.0640, -0.1431, -0.0167,  0.0222, -0.0586, -0.1808,  0.0198,\n",
      "         -0.1278,  0.0701, -0.1002,  0.0631, -0.0676, -0.0541,  0.0505, -0.0883,\n",
      "         -0.0518,  0.0285,  0.0013, -0.1970,  0.0006,  0.0546, -0.0142,  0.0711,\n",
      "         -0.0467, -0.0935, -0.0555, -0.0608,  0.0216,  0.0222,  0.0968, -0.0574,\n",
      "          0.0568,  0.0914,  0.1699,  0.1728,  0.2329, -0.0513,  0.0553,  0.0158,\n",
      "          0.0237, -0.1188,  0.1711, -0.0002,  0.0112,  0.0978,  0.0454,  0.0862,\n",
      "          0.0530,  0.0608,  0.0068, -0.1118,  0.0083, -0.1468,  0.1673,  0.0777,\n",
      "          0.0660,  0.0521,  0.0632, -0.0286,  0.1892, -0.1432,  0.0500,  0.0170,\n",
      "          0.0163,  0.0035, -0.1290,  0.0328, -0.0114, -0.1939,  0.1007,  0.0200,\n",
      "         -0.0886, -0.0748, -0.0414, -0.0459],\n",
      "        [-0.0702,  0.0972, -0.1089, -0.0164,  0.1510,  0.1673,  0.0355, -0.0335,\n",
      "          0.0098, -0.0335, -0.0313,  0.0474, -0.2167,  0.0931,  0.0591,  0.1774,\n",
      "          0.0661, -0.1510, -0.0437,  0.0292,  0.0459,  0.0118, -0.1072,  0.0775,\n",
      "          0.1941,  0.0081, -0.0666,  0.1146,  0.0869, -0.0447,  0.0142,  0.1406,\n",
      "         -0.0295,  0.0406,  0.1028,  0.1352,  0.0855, -0.0151, -0.0241, -0.0670,\n",
      "          0.0759,  0.0260, -0.1360,  0.1547, -0.0115, -0.0346,  0.1122,  0.0071,\n",
      "         -0.1181, -0.0383, -0.0050,  0.0827,  0.0534,  0.0518, -0.1492,  0.0719,\n",
      "         -0.0114,  0.1788, -0.0322,  0.0634, -0.1965,  0.0355, -0.1877,  0.0430,\n",
      "         -0.0153,  0.1204, -0.0848, -0.0072, -0.0121,  0.0730, -0.0186,  0.0754,\n",
      "          0.0164,  0.0924,  0.1594, -0.0360,  0.0770, -0.0528,  0.0936, -0.0763,\n",
      "         -0.0707, -0.0935, -0.0783, -0.0139, -0.0352,  0.0623, -0.0253, -0.1390,\n",
      "          0.0381, -0.1633,  0.1316, -0.1226, -0.0330,  0.1635, -0.1238, -0.0575,\n",
      "          0.2134, -0.1288, -0.0973, -0.1462],\n",
      "        [-0.1267,  0.0608,  0.0945, -0.0855,  0.0137, -0.1502, -0.0231, -0.0381,\n",
      "          0.0615,  0.1791,  0.0682, -0.0547, -0.1165,  0.0160, -0.0677,  0.1215,\n",
      "          0.1270,  0.0552,  0.0252,  0.0310, -0.0521,  0.0416, -0.0192, -0.0318,\n",
      "          0.1169, -0.0378, -0.0670, -0.1821,  0.0983, -0.0484, -0.0966,  0.0173,\n",
      "         -0.1199, -0.0362, -0.0371, -0.0377, -0.0871, -0.0873, -0.0467, -0.1680,\n",
      "         -0.0357,  0.0793, -0.1178, -0.0236,  0.0737, -0.0153, -0.0381, -0.0225,\n",
      "          0.0352, -0.2038,  0.0576,  0.0369, -0.0268,  0.0086,  0.0528,  0.2330,\n",
      "         -0.0982,  0.0023, -0.0252,  0.0119, -0.1204, -0.0712, -0.1209,  0.0804,\n",
      "          0.0809,  0.0293,  0.0905, -0.0259, -0.0375, -0.0021,  0.1119,  0.0360,\n",
      "         -0.0401,  0.0578, -0.1174, -0.0666, -0.1238, -0.0625,  0.0602, -0.0826,\n",
      "         -0.0951, -0.1556, -0.0814,  0.0590, -0.0276,  0.1907,  0.1193,  0.1279,\n",
      "          0.0191,  0.0608, -0.0323, -0.2167, -0.0499, -0.0226, -0.0062,  0.2766,\n",
      "          0.0613,  0.0723, -0.1194,  0.0362],\n",
      "        [ 0.1253, -0.0567, -0.0470,  0.0057, -0.0911,  0.1846, -0.0189,  0.0406,\n",
      "          0.0422, -0.0780, -0.0071, -0.2156, -0.0201, -0.0144, -0.0221, -0.0102,\n",
      "         -0.0019, -0.1399,  0.1202, -0.0799, -0.0560, -0.0376,  0.0086, -0.1423,\n",
      "         -0.1784,  0.1010,  0.0851,  0.0469, -0.0839, -0.0062, -0.1095,  0.1140,\n",
      "          0.0282,  0.0649, -0.0995, -0.0791,  0.1417, -0.0001, -0.0900,  0.0731,\n",
      "         -0.1580,  0.0366,  0.1625, -0.1173,  0.0578,  0.0885,  0.0795, -0.0279,\n",
      "          0.0966,  0.2265, -0.0082, -0.0968,  0.1544, -0.0177, -0.0833, -0.0294,\n",
      "          0.0502, -0.1520,  0.1117,  0.0786, -0.0282, -0.1254, -0.0582,  0.0808,\n",
      "         -0.1701, -0.0076, -0.1343, -0.0174, -0.1298, -0.0760, -0.0093, -0.0526,\n",
      "          0.0641,  0.0873,  0.0920,  0.0170,  0.0591, -0.0053,  0.0125,  0.0697,\n",
      "          0.0351, -0.1147, -0.1147,  0.0011, -0.0274, -0.1307, -0.1444,  0.0165,\n",
      "         -0.0701,  0.1172,  0.0456,  0.0969,  0.0502,  0.1024,  0.1399, -0.1740,\n",
      "         -0.1500,  0.0137, -0.0495,  0.0711],\n",
      "        [ 0.0179,  0.0685,  0.0873,  0.0371,  0.0590,  0.0197,  0.1005,  0.0666,\n",
      "         -0.1361,  0.1357, -0.0054, -0.0601,  0.1132, -0.1546, -0.0455, -0.0954,\n",
      "         -0.0512,  0.1773, -0.1578, -0.0489, -0.0059, -0.0846, -0.0196,  0.1207,\n",
      "          0.0869, -0.0223, -0.0498, -0.0834, -0.0735,  0.0632,  0.0749,  0.0071,\n",
      "          0.0989, -0.0011, -0.0934, -0.0903, -0.0573,  0.0495,  0.0562, -0.0934,\n",
      "         -0.0274,  0.0376,  0.2146,  0.0413, -0.0074, -0.0715,  0.0373,  0.1217,\n",
      "         -0.0909,  0.1196,  0.0167,  0.0224,  0.0212, -0.0289,  0.0734, -0.1166,\n",
      "          0.0324,  0.1181, -0.1991, -0.1180,  0.0931, -0.0650, -0.0690, -0.0341,\n",
      "          0.0157,  0.1252, -0.0985,  0.0414,  0.1322, -0.1907, -0.0653, -0.0911,\n",
      "         -0.0773,  0.0222, -0.1590,  0.0777, -0.0225,  0.1439,  0.0272,  0.0664,\n",
      "         -0.0481, -0.1818,  0.0939,  0.0641, -0.1797,  0.0371,  0.1511, -0.0627,\n",
      "          0.0379, -0.0997, -0.1519,  0.0007,  0.0910, -0.0139,  0.0055, -0.0742,\n",
      "         -0.0375,  0.1489, -0.0454, -0.1793],\n",
      "        [ 0.0146, -0.0842,  0.0056,  0.0951, -0.0240,  0.0560,  0.0690,  0.0636,\n",
      "         -0.0916,  0.0020, -0.0134,  0.0796, -0.0850, -0.0028,  0.0361, -0.0669,\n",
      "         -0.3067,  0.1429, -0.0458,  0.0598,  0.0754,  0.0671, -0.0477,  0.1118,\n",
      "         -0.0051, -0.0064, -0.0240,  0.1009,  0.0136, -0.0055,  0.0861,  0.0048,\n",
      "         -0.2677, -0.1203, -0.0678, -0.0073, -0.1324,  0.0625, -0.0334,  0.0507,\n",
      "          0.0945,  0.0802, -0.1084, -0.0306, -0.0056,  0.0800, -0.1123,  0.0358,\n",
      "         -0.0649,  0.1931,  0.0560,  0.1092, -0.1128, -0.0712,  0.1549, -0.1540,\n",
      "          0.0716,  0.1764,  0.0486, -0.0538,  0.0456,  0.1606, -0.0910, -0.0560,\n",
      "          0.0678,  0.1936,  0.0395, -0.0298, -0.0671,  0.0566, -0.1658,  0.0905,\n",
      "          0.0633, -0.0620,  0.1562,  0.0469, -0.1265, -0.2520,  0.0131, -0.0754,\n",
      "         -0.2041,  0.1002,  0.0500, -0.0082,  0.1458, -0.2233, -0.0389,  0.0779,\n",
      "          0.0896,  0.1174,  0.0230,  0.1004,  0.0039,  0.0297,  0.0805, -0.0051,\n",
      "          0.0482, -0.0716,  0.0410,  0.1311]])\n",
      "fc3.bias \t torch.Size([10])\n",
      "fc3.bias \t tensor([-0.0838,  0.0204, -0.0172,  0.0138,  0.0053, -0.0699,  0.0305,  0.0152,\n",
      "        -0.0514, -0.0417])\n"
     ]
    }
   ],
   "source": [
    "for param_tensor in net.state_dict():\n",
    "    print(param_tensor, \"\\t\", net.state_dict()[param_tensor].size())\n",
    "    print(param_tensor, \"\\t\", net.state_dict()[param_tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   torch.Size([6, 1, 5, 5]) \n",
      "  Parameter containing:\n",
      "tensor([[[[-0.0192,  0.2511,  0.2183,  0.0210,  0.0190],\n",
      "          [-0.0522,  0.3645,  0.3561,  0.5513,  0.3440],\n",
      "          [ 0.0598,  0.5070,  0.6116,  0.6220,  0.2953],\n",
      "          [ 0.2985,  0.1301,  0.4567,  0.1638,  0.2149],\n",
      "          [-0.0246,  0.3206,  0.1249,  0.1288, -0.1632]]],\n",
      "\n",
      "\n",
      "        [[[-0.1775, -0.0977,  0.0400,  0.2623,  0.2931],\n",
      "          [ 0.0318, -0.1988, -0.1956,  0.1583,  0.1678],\n",
      "          [-0.2439, -0.2983, -0.0792,  0.2235,  0.3461],\n",
      "          [-0.0280, -0.2769, -0.1121,  0.0926,  0.3560],\n",
      "          [-0.1970, -0.1645,  0.1938,  0.2115,  0.1824]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1362,  0.2118, -0.2154, -0.2076, -0.2334],\n",
      "          [ 0.2467, -0.0821, -0.1670, -0.0738,  0.2066],\n",
      "          [ 0.2564,  0.1952,  0.2048,  0.3864,  0.0963],\n",
      "          [ 0.0786,  0.3546,  0.3418, -0.0168,  0.1037],\n",
      "          [ 0.0178, -0.2039, -0.1759, -0.0146, -0.0048]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0299,  0.1694, -0.0029, -0.1827, -0.0718],\n",
      "          [-0.1909, -0.1638,  0.1044, -0.2096,  0.0405],\n",
      "          [ 0.0873, -0.1777, -0.1820, -0.0258, -0.1887],\n",
      "          [ 0.0190, -0.1462, -0.0486,  0.0288, -0.2104],\n",
      "          [ 0.1727, -0.1630, -0.0454, -0.2031, -0.1915]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1378,  0.0087, -0.1978, -0.2727,  0.0345],\n",
      "          [ 0.2285, -0.0154, -0.1342, -0.2998, -0.0739],\n",
      "          [ 0.2801,  0.2191,  0.1079,  0.2947,  0.1320],\n",
      "          [ 0.3344,  0.4029,  0.3628,  0.5148,  0.0400],\n",
      "          [ 0.0682,  0.0300,  0.3382,  0.2907,  0.3091]]],\n",
      "\n",
      "\n",
      "        [[[-0.2584, -0.2308, -0.1856,  0.0330,  0.0465],\n",
      "          [-0.2978, -0.1939, -0.2057,  0.0400,  0.1692],\n",
      "          [ 0.0883, -0.1518,  0.0861, -0.1625,  0.0874],\n",
      "          [ 0.1464,  0.2543,  0.0292,  0.0581, -0.0674],\n",
      "          [ 0.3818,  0.3657,  0.2362, -0.0540,  0.1097]]]],\n",
      "       requires_grad=True) \n",
      "\n",
      "\n",
      "2   torch.Size([6]) \n",
      "  Parameter containing:\n",
      "tensor([ 0.2434, -0.0632,  0.2198,  0.1060,  0.1912,  0.0086], requires_grad=True) \n",
      "\n",
      "\n",
      "3   torch.Size([16, 6, 5, 5]) \n",
      "  Parameter containing:\n",
      "tensor([[[[-0.0109, -0.0548, -0.0268,  0.0555,  0.0529],\n",
      "          [-0.0747, -0.0093, -0.0871,  0.0756,  0.0290],\n",
      "          [ 0.0085, -0.0744, -0.1693, -0.1346, -0.1455],\n",
      "          [ 0.0382, -0.0446, -0.1455, -0.0654, -0.0830],\n",
      "          [ 0.0522,  0.1614,  0.1331,  0.1559,  0.0276]],\n",
      "\n",
      "         [[-0.0135,  0.0531,  0.0238,  0.0102,  0.0312],\n",
      "          [ 0.0628, -0.0327,  0.0206, -0.0319,  0.0428],\n",
      "          [-0.0834, -0.1235, -0.0557,  0.0262, -0.0169],\n",
      "          [ 0.0244, -0.0334,  0.0382, -0.0140,  0.0345],\n",
      "          [ 0.1239, -0.0369, -0.0981, -0.0913, -0.0969]],\n",
      "\n",
      "         [[-0.0242, -0.0831,  0.0583,  0.0632, -0.0662],\n",
      "          [-0.0261, -0.0701,  0.0334, -0.0154,  0.0068],\n",
      "          [-0.0244,  0.0824, -0.1057, -0.1036,  0.0335],\n",
      "          [-0.0140,  0.1386,  0.0705,  0.0171, -0.0072],\n",
      "          [ 0.0018,  0.1739,  0.1223,  0.0542,  0.0006]],\n",
      "\n",
      "         [[ 0.0685,  0.0419, -0.0685, -0.0128, -0.0514],\n",
      "          [ 0.0531,  0.0907, -0.0022,  0.0279,  0.0706],\n",
      "          [ 0.0644,  0.0581,  0.0447,  0.0862, -0.0299],\n",
      "          [-0.0563, -0.0664,  0.0204, -0.0461, -0.0049],\n",
      "          [-0.0201, -0.0669, -0.0425, -0.0638,  0.0590]],\n",
      "\n",
      "         [[-0.0472,  0.0201, -0.0225, -0.0141, -0.0058],\n",
      "          [ 0.0624,  0.0067,  0.0042,  0.0046,  0.0419],\n",
      "          [ 0.0394,  0.0676, -0.0732, -0.1638, -0.0343],\n",
      "          [ 0.1362,  0.1999,  0.0978,  0.1239,  0.0379],\n",
      "          [ 0.0652,  0.1395,  0.1929,  0.1191,  0.0623]],\n",
      "\n",
      "         [[ 0.0314, -0.0123, -0.0633,  0.0803,  0.0407],\n",
      "          [-0.0420,  0.0859,  0.0217, -0.0667,  0.0375],\n",
      "          [ 0.0298,  0.0806,  0.0096,  0.0557, -0.0537],\n",
      "          [ 0.0555, -0.0591,  0.0920,  0.1185,  0.0150],\n",
      "          [-0.0733, -0.1120, -0.0059,  0.1112,  0.0869]]],\n",
      "\n",
      "\n",
      "        [[[-0.0222, -0.0632,  0.0230,  0.0518,  0.0471],\n",
      "          [-0.0131, -0.0666, -0.0177, -0.0039,  0.0601],\n",
      "          [ 0.0307,  0.0119,  0.1052, -0.0188,  0.0316],\n",
      "          [-0.0572, -0.0849, -0.0043,  0.1368,  0.0699],\n",
      "          [-0.0658, -0.1288, -0.1282, -0.0940, -0.0316]],\n",
      "\n",
      "         [[ 0.0440,  0.0498,  0.0480,  0.0980,  0.0044],\n",
      "          [-0.0486,  0.0267,  0.0349, -0.0436,  0.0280],\n",
      "          [-0.0089,  0.0524,  0.0789, -0.0944, -0.0586],\n",
      "          [-0.0659,  0.0035,  0.0432, -0.0714, -0.0228],\n",
      "          [ 0.0241, -0.0759, -0.0205,  0.0458, -0.0653]],\n",
      "\n",
      "         [[-0.0281,  0.0291, -0.0404,  0.0430, -0.0491],\n",
      "          [ 0.0727, -0.0770, -0.0016,  0.0005,  0.0026],\n",
      "          [-0.0638,  0.0402,  0.0268,  0.0278, -0.0408],\n",
      "          [-0.0593, -0.0857, -0.0497,  0.1150,  0.1128],\n",
      "          [-0.0520, -0.0732, -0.0377, -0.0443, -0.0022]],\n",
      "\n",
      "         [[-0.0036, -0.0737,  0.0009,  0.0342,  0.0625],\n",
      "          [ 0.0713, -0.0301, -0.0545, -0.0360, -0.0155],\n",
      "          [ 0.0323,  0.0786, -0.0489, -0.0150, -0.0732],\n",
      "          [-0.0087,  0.0101,  0.0736, -0.0299,  0.0564],\n",
      "          [ 0.0291, -0.0514,  0.0165, -0.0648, -0.0488]],\n",
      "\n",
      "         [[-0.0781,  0.0070, -0.0439,  0.0522,  0.0101],\n",
      "          [-0.0655, -0.0328,  0.0275, -0.0029, -0.0499],\n",
      "          [-0.0462,  0.0460,  0.0361,  0.1371,  0.0840],\n",
      "          [ 0.0280, -0.0768,  0.0399,  0.0632,  0.1553],\n",
      "          [ 0.0167,  0.0032, -0.0908, -0.1111, -0.0763]],\n",
      "\n",
      "         [[ 0.0044,  0.0608, -0.0532, -0.0601,  0.0587],\n",
      "          [-0.0058, -0.0142, -0.0047, -0.0417, -0.0031],\n",
      "          [-0.0824, -0.0439, -0.0758, -0.0655, -0.0323],\n",
      "          [ 0.0141, -0.0282,  0.0304,  0.0188, -0.0538],\n",
      "          [-0.0402,  0.0069,  0.0732,  0.0188, -0.0666]]],\n",
      "\n",
      "\n",
      "        [[[-0.0290, -0.0331, -0.0362, -0.0128, -0.1624],\n",
      "          [ 0.0264,  0.0704,  0.0559,  0.0057, -0.1444],\n",
      "          [ 0.0334, -0.0197,  0.0786,  0.1296, -0.0665],\n",
      "          [-0.1325, -0.0002, -0.0102,  0.0673,  0.1488],\n",
      "          [ 0.0281,  0.0752,  0.1247,  0.0654,  0.0795]],\n",
      "\n",
      "         [[ 0.0432,  0.0453, -0.0163, -0.0221, -0.0871],\n",
      "          [ 0.0297,  0.0078, -0.0213, -0.0102,  0.0096],\n",
      "          [-0.0610,  0.0428,  0.1683,  0.1447,  0.1145],\n",
      "          [ 0.0129,  0.1065,  0.1422,  0.0659,  0.0251],\n",
      "          [-0.0014,  0.0767,  0.0355,  0.0775,  0.0778]],\n",
      "\n",
      "         [[-0.0408,  0.0344,  0.0030, -0.0213, -0.0086],\n",
      "          [ 0.0332,  0.0192,  0.0254,  0.0032,  0.0026],\n",
      "          [-0.0381, -0.0148,  0.0117,  0.0037,  0.0669],\n",
      "          [ 0.0096, -0.0044,  0.0353, -0.0138,  0.0783],\n",
      "          [ 0.0304,  0.0076,  0.0405,  0.0741,  0.0048]],\n",
      "\n",
      "         [[-0.0272,  0.0014, -0.0568,  0.0614,  0.0953],\n",
      "          [ 0.0689, -0.0018,  0.0250,  0.0122,  0.0488],\n",
      "          [ 0.0131, -0.0347,  0.0192,  0.0197, -0.0680],\n",
      "          [ 0.0553, -0.0440, -0.0922, -0.0444,  0.0591],\n",
      "          [ 0.0409, -0.0933,  0.0049, -0.0250,  0.0385]],\n",
      "\n",
      "         [[ 0.0040,  0.0977,  0.0278,  0.0440, -0.1256],\n",
      "          [ 0.0426,  0.0925,  0.1221,  0.1534, -0.0139],\n",
      "          [-0.0277,  0.0244, -0.0303,  0.1574,  0.0935],\n",
      "          [-0.0314,  0.0749,  0.0602,  0.0665,  0.0982],\n",
      "          [ 0.0176,  0.0285,  0.0090,  0.0930, -0.0757]],\n",
      "\n",
      "         [[-0.0138,  0.1097,  0.0643,  0.1291,  0.1020],\n",
      "          [ 0.0214,  0.0248, -0.0334,  0.1013,  0.0531],\n",
      "          [-0.0008, -0.0636,  0.0248, -0.0394, -0.0282],\n",
      "          [ 0.1024,  0.0172,  0.0456, -0.0545,  0.0182],\n",
      "          [-0.0197,  0.1342,  0.0421,  0.0906,  0.0427]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0875,  0.0322,  0.0375,  0.0408,  0.0054],\n",
      "          [-0.0460, -0.0633, -0.0649,  0.0760, -0.0567],\n",
      "          [ 0.0322, -0.0105, -0.0606, -0.0797, -0.0679],\n",
      "          [-0.0232, -0.0553, -0.0724,  0.0120, -0.0809],\n",
      "          [ 0.0408, -0.0291, -0.0568, -0.0558, -0.0341]],\n",
      "\n",
      "         [[-0.0568, -0.0631,  0.0572, -0.0491, -0.0536],\n",
      "          [-0.0138,  0.0440,  0.0787,  0.0738,  0.0220],\n",
      "          [-0.0163,  0.0168, -0.0073,  0.0200, -0.0652],\n",
      "          [ 0.0009,  0.0010, -0.0487, -0.0715,  0.0072],\n",
      "          [-0.0719, -0.0316, -0.0134, -0.0032,  0.0724]],\n",
      "\n",
      "         [[ 0.0582, -0.0085,  0.0132, -0.0703,  0.0159],\n",
      "          [ 0.0671, -0.0448,  0.0393, -0.0356,  0.0394],\n",
      "          [ 0.0450,  0.0304, -0.0662,  0.0135,  0.0431],\n",
      "          [-0.0309,  0.0268, -0.0411, -0.0587,  0.0662],\n",
      "          [ 0.0126,  0.0711, -0.0226, -0.0170,  0.0568]],\n",
      "\n",
      "         [[ 0.0282, -0.0763, -0.0282, -0.0218, -0.0370],\n",
      "          [ 0.0586, -0.0726, -0.0211, -0.0571, -0.0420],\n",
      "          [ 0.0335,  0.0127,  0.0681,  0.0412,  0.0192],\n",
      "          [-0.0766, -0.0016, -0.0073,  0.0633, -0.0200],\n",
      "          [-0.0027, -0.0093,  0.0077, -0.0436,  0.0106]],\n",
      "\n",
      "         [[-0.0392,  0.0598, -0.0669,  0.0659, -0.0636],\n",
      "          [-0.0772, -0.0788, -0.0499, -0.0290,  0.0244],\n",
      "          [-0.0204, -0.0283,  0.0083, -0.0568,  0.0490],\n",
      "          [ 0.0234, -0.0123, -0.0521,  0.0399, -0.0175],\n",
      "          [ 0.0072, -0.0435, -0.0295, -0.0564, -0.0306]],\n",
      "\n",
      "         [[ 0.0560, -0.0579, -0.0484,  0.0134,  0.0548],\n",
      "          [-0.0322,  0.0032,  0.0593, -0.0421, -0.0552],\n",
      "          [ 0.0751,  0.0288, -0.0811, -0.0192, -0.0289],\n",
      "          [-0.0103,  0.0337, -0.0256, -0.0466,  0.0394],\n",
      "          [ 0.0175,  0.0412, -0.0659, -0.0206,  0.0141]]],\n",
      "\n",
      "\n",
      "        [[[-0.0340,  0.0957,  0.0862, -0.0030,  0.0326],\n",
      "          [ 0.0625,  0.1338,  0.0669, -0.0977,  0.0272],\n",
      "          [ 0.1258,  0.2758,  0.0864, -0.1109, -0.1041],\n",
      "          [ 0.1510,  0.1942,  0.0006, -0.1443, -0.1476],\n",
      "          [ 0.1227,  0.0747, -0.0599, -0.0265, -0.0703]],\n",
      "\n",
      "         [[ 0.0696,  0.0604,  0.0966,  0.0341, -0.0003],\n",
      "          [ 0.2600,  0.1970,  0.0654, -0.0413,  0.0700],\n",
      "          [ 0.2760,  0.1238,  0.0613,  0.0552, -0.0365],\n",
      "          [ 0.2264,  0.0426,  0.0530, -0.0057,  0.0397],\n",
      "          [ 0.0955,  0.0771,  0.0420, -0.0585, -0.0408]],\n",
      "\n",
      "         [[-0.0805, -0.0571,  0.0686,  0.0679,  0.0019],\n",
      "          [ 0.0002, -0.0732,  0.0858,  0.0114, -0.0765],\n",
      "          [-0.0982,  0.0699,  0.1299,  0.0603, -0.0301],\n",
      "          [-0.0205,  0.0617,  0.0674,  0.0328,  0.0286],\n",
      "          [-0.0963,  0.0384,  0.1049,  0.1011,  0.0627]],\n",
      "\n",
      "         [[ 0.0357,  0.0340,  0.0522,  0.0495,  0.0708],\n",
      "          [-0.0845, -0.0224, -0.0304, -0.0551, -0.0190],\n",
      "          [-0.0668,  0.0409, -0.0619, -0.0562,  0.0009],\n",
      "          [ 0.0180, -0.0264,  0.0483,  0.0653,  0.0173],\n",
      "          [ 0.0295,  0.0553,  0.0585, -0.0805,  0.0243]],\n",
      "\n",
      "         [[ 0.1076, -0.0023, -0.0163, -0.0140,  0.0564],\n",
      "          [ 0.0750,  0.0792, -0.0273,  0.0257, -0.0842],\n",
      "          [ 0.0222,  0.0533, -0.0139, -0.0419, -0.0244],\n",
      "          [ 0.0319,  0.0712,  0.0382,  0.0173,  0.0096],\n",
      "          [-0.0934,  0.0405,  0.1524,  0.0470,  0.0904]],\n",
      "\n",
      "         [[-0.0850,  0.0575,  0.0297,  0.0397,  0.0481],\n",
      "          [-0.0801, -0.0908, -0.0910, -0.0494,  0.0574],\n",
      "          [ 0.1137, -0.0567, -0.1489, -0.0140,  0.0657],\n",
      "          [ 0.0604, -0.0574, -0.0979,  0.0109,  0.0994],\n",
      "          [ 0.0521, -0.0905,  0.0108,  0.0659,  0.0968]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1651,  0.1899,  0.1213,  0.0844,  0.0381],\n",
      "          [ 0.0872,  0.0726,  0.1388,  0.1072,  0.0381],\n",
      "          [-0.0822, -0.0235, -0.0253,  0.0575,  0.0126],\n",
      "          [-0.1143, -0.0686,  0.0064,  0.0676,  0.0519],\n",
      "          [-0.0414, -0.0143, -0.0119,  0.0260,  0.0315]],\n",
      "\n",
      "         [[-0.0832, -0.0186,  0.0401, -0.0030,  0.0215],\n",
      "          [-0.0418,  0.0453,  0.0292,  0.0065,  0.0488],\n",
      "          [ 0.0127, -0.1047,  0.0074,  0.0770,  0.0699],\n",
      "          [-0.1040,  0.0111, -0.0547,  0.0259,  0.0403],\n",
      "          [-0.0534, -0.0387, -0.0023,  0.0301, -0.0905]],\n",
      "\n",
      "         [[ 0.0518,  0.1405,  0.1145,  0.0954, -0.0037],\n",
      "          [-0.0601,  0.0425, -0.0251,  0.0921, -0.0411],\n",
      "          [-0.0104, -0.0991, -0.0232, -0.0040,  0.0175],\n",
      "          [ 0.0217, -0.0569, -0.0210, -0.0877,  0.0530],\n",
      "          [ 0.0366, -0.0513,  0.0025, -0.0891,  0.0799]],\n",
      "\n",
      "         [[ 0.0528,  0.0358, -0.0843,  0.0293,  0.0443],\n",
      "          [ 0.0218,  0.0180, -0.0699, -0.0587,  0.0115],\n",
      "          [ 0.0040,  0.0050,  0.0047,  0.0408,  0.0669],\n",
      "          [ 0.0741, -0.0620,  0.0226,  0.0472,  0.0682],\n",
      "          [ 0.0717,  0.0853, -0.0000, -0.0112, -0.0270]],\n",
      "\n",
      "         [[ 0.1038,  0.1426,  0.0998,  0.0320,  0.1111],\n",
      "          [-0.1177, -0.0672,  0.0677,  0.1034, -0.0451],\n",
      "          [-0.0871, -0.1239, -0.0099, -0.0290, -0.0613],\n",
      "          [-0.0878, -0.0596, -0.0144, -0.0210,  0.0641],\n",
      "          [-0.0289,  0.0519, -0.0234,  0.0174,  0.0056]],\n",
      "\n",
      "         [[-0.0465,  0.0461,  0.0285,  0.0367,  0.0337],\n",
      "          [ 0.0520, -0.0826, -0.0852, -0.0947, -0.1000],\n",
      "          [ 0.0594,  0.0626,  0.0371,  0.0097, -0.0623],\n",
      "          [ 0.0788, -0.0128,  0.0158, -0.0668, -0.0158],\n",
      "          [-0.0014,  0.0584, -0.0293, -0.0480, -0.0613]]]],\n",
      "       requires_grad=True) \n",
      "\n",
      "\n",
      "4   torch.Size([16]) \n",
      "  Parameter containing:\n",
      "tensor([ 0.0730,  0.0296,  0.0032,  0.0657,  0.0553,  0.0152, -0.0441, -0.0667,\n",
      "         0.0277,  0.0222, -0.0358,  0.0246,  0.0430, -0.0688, -0.0241,  0.0027],\n",
      "       requires_grad=True) \n",
      "\n",
      "\n",
      "5   torch.Size([300, 256]) \n",
      "  Parameter containing:\n",
      "tensor([[ 0.0272,  0.0675,  0.0587,  ...,  0.0256, -0.0110, -0.0366],\n",
      "        [ 0.0592,  0.0532,  0.0201,  ..., -0.0201, -0.0062,  0.0536],\n",
      "        [-0.0039, -0.0355, -0.0470,  ...,  0.0263, -0.0019, -0.0098],\n",
      "        ...,\n",
      "        [ 0.0400,  0.0265, -0.0372,  ..., -0.0495,  0.0229,  0.0028],\n",
      "        [-0.0405,  0.0220, -0.0051,  ...,  0.0582, -0.0126, -0.0565],\n",
      "        [ 0.0613,  0.0368, -0.0311,  ..., -0.0378, -0.0014,  0.0345]],\n",
      "       requires_grad=True) \n",
      "\n",
      "\n",
      "6   torch.Size([300]) \n",
      "  Parameter containing:\n",
      "tensor([ 0.0125,  0.0496,  0.0088,  0.0085,  0.0095, -0.0318, -0.0080,  0.0076,\n",
      "         0.0534, -0.0552, -0.0182, -0.0311, -0.0108, -0.0078, -0.0341,  0.0239,\n",
      "        -0.0408, -0.0497, -0.0399, -0.0287,  0.0010, -0.0028,  0.0587,  0.0291,\n",
      "        -0.0397,  0.0408, -0.0342,  0.0057,  0.0011,  0.0218, -0.0139,  0.0099,\n",
      "        -0.0637, -0.0040,  0.0283, -0.0100, -0.0033,  0.0194,  0.0250,  0.0024,\n",
      "        -0.0618,  0.0368, -0.0075, -0.0286, -0.0415,  0.0529,  0.0308, -0.0437,\n",
      "         0.0435,  0.0390, -0.0456, -0.0025,  0.0445, -0.0515,  0.0301, -0.0621,\n",
      "        -0.0068,  0.0022, -0.0306,  0.0367, -0.0544, -0.0037, -0.0045,  0.0001,\n",
      "         0.0466,  0.0304,  0.0454,  0.0361,  0.0541, -0.0258, -0.0537, -0.0621,\n",
      "        -0.0620,  0.0021,  0.0354,  0.0299,  0.0376,  0.0373, -0.0519,  0.0416,\n",
      "         0.0261, -0.0177, -0.0317,  0.0305, -0.0425,  0.0313,  0.0406,  0.0041,\n",
      "         0.0194,  0.0046,  0.0000, -0.0381,  0.0463,  0.0631,  0.0508, -0.0166,\n",
      "        -0.0199, -0.0257, -0.0614, -0.0028,  0.0009, -0.0030, -0.0501, -0.0544,\n",
      "         0.0413, -0.0580,  0.0460,  0.0103,  0.0018,  0.0094,  0.0230,  0.0387,\n",
      "        -0.0001,  0.0430, -0.0575,  0.0499, -0.0169,  0.0482,  0.0148,  0.0434,\n",
      "         0.0406, -0.0329, -0.0347, -0.0067,  0.0056,  0.0384,  0.0232,  0.0367,\n",
      "        -0.0032,  0.0292, -0.0203, -0.0486,  0.0126, -0.0531,  0.0207,  0.0398,\n",
      "         0.0525, -0.0629,  0.0590, -0.0428, -0.0445, -0.0290, -0.0070, -0.0509,\n",
      "         0.0348,  0.0296, -0.0262, -0.0463,  0.0530, -0.0203,  0.0406, -0.0518,\n",
      "         0.0414,  0.0028,  0.0606,  0.0647, -0.0044,  0.0148, -0.0470,  0.0146,\n",
      "        -0.0530, -0.0190,  0.0125,  0.0080, -0.0501,  0.0331, -0.0305, -0.0425,\n",
      "         0.0532, -0.0100,  0.0302, -0.0257,  0.0368,  0.0359,  0.0030, -0.0122,\n",
      "        -0.0206, -0.0331,  0.0122, -0.0050,  0.0362, -0.0105,  0.0027, -0.0145,\n",
      "        -0.0539,  0.0082,  0.0559, -0.0274, -0.0482, -0.0504, -0.0238,  0.0578,\n",
      "         0.0111, -0.0489,  0.0005,  0.0606, -0.0305,  0.0339,  0.0619,  0.0450,\n",
      "        -0.0125,  0.0277, -0.0592, -0.0471, -0.0499, -0.0444, -0.0058,  0.0355,\n",
      "         0.0439, -0.0299, -0.0286, -0.0260, -0.0086,  0.0275,  0.0235,  0.0480,\n",
      "         0.0576, -0.0442, -0.0399,  0.0315,  0.0131, -0.0080,  0.0349,  0.0340,\n",
      "        -0.0147, -0.0120, -0.0187,  0.0264,  0.0293,  0.0585,  0.0324, -0.0166,\n",
      "        -0.0555,  0.0493, -0.0615, -0.0557,  0.0566, -0.0102,  0.0540, -0.0159,\n",
      "        -0.0254, -0.0540, -0.0359, -0.0339,  0.0491, -0.0252,  0.0568,  0.0199,\n",
      "        -0.0021, -0.0235, -0.0565,  0.0607,  0.0233, -0.0354,  0.0298,  0.0329,\n",
      "         0.0625, -0.0587,  0.0386, -0.0303,  0.0186, -0.0189,  0.0408, -0.0094,\n",
      "         0.0109, -0.0002, -0.0109, -0.0081,  0.0345, -0.0408, -0.0037, -0.0351,\n",
      "         0.0441,  0.0274, -0.0352,  0.0627, -0.0417,  0.0531, -0.0357,  0.0050,\n",
      "         0.0328, -0.0356,  0.0408, -0.0267,  0.0032, -0.0200,  0.0475, -0.0275,\n",
      "        -0.0526,  0.0087,  0.0170,  0.0063,  0.0208, -0.0253, -0.0119,  0.0515,\n",
      "        -0.0609, -0.0366,  0.0094,  0.0507], requires_grad=True) \n",
      "\n",
      "\n",
      "7   torch.Size([100, 300]) \n",
      "  Parameter containing:\n",
      "tensor([[ 0.0402, -0.0434,  0.0285,  ..., -0.0308, -0.0236,  0.0146],\n",
      "        [ 0.0027,  0.0438, -0.0360,  ...,  0.0140,  0.0560,  0.0263],\n",
      "        [ 0.0155, -0.0348,  0.0268,  ...,  0.0200,  0.0367,  0.0531],\n",
      "        ...,\n",
      "        [ 0.0570, -0.0697,  0.0352,  ..., -0.0380, -0.0513, -0.0107],\n",
      "        [-0.0099,  0.0150,  0.0478,  ...,  0.0631, -0.0225,  0.0330],\n",
      "        [-0.0361,  0.0464, -0.0538,  ...,  0.0255, -0.0425, -0.0736]],\n",
      "       requires_grad=True) \n",
      "\n",
      "\n",
      "8   torch.Size([100]) \n",
      "  Parameter containing:\n",
      "tensor([ 0.0397, -0.0087, -0.0203,  0.0181,  0.0399, -0.0314, -0.0457,  0.0263,\n",
      "        -0.0335,  0.0092, -0.0015, -0.0373,  0.0526,  0.0600,  0.0099, -0.0135,\n",
      "         0.0540,  0.0312,  0.0291,  0.0140,  0.0042,  0.0081, -0.0266,  0.0049,\n",
      "         0.0078,  0.0362, -0.0094,  0.0693,  0.0406,  0.0248,  0.0119, -0.0411,\n",
      "         0.0599, -0.0495, -0.0417, -0.0585, -0.0123,  0.0157, -0.0193, -0.0215,\n",
      "         0.0462, -0.0107, -0.0284,  0.0102, -0.0230,  0.0080, -0.0122, -0.0338,\n",
      "         0.0525, -0.0359,  0.0041,  0.0639,  0.0477,  0.0078,  0.0393,  0.0211,\n",
      "        -0.0103, -0.0084, -0.0399, -0.0345, -0.0042, -0.0272,  0.0004,  0.0318,\n",
      "        -0.0283,  0.0067, -0.0566,  0.0388,  0.0067,  0.0128, -0.0366, -0.0135,\n",
      "        -0.0255, -0.0400,  0.0588, -0.0205,  0.0412,  0.0009,  0.0443,  0.0374,\n",
      "         0.0142,  0.0051,  0.0115,  0.0211,  0.0548,  0.0299,  0.0294, -0.0427,\n",
      "        -0.0211, -0.0392,  0.0204,  0.0366, -0.0392, -0.0465, -0.0501, -0.0336,\n",
      "        -0.0278,  0.0443,  0.0489, -0.0206], requires_grad=True) \n",
      "\n",
      "\n",
      "9   torch.Size([10, 100]) \n",
      "  Parameter containing:\n",
      "tensor([[-0.0799, -0.0514,  0.0154,  0.0339, -0.0871, -0.0275,  0.0830, -0.0554,\n",
      "         -0.0946, -0.0866, -0.1241,  0.0442, -0.0847,  0.1099, -0.0807, -0.0870,\n",
      "         -0.0052,  0.0141, -0.1187,  0.0135, -0.0574,  0.0641,  0.0971,  0.1102,\n",
      "         -0.0481, -0.1465, -0.0263, -0.1137, -0.0913,  0.1041,  0.0754, -0.0701,\n",
      "         -0.0155,  0.1341, -0.0931, -0.0810,  0.0836,  0.0484,  0.1427, -0.1458,\n",
      "         -0.1428,  0.0642,  0.0834, -0.0122,  0.0128, -0.0866,  0.1009, -0.0585,\n",
      "          0.1132, -0.0641,  0.0977,  0.0277,  0.0624, -0.0949, -0.0213,  0.1714,\n",
      "         -0.1392, -0.0815, -0.0149,  0.1095, -0.0326, -0.0129,  0.1646,  0.0889,\n",
      "         -0.1588, -0.0397, -0.0864,  0.0607,  0.0431,  0.0588, -0.0666,  0.0588,\n",
      "          0.0749,  0.0891, -0.0775,  0.0067, -0.0723,  0.0007, -0.1620, -0.0965,\n",
      "         -0.1363,  0.0115,  0.0796,  0.0139,  0.0489, -0.0417, -0.0408,  0.1485,\n",
      "          0.0496,  0.1629, -0.0059, -0.0451, -0.0528,  0.1137, -0.0703,  0.1330,\n",
      "         -0.0167, -0.0833, -0.0043,  0.0967],\n",
      "        [ 0.0605, -0.0714, -0.1559, -0.0261, -0.0907, -0.0269,  0.0549, -0.1048,\n",
      "          0.1263, -0.1483,  0.1830, -0.1227,  0.1579,  0.0976, -0.0630, -0.0642,\n",
      "          0.0642,  0.0171,  0.0748, -0.0418, -0.0341,  0.1174,  0.1188, -0.1357,\n",
      "         -0.0569,  0.1670,  0.1514,  0.1882, -0.0166, -0.0848, -0.0153,  0.0541,\n",
      "          0.1883, -0.0972, -0.0972, -0.0510, -0.1072, -0.0235, -0.0642,  0.1352,\n",
      "          0.0150, -0.0173, -0.1752,  0.1126, -0.0674,  0.0020,  0.0317, -0.0967,\n",
      "          0.1348, -0.1442, -0.0774, -0.1404,  0.1202, -0.0748, -0.1379,  0.0576,\n",
      "          0.1114, -0.0876,  0.1180, -0.1181,  0.1069,  0.1197,  0.1634, -0.0131,\n",
      "          0.1384, -0.0552,  0.0004, -0.0252, -0.0005, -0.0646, -0.0370, -0.0633,\n",
      "         -0.0284,  0.0869, -0.1731,  0.1347, -0.1184, -0.1579, -0.0766,  0.0333,\n",
      "          0.0633, -0.0766, -0.0020,  0.0931, -0.0060, -0.0381,  0.0882,  0.0496,\n",
      "         -0.0383, -0.0410,  0.0548, -0.0701, -0.0373, -0.1803,  0.1029, -0.0843,\n",
      "         -0.0158, -0.1036,  0.0492, -0.0733],\n",
      "        [ 0.1163,  0.0529,  0.0872, -0.0351, -0.0968,  0.1147,  0.0832, -0.0014,\n",
      "         -0.0788,  0.0679,  0.0367,  0.0653,  0.2598, -0.0424, -0.0725,  0.0351,\n",
      "          0.0587,  0.0893, -0.1037, -0.0686, -0.0598, -0.0415,  0.1333,  0.0031,\n",
      "          0.0858, -0.0589, -0.0039, -0.0715,  0.0809, -0.0254,  0.0300, -0.1061,\n",
      "          0.1893,  0.0260, -0.0539,  0.0239,  0.2075, -0.0787, -0.1141,  0.0259,\n",
      "          0.0277, -0.0784, -0.0361, -0.0954,  0.1004, -0.0387, -0.0915, -0.1756,\n",
      "          0.0812,  0.0002,  0.0163,  0.1229,  0.0020, -0.0592,  0.0071,  0.0194,\n",
      "         -0.0185, -0.1658, -0.0266, -0.0476, -0.0040, -0.1298,  0.0797, -0.0132,\n",
      "         -0.0125, -0.0713,  0.0886,  0.0654, -0.1828,  0.1266, -0.0312, -0.1565,\n",
      "         -0.0008,  0.0433, -0.0532, -0.0615,  0.0067,  0.2707, -0.1773, -0.0664,\n",
      "          0.0780,  0.1225, -0.0906, -0.0346, -0.1364, -0.1227, -0.0573,  0.0918,\n",
      "         -0.1081,  0.1082, -0.0558, -0.0893,  0.0545, -0.0031,  0.0543, -0.1526,\n",
      "         -0.1887,  0.0908, -0.0388,  0.1185],\n",
      "        [-0.1174, -0.0956, -0.0778, -0.0839, -0.1300,  0.1048, -0.0927,  0.0063,\n",
      "         -0.0726, -0.1231,  0.0053,  0.0911, -0.0725, -0.1458, -0.0792,  0.0743,\n",
      "          0.0184,  0.0899,  0.2005, -0.1634, -0.0627, -0.0126, -0.0801, -0.0196,\n",
      "         -0.1274, -0.1908, -0.0943,  0.0627, -0.0222,  0.0798,  0.0219, -0.1379,\n",
      "          0.1264,  0.0201,  0.1231, -0.0776, -0.0175,  0.0741,  0.2067,  0.1731,\n",
      "          0.1828,  0.0337, -0.0757,  0.1103,  0.0470, -0.0247,  0.0363, -0.1289,\n",
      "         -0.1138,  0.1339,  0.0701,  0.0968, -0.1750, -0.0275, -0.1629, -0.1297,\n",
      "          0.1120, -0.0651, -0.0119, -0.0819, -0.0517,  0.1247, -0.0554,  0.0212,\n",
      "         -0.1113,  0.0962, -0.1201, -0.0136,  0.1305, -0.0559, -0.1068, -0.1020,\n",
      "         -0.0739,  0.0870,  0.1114, -0.0510, -0.0069,  0.1589, -0.0137, -0.0609,\n",
      "          0.0888,  0.0635, -0.0432, -0.0050, -0.0781,  0.0995, -0.0672,  0.0887,\n",
      "         -0.0514, -0.0577, -0.1168,  0.0129, -0.0206,  0.0918,  0.0148, -0.0447,\n",
      "          0.0651,  0.0980, -0.0730,  0.1064],\n",
      "        [ 0.1344, -0.0527, -0.1721,  0.0228,  0.0103, -0.0212,  0.0978, -0.0764,\n",
      "         -0.0590,  0.0773,  0.0813,  0.1136,  0.0045, -0.0662,  0.0648, -0.1574,\n",
      "          0.0122, -0.0855, -0.0298, -0.1251,  0.0770,  0.1594,  0.1165, -0.0861,\n",
      "         -0.1141, -0.0640, -0.1431, -0.0167,  0.0222, -0.0586, -0.1808,  0.0198,\n",
      "         -0.1278,  0.0701, -0.1002,  0.0631, -0.0676, -0.0541,  0.0505, -0.0883,\n",
      "         -0.0518,  0.0285,  0.0013, -0.1970,  0.0006,  0.0546, -0.0142,  0.0711,\n",
      "         -0.0467, -0.0935, -0.0555, -0.0608,  0.0216,  0.0222,  0.0968, -0.0574,\n",
      "          0.0568,  0.0914,  0.1699,  0.1728,  0.2329, -0.0513,  0.0553,  0.0158,\n",
      "          0.0237, -0.1188,  0.1711, -0.0002,  0.0112,  0.0978,  0.0454,  0.0862,\n",
      "          0.0530,  0.0608,  0.0068, -0.1118,  0.0083, -0.1468,  0.1673,  0.0777,\n",
      "          0.0660,  0.0521,  0.0632, -0.0286,  0.1892, -0.1432,  0.0500,  0.0170,\n",
      "          0.0163,  0.0035, -0.1290,  0.0328, -0.0114, -0.1939,  0.1007,  0.0200,\n",
      "         -0.0886, -0.0748, -0.0414, -0.0459],\n",
      "        [-0.0702,  0.0972, -0.1089, -0.0164,  0.1510,  0.1673,  0.0355, -0.0335,\n",
      "          0.0098, -0.0335, -0.0313,  0.0474, -0.2167,  0.0931,  0.0591,  0.1774,\n",
      "          0.0661, -0.1510, -0.0437,  0.0292,  0.0459,  0.0118, -0.1072,  0.0775,\n",
      "          0.1941,  0.0081, -0.0666,  0.1146,  0.0869, -0.0447,  0.0142,  0.1406,\n",
      "         -0.0295,  0.0406,  0.1028,  0.1352,  0.0855, -0.0151, -0.0241, -0.0670,\n",
      "          0.0759,  0.0260, -0.1360,  0.1547, -0.0115, -0.0346,  0.1122,  0.0071,\n",
      "         -0.1181, -0.0383, -0.0050,  0.0827,  0.0534,  0.0518, -0.1492,  0.0719,\n",
      "         -0.0114,  0.1788, -0.0322,  0.0634, -0.1965,  0.0355, -0.1877,  0.0430,\n",
      "         -0.0153,  0.1204, -0.0848, -0.0072, -0.0121,  0.0730, -0.0186,  0.0754,\n",
      "          0.0164,  0.0924,  0.1594, -0.0360,  0.0770, -0.0528,  0.0936, -0.0763,\n",
      "         -0.0707, -0.0935, -0.0783, -0.0139, -0.0352,  0.0623, -0.0253, -0.1390,\n",
      "          0.0381, -0.1633,  0.1316, -0.1226, -0.0330,  0.1635, -0.1238, -0.0575,\n",
      "          0.2134, -0.1288, -0.0973, -0.1462],\n",
      "        [-0.1267,  0.0608,  0.0945, -0.0855,  0.0137, -0.1502, -0.0231, -0.0381,\n",
      "          0.0615,  0.1791,  0.0682, -0.0547, -0.1165,  0.0160, -0.0677,  0.1215,\n",
      "          0.1270,  0.0552,  0.0252,  0.0310, -0.0521,  0.0416, -0.0192, -0.0318,\n",
      "          0.1169, -0.0378, -0.0670, -0.1821,  0.0983, -0.0484, -0.0966,  0.0173,\n",
      "         -0.1199, -0.0362, -0.0371, -0.0377, -0.0871, -0.0873, -0.0467, -0.1680,\n",
      "         -0.0357,  0.0793, -0.1178, -0.0236,  0.0737, -0.0153, -0.0381, -0.0225,\n",
      "          0.0352, -0.2038,  0.0576,  0.0369, -0.0268,  0.0086,  0.0528,  0.2330,\n",
      "         -0.0982,  0.0023, -0.0252,  0.0119, -0.1204, -0.0712, -0.1209,  0.0804,\n",
      "          0.0809,  0.0293,  0.0905, -0.0259, -0.0375, -0.0021,  0.1119,  0.0360,\n",
      "         -0.0401,  0.0578, -0.1174, -0.0666, -0.1238, -0.0625,  0.0602, -0.0826,\n",
      "         -0.0951, -0.1556, -0.0814,  0.0590, -0.0276,  0.1907,  0.1193,  0.1279,\n",
      "          0.0191,  0.0608, -0.0323, -0.2167, -0.0499, -0.0226, -0.0062,  0.2766,\n",
      "          0.0613,  0.0723, -0.1194,  0.0362],\n",
      "        [ 0.1253, -0.0567, -0.0470,  0.0057, -0.0911,  0.1846, -0.0189,  0.0406,\n",
      "          0.0422, -0.0780, -0.0071, -0.2156, -0.0201, -0.0144, -0.0221, -0.0102,\n",
      "         -0.0019, -0.1399,  0.1202, -0.0799, -0.0560, -0.0376,  0.0086, -0.1423,\n",
      "         -0.1784,  0.1010,  0.0851,  0.0469, -0.0839, -0.0062, -0.1095,  0.1140,\n",
      "          0.0282,  0.0649, -0.0995, -0.0791,  0.1417, -0.0001, -0.0900,  0.0731,\n",
      "         -0.1580,  0.0366,  0.1625, -0.1173,  0.0578,  0.0885,  0.0795, -0.0279,\n",
      "          0.0966,  0.2265, -0.0082, -0.0968,  0.1544, -0.0177, -0.0833, -0.0294,\n",
      "          0.0502, -0.1520,  0.1117,  0.0786, -0.0282, -0.1254, -0.0582,  0.0808,\n",
      "         -0.1701, -0.0076, -0.1343, -0.0174, -0.1298, -0.0760, -0.0093, -0.0526,\n",
      "          0.0641,  0.0873,  0.0920,  0.0170,  0.0591, -0.0053,  0.0125,  0.0697,\n",
      "          0.0351, -0.1147, -0.1147,  0.0011, -0.0274, -0.1307, -0.1444,  0.0165,\n",
      "         -0.0701,  0.1172,  0.0456,  0.0969,  0.0502,  0.1024,  0.1399, -0.1740,\n",
      "         -0.1500,  0.0137, -0.0495,  0.0711],\n",
      "        [ 0.0179,  0.0685,  0.0873,  0.0371,  0.0590,  0.0197,  0.1005,  0.0666,\n",
      "         -0.1361,  0.1357, -0.0054, -0.0601,  0.1132, -0.1546, -0.0455, -0.0954,\n",
      "         -0.0512,  0.1773, -0.1578, -0.0489, -0.0059, -0.0846, -0.0196,  0.1207,\n",
      "          0.0869, -0.0223, -0.0498, -0.0834, -0.0735,  0.0632,  0.0749,  0.0071,\n",
      "          0.0989, -0.0011, -0.0934, -0.0903, -0.0573,  0.0495,  0.0562, -0.0934,\n",
      "         -0.0274,  0.0376,  0.2146,  0.0413, -0.0074, -0.0715,  0.0373,  0.1217,\n",
      "         -0.0909,  0.1196,  0.0167,  0.0224,  0.0212, -0.0289,  0.0734, -0.1166,\n",
      "          0.0324,  0.1181, -0.1991, -0.1180,  0.0931, -0.0650, -0.0690, -0.0341,\n",
      "          0.0157,  0.1252, -0.0985,  0.0414,  0.1322, -0.1907, -0.0653, -0.0911,\n",
      "         -0.0773,  0.0222, -0.1590,  0.0777, -0.0225,  0.1439,  0.0272,  0.0664,\n",
      "         -0.0481, -0.1818,  0.0939,  0.0641, -0.1797,  0.0371,  0.1511, -0.0627,\n",
      "          0.0379, -0.0997, -0.1519,  0.0007,  0.0910, -0.0139,  0.0055, -0.0742,\n",
      "         -0.0375,  0.1489, -0.0454, -0.1793],\n",
      "        [ 0.0146, -0.0842,  0.0056,  0.0951, -0.0240,  0.0560,  0.0690,  0.0636,\n",
      "         -0.0916,  0.0020, -0.0134,  0.0796, -0.0850, -0.0028,  0.0361, -0.0669,\n",
      "         -0.3067,  0.1429, -0.0458,  0.0598,  0.0754,  0.0671, -0.0477,  0.1118,\n",
      "         -0.0051, -0.0064, -0.0240,  0.1009,  0.0136, -0.0055,  0.0861,  0.0048,\n",
      "         -0.2677, -0.1203, -0.0678, -0.0073, -0.1324,  0.0625, -0.0334,  0.0507,\n",
      "          0.0945,  0.0802, -0.1084, -0.0306, -0.0056,  0.0800, -0.1123,  0.0358,\n",
      "         -0.0649,  0.1931,  0.0560,  0.1092, -0.1128, -0.0712,  0.1549, -0.1540,\n",
      "          0.0716,  0.1764,  0.0486, -0.0538,  0.0456,  0.1606, -0.0910, -0.0560,\n",
      "          0.0678,  0.1936,  0.0395, -0.0298, -0.0671,  0.0566, -0.1658,  0.0905,\n",
      "          0.0633, -0.0620,  0.1562,  0.0469, -0.1265, -0.2520,  0.0131, -0.0754,\n",
      "         -0.2041,  0.1002,  0.0500, -0.0082,  0.1458, -0.2233, -0.0389,  0.0779,\n",
      "          0.0896,  0.1174,  0.0230,  0.1004,  0.0039,  0.0297,  0.0805, -0.0051,\n",
      "          0.0482, -0.0716,  0.0410,  0.1311]], requires_grad=True) \n",
      "\n",
      "\n",
      "10   torch.Size([10]) \n",
      "  Parameter containing:\n",
      "tensor([-0.0838,  0.0204, -0.0172,  0.0138,  0.0053, -0.0699,  0.0305,  0.0152,\n",
      "        -0.0514, -0.0417], requires_grad=True) \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for parameter in net.parameters():\n",
    "    i+=1\n",
    "    print(i,\" \",parameter.shape,\"\\n \",parameter,\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### First we have to convert the nodes to points in some d dimenstion. Where d is the number of nodes in the next layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300, 256])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net.state_dict()[\"fc1.weight\"]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can not prune the layer with 256 nodes. We have to prune the layer with 300 nodes. So, that depends on the outgoing edges weights means fc2. Because, if we consider the incoming edges two nodes with similar kind of incoming weights might not have a similar kind of effect on the next layer. But, two nodes having similar kind of outgoing edges will have same effect on the next layer. Example: if node1 has incoming edge i1, and outgoing edge o1. And node2 have incoming edge form same previous incoming node as i2, and same outgoing edge weight as o2. Then if we club them up, the net effect will be some function of f(i1+i2)* o1. assuming o1 and o2 are very similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 300])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print((net.state_dict()[\"fc2.weight\"]).shape)\n",
    "print(type(net.state_dict()[\"fc2.weight\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After changing the dimension of the layer with 300 nodes, to somehting less than 300. We also have to assing the incoming weight edges accordingly, and assign the outgoing edges equals to be mostly the avg of the nodes in same cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, first we need to form a space of dimension 100, with 300 points depending on fc2 weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0402,  0.0027,  0.0155,  ...,  0.0570, -0.0099, -0.0361],\n",
      "        [-0.0434,  0.0438, -0.0348,  ..., -0.0697,  0.0150,  0.0464],\n",
      "        [ 0.0285, -0.0360,  0.0268,  ...,  0.0352,  0.0478, -0.0538],\n",
      "        ...,\n",
      "        [-0.0308,  0.0140,  0.0200,  ..., -0.0380,  0.0631,  0.0255],\n",
      "        [-0.0236,  0.0560,  0.0367,  ..., -0.0513, -0.0225, -0.0425],\n",
      "        [ 0.0146,  0.0263,  0.0531,  ..., -0.0107,  0.0330, -0.0736]])\n",
      "torch.Size([300, 100])\n"
     ]
    }
   ],
   "source": [
    "mat=net.state_dict()[\"fc2.weight\"].t()\n",
    "print(mat)\n",
    "print(mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300   100\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "nodes=defaultdict(list)\n",
    "for j in range(len(net.state_dict()[\"fc2.weight\"][0])):\n",
    "    ele=[]\n",
    "    for i in range(len(net.state_dict()[\"fc2.weight\"])):\n",
    "        ele.append(net.state_dict()[\"fc2.weight\"][i][j].item())\n",
    "    nodes[j]=ele\n",
    "\n",
    "print(len(nodes), \" \", len(nodes[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(nodes[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have nodes as a dictionary, where key is the node id, and values are the outgoing edges. So, now we have to find such node_ids who are having almost similar outgoing edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the Euclidean distance between two vectors\n",
    "def euclidean_distance(row1, row2):\n",
    "\tdistance = 0.0\n",
    "\tfor i in range(len(row1)-1):\n",
    "\t\tdistance += (row1[i] - row2[i])**2\n",
    "\treturn sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "distances=[]\n",
    "for i in nodes.keys():\n",
    "    for j in nodes.keys():\n",
    "        if(i!=j and j>i):\n",
    "            distances.append(euclidean_distance(nodes[i], nodes[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44850\n"
     ]
    }
   ],
   "source": [
    "distances.sort()\n",
    "print(len(distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "# plt.plot([x for x in range(len(distances))], distances) \n",
    "# plt.ylabel(\"Distances\")\n",
    "# plt.show() \n",
    "x=[k for k in range(len(distances))]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(x, distances)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# A=random.sample(range(len(cluster)), (len(cluster)))\n",
    "# print(A[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster=defaultdict(bool)\n",
    "setpoints=defaultdict(set)\n",
    "for i in nodes.keys():\n",
    "    cluster[i]=False\n",
    "    setpoints[i]={i}\n",
    "    \n",
    "import random\n",
    "A=random.sample(range(len(cluster)), (len(cluster)))\n",
    "\n",
    "# print(len(A),\"\\n\",A)\n",
    "\n",
    "\n",
    "num_cluster=33\n",
    "num_nodes=300\n",
    "sz_cluster=num_nodes//num_cluster\n",
    "\n",
    "for i in range(num_cluster):\n",
    "    for j in range(1,sz_cluster):\n",
    "        setpoints[A[i*sz_cluster]].add(A[i*sz_cluster+j])\n",
    "        del setpoints[A[i*sz_cluster+j]]\n",
    "\n",
    "if num_nodes % num_cluster != 0:\n",
    "    for z in range(num_cluster*sz_cluster, num_nodes):\n",
    "        setpoints[A[(num_cluster-1)*sz_cluster]].add(A[z])\n",
    "        del setpoints[A[z]]\n",
    "        \n",
    "# for i in nodes.keys():\n",
    "#     for j in nodes.keys():\n",
    "#         if(i!=j and j>i and cluster[i]==False and cluster[j]==False):\n",
    "#             if(euclidean_distance(nodes[i], nodes[j])<0.45):\n",
    "#                 setpoints[i].add(j)\n",
    "#                 del setpoints[j]\n",
    "#                 cluster[j]=True\n",
    "#     cluster[i]=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2  ->  {97, 2, 133, 167, 13, 239, 176, 273, 17, 118, 248, 95}\n",
      "11  ->  {259, 68, 11, 173, 14, 213, 60, 221, 62}\n",
      "23  ->  {128, 257, 69, 6, 297, 106, 272, 209, 23}\n",
      "25  ->  {289, 129, 109, 174, 183, 152, 25, 215, 59}\n",
      "31  ->  {260, 293, 294, 31, 206, 240, 149, 188, 191}\n",
      "35  ->  {224, 96, 35, 195, 4, 41, 110, 249, 223}\n",
      "36  ->  {36, 231, 205, 112, 50, 20, 279, 24, 253}\n",
      "40  ->  {196, 40, 75, 142, 83, 244, 52, 282, 157}\n",
      "46  ->  {67, 3, 265, 170, 236, 46, 212, 116, 120}\n",
      "53  ->  {263, 299, 235, 111, 117, 53, 22, 26, 284}\n",
      "85  ->  {193, 261, 73, 139, 43, 80, 114, 85, 182}\n",
      "86  ->  {228, 168, 234, 242, 179, 86, 87, 153, 255}\n",
      "90  ->  {100, 165, 292, 233, 237, 178, 245, 90, 251}\n",
      "94  ->  {103, 169, 74, 113, 181, 150, 154, 94, 63}\n",
      "121  ->  {0, 192, 258, 226, 98, 166, 81, 121, 283}\n",
      "127  ->  {65, 291, 37, 102, 295, 82, 219, 125, 127}\n",
      "131  ->  {131, 164, 141, 269, 16, 49, 246, 184, 189}\n",
      "148  ->  {160, 136, 180, 148, 252, 247, 281, 92, 158}\n",
      "162  ->  {256, 162, 70, 105, 44, 208, 51, 55, 58}\n",
      "175  ->  {32, 227, 201, 203, 108, 175, 243, 115, 156}\n",
      "186  ->  {194, 10, 18, 275, 151, 186, 123, 28, 190}\n",
      "198  ->  {198, 137, 45, 48, 210, 250, 61, 126, 287}\n",
      "204  ->  {99, 229, 230, 200, 172, 204, 144, 241, 285}\n",
      "217  ->  {34, 163, 132, 39, 76, 140, 146, 19, 217}\n",
      "220  ->  {38, 71, 202, 138, 270, 207, 78, 122, 220}\n",
      "225  ->  {225, 262, 42, 15, 277, 119, 89, 91, 254}\n",
      "232  ->  {288, 197, 232, 104, 177, 145, 155, 222, 30}\n",
      "267  ->  {64, 33, 290, 66, 267, 107, 79, 47, 88}\n",
      "268  ->  {130, 101, 199, 268, 238, 147, 54, 218, 159}\n",
      "276  ->  {1, 135, 8, 27, 12, 276, 57, 187, 124}\n",
      "286  ->  {7, 72, 9, 77, 214, 280, 185, 93, 286}\n",
      "296  ->  {134, 296, 264, 171, 271, 21, 278, 216, 56}\n",
      "298  ->  {161, 5, 298, 266, 143, 274, 211, 84, 29}\n"
     ]
    }
   ],
   "source": [
    "for key in setpoints.keys():\n",
    "    print(key,\" -> \",setpoints[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "print(len(setpoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "temp=[]\n",
    "for node in setpoints.keys():\n",
    "    row=torch.zeros(len(net.state_dict()[\"fc1.weight\"][0]), dtype=torch.float)\n",
    "    for val in setpoints[node]:\n",
    "        row+=net.state_dict()[\"fc1.weight\"][val]\n",
    "    temp.append(row)\n",
    "print(len(temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have i many nodes in place of 300. Now, we will first fix the incoming weights this i many nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([300, 256])\n",
      "torch.Size([33, 256])\n"
     ]
    }
   ],
   "source": [
    "print(net.state_dict()[\"fc1.weight\"].shape)\n",
    "net.state_dict()[\"fc1.weight\"].resize_((len(temp), len(temp[0])))\n",
    "print(net.state_dict()[\"fc1.weight\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(temp)):\n",
    "    for j in range(len(temp[0])):\n",
    "        net.state_dict()[\"fc1.weight\"][i][j]=temp[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([33, 256])\n"
     ]
    }
   ],
   "source": [
    "print(net.state_dict()[\"fc1.weight\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "temp=[]\n",
    "for node in setpoints.keys():\n",
    "    ele=0\n",
    "    for val in setpoints[node]:\n",
    "        ele+=net.state_dict()[\"fc1.bias\"][val]\n",
    "    temp.append(ele)\n",
    "print(len(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([300])\n",
      "torch.Size([33])\n"
     ]
    }
   ],
   "source": [
    "print(net.state_dict()[\"fc1.bias\"].shape)\n",
    "net.state_dict()[\"fc1.bias\"].resize_((len(temp)))\n",
    "print(net.state_dict()[\"fc1.bias\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([33])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(temp)):\n",
    "    net.state_dict()[\"fc1.bias\"][i]=temp[i]\n",
    "print(net.state_dict()[\"fc1.bias\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have to change the outgoing weights. We can try out checking with the average of the same cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 300])\n"
     ]
    }
   ],
   "source": [
    "print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "temp=[]\n",
    "for i in range(len(net.state_dict()[\"fc2.weight\"])):\n",
    "    row=[]\n",
    "    for j in setpoints.keys():\n",
    "        ele=0\n",
    "        for val in setpoints[j]:\n",
    "            ele+=net.state_dict()[\"fc2.weight\"][i][val]\n",
    "        row.append(ele/len(setpoints[j]))\n",
    "    temp.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 33\n"
     ]
    }
   ],
   "source": [
    "print(len(temp), len(temp[0]))\n",
    "# print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 33])\n"
     ]
    }
   ],
   "source": [
    "net.state_dict()[\"fc2.weight\"].resize_(len(temp), len(temp[0]))\n",
    "for i in range(len(temp)):\n",
    "    for j in range(len(temp[0])):\n",
    "        net.state_dict()[\"fc2.weight\"][i][j]=temp[i][j]\n",
    "print(net.state_dict()[\"fc2.weight\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "print((net.state_dict()[\"fc2.bias\"]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 26.760000 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try to prune the next layer which consists of 100 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 33])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net.state_dict()[\"fc2.weight\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 100])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net.state_dict()[\"fc3.weight\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100   10\n"
     ]
    }
   ],
   "source": [
    "nodes=defaultdict(list)\n",
    "for j in range(len(net.state_dict()[\"fc3.weight\"][0])):\n",
    "    ele=[]\n",
    "    for i in range(len(net.state_dict()[\"fc3.weight\"])):\n",
    "        ele.append(net.state_dict()[\"fc3.weight\"][i][j].item())\n",
    "    nodes[j]=ele\n",
    "\n",
    "print(len(nodes), \" \", len(nodes[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "distances=[]\n",
    "for i in nodes.keys():\n",
    "    for j in nodes.keys():\n",
    "        if(i!=j and j>i):\n",
    "            distances.append(euclidean_distance(nodes[i], nodes[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4950\n"
     ]
    }
   ],
   "source": [
    "distances.sort()\n",
    "print(len(distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "\n",
    "x=[k for k in range(len(distances))]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(x, distances)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to set the cutoff as 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster=defaultdict(bool)\n",
    "setpoints=defaultdict(set)\n",
    "for i in nodes.keys():\n",
    "    cluster[i]=False\n",
    "    setpoints[i]={i}\n",
    "    \n",
    "import random\n",
    "A=random.sample(range(len(cluster)), (len(cluster)))\n",
    "\n",
    "\n",
    "num_cluster=10\n",
    "num_nodes=100\n",
    "sz_cluster=num_nodes//num_cluster\n",
    "\n",
    "# now make 9 random clusters from A, which has 100 elements. \n",
    "\n",
    "for i in range(num_cluster):\n",
    "    for j in range(1,sz_cluster):\n",
    "        setpoints[A[i*sz_cluster]].add(A[i*sz_cluster+j])\n",
    "        del setpoints[A[i*sz_cluster+j]]\n",
    "\n",
    "if num_nodes % num_cluster != 0:\n",
    "    for z in range(num_cluster*sz_cluster, num_nodes):\n",
    "        setpoints[A[(num_cluster-1)*sz_cluster]].add(A[z])\n",
    "        del setpoints[A[z]]\n",
    "\n",
    "\n",
    "    \n",
    "# for i in nodes.keys():\n",
    "#     for j in nodes.keys():\n",
    "#         if(i!=j and j>i and cluster[i]==False and cluster[j]==False):\n",
    "#             if(euclidean_distance(nodes[i], nodes[j])<0.3):\n",
    "#                 setpoints[i].add(j)\n",
    "#                 del setpoints[j]\n",
    "#                 cluster[j]=True\n",
    "#     cluster[i]=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37  ->  {0, 96, 3, 68, 37, 72, 8, 44, 58, 94}\n",
      "39  ->  {67, 99, 39, 19, 23, 88, 91, 93, 30, 95}\n",
      "40  ->  {33, 38, 40, 9, 11, 82, 22, 25, 59, 92}\n",
      "49  ->  {65, 1, 4, 5, 41, 14, 46, 16, 49, 81}\n",
      "54  ->  {6, 42, 74, 79, 51, 83, 54, 87, 61, 62}\n",
      "71  ->  {2, 36, 71, 13, 78, 84, 21, 85, 28, 63}\n",
      "73  ->  {64, 32, 26, 35, 73, 12, 24, 90, 27, 60}\n",
      "75  ->  {98, 66, 69, 10, 75, 47, 17, 53, 55, 31}\n",
      "76  ->  {34, 70, 7, 43, 76, 77, 15, 48, 52, 57}\n",
      "86  ->  {97, 45, 80, 50, 18, 20, 86, 56, 89, 29}\n"
     ]
    }
   ],
   "source": [
    "for key in setpoints.keys():\n",
    "    print(key,\" -> \",setpoints[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(setpoints))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have i many nodes in place of 100. Now, we will first fix the incoming weights this i many nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "temp=[]\n",
    "for node in setpoints.keys():\n",
    "    row=torch.zeros(len(net.state_dict()[\"fc2.weight\"][0]), dtype=torch.float)\n",
    "    for val in setpoints[node]:\n",
    "        row+=net.state_dict()[\"fc2.weight\"][val]\n",
    "    temp.append(row)\n",
    "print(len(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 33])\n",
      "torch.Size([10, 33])\n"
     ]
    }
   ],
   "source": [
    "print(net.state_dict()[\"fc2.weight\"].shape)\n",
    "net.state_dict()[\"fc2.weight\"].resize_((len(temp), len(temp[0])))\n",
    "print(net.state_dict()[\"fc2.weight\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(temp)):\n",
    "    for j in range(len(temp[0])):\n",
    "        net.state_dict()[\"fc2.weight\"][i][j]=temp[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 33])\n"
     ]
    }
   ],
   "source": [
    "print(net.state_dict()[\"fc2.weight\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "temp=[]\n",
    "for node in setpoints.keys():\n",
    "    ele=0\n",
    "    for val in setpoints[node]:\n",
    "        ele+=net.state_dict()[\"fc2.bias\"][val]\n",
    "    temp.append(ele)\n",
    "print(len(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(net.state_dict()[\"fc2.bias\"].shape)\n",
    "net.state_dict()[\"fc2.bias\"].resize_((len(temp)))\n",
    "print(net.state_dict()[\"fc2.bias\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(temp)):\n",
    "    net.state_dict()[\"fc2.bias\"][i]=temp[i]\n",
    "print(net.state_dict()[\"fc2.bias\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100])\n"
     ]
    }
   ],
   "source": [
    "print(net.state_dict()[\"fc3.weight\"].shape)\n",
    "temp=[]\n",
    "for i in range(len(net.state_dict()[\"fc3.weight\"])):\n",
    "    row=[]\n",
    "    for j in setpoints.keys():\n",
    "        ele=0\n",
    "        for val in setpoints[j]:\n",
    "            ele+=net.state_dict()[\"fc3.weight\"][i][val]\n",
    "        row.append(ele/len(setpoints[j]))\n",
    "    temp.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(temp), len(temp[0]))\n",
    "# print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "net.state_dict()[\"fc3.weight\"].resize_(len(temp), len(temp[0]))\n",
    "for i in range(len(temp)):\n",
    "    for j in range(len(temp[0])):\n",
    "        net.state_dict()[\"fc3.weight\"][i][j]=temp[i][j]\n",
    "print(net.state_dict()[\"fc3.weight\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print((net.state_dict()[\"fc3.bias\"]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 9.650000 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for parameter in net.parameters():\n",
    "    i+=1\n",
    "    if(i<5):\n",
    "        parameter.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.1307,), (0.3081,))])\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=200,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=200,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('0', '1', '2', '3',\n",
    "           '4', '5', '6', '7', '8', '9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   torch.Size([6, 1, 5, 5]) \n",
      "  Parameter containing:\n",
      "tensor([[[[-0.0192,  0.2511,  0.2183,  0.0210,  0.0190],\n",
      "          [-0.0522,  0.3645,  0.3561,  0.5513,  0.3440],\n",
      "          [ 0.0598,  0.5070,  0.6116,  0.6220,  0.2953],\n",
      "          [ 0.2985,  0.1301,  0.4567,  0.1638,  0.2149],\n",
      "          [-0.0246,  0.3206,  0.1249,  0.1288, -0.1632]]],\n",
      "\n",
      "\n",
      "        [[[-0.1775, -0.0977,  0.0400,  0.2623,  0.2931],\n",
      "          [ 0.0318, -0.1988, -0.1956,  0.1583,  0.1678],\n",
      "          [-0.2439, -0.2983, -0.0792,  0.2235,  0.3461],\n",
      "          [-0.0280, -0.2769, -0.1121,  0.0926,  0.3560],\n",
      "          [-0.1970, -0.1645,  0.1938,  0.2115,  0.1824]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1362,  0.2118, -0.2154, -0.2076, -0.2334],\n",
      "          [ 0.2467, -0.0821, -0.1670, -0.0738,  0.2066],\n",
      "          [ 0.2564,  0.1952,  0.2048,  0.3864,  0.0963],\n",
      "          [ 0.0786,  0.3546,  0.3418, -0.0168,  0.1037],\n",
      "          [ 0.0178, -0.2039, -0.1759, -0.0146, -0.0048]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0299,  0.1694, -0.0029, -0.1827, -0.0718],\n",
      "          [-0.1909, -0.1638,  0.1044, -0.2096,  0.0405],\n",
      "          [ 0.0873, -0.1777, -0.1820, -0.0258, -0.1887],\n",
      "          [ 0.0190, -0.1462, -0.0486,  0.0288, -0.2104],\n",
      "          [ 0.1727, -0.1630, -0.0454, -0.2031, -0.1915]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1378,  0.0087, -0.1978, -0.2727,  0.0345],\n",
      "          [ 0.2285, -0.0154, -0.1342, -0.2998, -0.0739],\n",
      "          [ 0.2801,  0.2191,  0.1079,  0.2947,  0.1320],\n",
      "          [ 0.3344,  0.4029,  0.3628,  0.5148,  0.0400],\n",
      "          [ 0.0682,  0.0300,  0.3382,  0.2907,  0.3091]]],\n",
      "\n",
      "\n",
      "        [[[-0.2584, -0.2308, -0.1856,  0.0330,  0.0465],\n",
      "          [-0.2978, -0.1939, -0.2057,  0.0400,  0.1692],\n",
      "          [ 0.0883, -0.1518,  0.0861, -0.1625,  0.0874],\n",
      "          [ 0.1464,  0.2543,  0.0292,  0.0581, -0.0674],\n",
      "          [ 0.3818,  0.3657,  0.2362, -0.0540,  0.1097]]]]) \n",
      "\n",
      "\n",
      "2   torch.Size([6]) \n",
      "  Parameter containing:\n",
      "tensor([ 0.2434, -0.0632,  0.2198,  0.1060,  0.1912,  0.0086]) \n",
      "\n",
      "\n",
      "3   torch.Size([16, 6, 5, 5]) \n",
      "  Parameter containing:\n",
      "tensor([[[[-0.0109, -0.0548, -0.0268,  0.0555,  0.0529],\n",
      "          [-0.0747, -0.0093, -0.0871,  0.0756,  0.0290],\n",
      "          [ 0.0085, -0.0744, -0.1693, -0.1346, -0.1455],\n",
      "          [ 0.0382, -0.0446, -0.1455, -0.0654, -0.0830],\n",
      "          [ 0.0522,  0.1614,  0.1331,  0.1559,  0.0276]],\n",
      "\n",
      "         [[-0.0135,  0.0531,  0.0238,  0.0102,  0.0312],\n",
      "          [ 0.0628, -0.0327,  0.0206, -0.0319,  0.0428],\n",
      "          [-0.0834, -0.1235, -0.0557,  0.0262, -0.0169],\n",
      "          [ 0.0244, -0.0334,  0.0382, -0.0140,  0.0345],\n",
      "          [ 0.1239, -0.0369, -0.0981, -0.0913, -0.0969]],\n",
      "\n",
      "         [[-0.0242, -0.0831,  0.0583,  0.0632, -0.0662],\n",
      "          [-0.0261, -0.0701,  0.0334, -0.0154,  0.0068],\n",
      "          [-0.0244,  0.0824, -0.1057, -0.1036,  0.0335],\n",
      "          [-0.0140,  0.1386,  0.0705,  0.0171, -0.0072],\n",
      "          [ 0.0018,  0.1739,  0.1223,  0.0542,  0.0006]],\n",
      "\n",
      "         [[ 0.0685,  0.0419, -0.0685, -0.0128, -0.0514],\n",
      "          [ 0.0531,  0.0907, -0.0022,  0.0279,  0.0706],\n",
      "          [ 0.0644,  0.0581,  0.0447,  0.0862, -0.0299],\n",
      "          [-0.0563, -0.0664,  0.0204, -0.0461, -0.0049],\n",
      "          [-0.0201, -0.0669, -0.0425, -0.0638,  0.0590]],\n",
      "\n",
      "         [[-0.0472,  0.0201, -0.0225, -0.0141, -0.0058],\n",
      "          [ 0.0624,  0.0067,  0.0042,  0.0046,  0.0419],\n",
      "          [ 0.0394,  0.0676, -0.0732, -0.1638, -0.0343],\n",
      "          [ 0.1362,  0.1999,  0.0978,  0.1239,  0.0379],\n",
      "          [ 0.0652,  0.1395,  0.1929,  0.1191,  0.0623]],\n",
      "\n",
      "         [[ 0.0314, -0.0123, -0.0633,  0.0803,  0.0407],\n",
      "          [-0.0420,  0.0859,  0.0217, -0.0667,  0.0375],\n",
      "          [ 0.0298,  0.0806,  0.0096,  0.0557, -0.0537],\n",
      "          [ 0.0555, -0.0591,  0.0920,  0.1185,  0.0150],\n",
      "          [-0.0733, -0.1120, -0.0059,  0.1112,  0.0869]]],\n",
      "\n",
      "\n",
      "        [[[-0.0222, -0.0632,  0.0230,  0.0518,  0.0471],\n",
      "          [-0.0131, -0.0666, -0.0177, -0.0039,  0.0601],\n",
      "          [ 0.0307,  0.0119,  0.1052, -0.0188,  0.0316],\n",
      "          [-0.0572, -0.0849, -0.0043,  0.1368,  0.0699],\n",
      "          [-0.0658, -0.1288, -0.1282, -0.0940, -0.0316]],\n",
      "\n",
      "         [[ 0.0440,  0.0498,  0.0480,  0.0980,  0.0044],\n",
      "          [-0.0486,  0.0267,  0.0349, -0.0436,  0.0280],\n",
      "          [-0.0089,  0.0524,  0.0789, -0.0944, -0.0586],\n",
      "          [-0.0659,  0.0035,  0.0432, -0.0714, -0.0228],\n",
      "          [ 0.0241, -0.0759, -0.0205,  0.0458, -0.0653]],\n",
      "\n",
      "         [[-0.0281,  0.0291, -0.0404,  0.0430, -0.0491],\n",
      "          [ 0.0727, -0.0770, -0.0016,  0.0005,  0.0026],\n",
      "          [-0.0638,  0.0402,  0.0268,  0.0278, -0.0408],\n",
      "          [-0.0593, -0.0857, -0.0497,  0.1150,  0.1128],\n",
      "          [-0.0520, -0.0732, -0.0377, -0.0443, -0.0022]],\n",
      "\n",
      "         [[-0.0036, -0.0737,  0.0009,  0.0342,  0.0625],\n",
      "          [ 0.0713, -0.0301, -0.0545, -0.0360, -0.0155],\n",
      "          [ 0.0323,  0.0786, -0.0489, -0.0150, -0.0732],\n",
      "          [-0.0087,  0.0101,  0.0736, -0.0299,  0.0564],\n",
      "          [ 0.0291, -0.0514,  0.0165, -0.0648, -0.0488]],\n",
      "\n",
      "         [[-0.0781,  0.0070, -0.0439,  0.0522,  0.0101],\n",
      "          [-0.0655, -0.0328,  0.0275, -0.0029, -0.0499],\n",
      "          [-0.0462,  0.0460,  0.0361,  0.1371,  0.0840],\n",
      "          [ 0.0280, -0.0768,  0.0399,  0.0632,  0.1553],\n",
      "          [ 0.0167,  0.0032, -0.0908, -0.1111, -0.0763]],\n",
      "\n",
      "         [[ 0.0044,  0.0608, -0.0532, -0.0601,  0.0587],\n",
      "          [-0.0058, -0.0142, -0.0047, -0.0417, -0.0031],\n",
      "          [-0.0824, -0.0439, -0.0758, -0.0655, -0.0323],\n",
      "          [ 0.0141, -0.0282,  0.0304,  0.0188, -0.0538],\n",
      "          [-0.0402,  0.0069,  0.0732,  0.0188, -0.0666]]],\n",
      "\n",
      "\n",
      "        [[[-0.0290, -0.0331, -0.0362, -0.0128, -0.1624],\n",
      "          [ 0.0264,  0.0704,  0.0559,  0.0057, -0.1444],\n",
      "          [ 0.0334, -0.0197,  0.0786,  0.1296, -0.0665],\n",
      "          [-0.1325, -0.0002, -0.0102,  0.0673,  0.1488],\n",
      "          [ 0.0281,  0.0752,  0.1247,  0.0654,  0.0795]],\n",
      "\n",
      "         [[ 0.0432,  0.0453, -0.0163, -0.0221, -0.0871],\n",
      "          [ 0.0297,  0.0078, -0.0213, -0.0102,  0.0096],\n",
      "          [-0.0610,  0.0428,  0.1683,  0.1447,  0.1145],\n",
      "          [ 0.0129,  0.1065,  0.1422,  0.0659,  0.0251],\n",
      "          [-0.0014,  0.0767,  0.0355,  0.0775,  0.0778]],\n",
      "\n",
      "         [[-0.0408,  0.0344,  0.0030, -0.0213, -0.0086],\n",
      "          [ 0.0332,  0.0192,  0.0254,  0.0032,  0.0026],\n",
      "          [-0.0381, -0.0148,  0.0117,  0.0037,  0.0669],\n",
      "          [ 0.0096, -0.0044,  0.0353, -0.0138,  0.0783],\n",
      "          [ 0.0304,  0.0076,  0.0405,  0.0741,  0.0048]],\n",
      "\n",
      "         [[-0.0272,  0.0014, -0.0568,  0.0614,  0.0953],\n",
      "          [ 0.0689, -0.0018,  0.0250,  0.0122,  0.0488],\n",
      "          [ 0.0131, -0.0347,  0.0192,  0.0197, -0.0680],\n",
      "          [ 0.0553, -0.0440, -0.0922, -0.0444,  0.0591],\n",
      "          [ 0.0409, -0.0933,  0.0049, -0.0250,  0.0385]],\n",
      "\n",
      "         [[ 0.0040,  0.0977,  0.0278,  0.0440, -0.1256],\n",
      "          [ 0.0426,  0.0925,  0.1221,  0.1534, -0.0139],\n",
      "          [-0.0277,  0.0244, -0.0303,  0.1574,  0.0935],\n",
      "          [-0.0314,  0.0749,  0.0602,  0.0665,  0.0982],\n",
      "          [ 0.0176,  0.0285,  0.0090,  0.0930, -0.0757]],\n",
      "\n",
      "         [[-0.0138,  0.1097,  0.0643,  0.1291,  0.1020],\n",
      "          [ 0.0214,  0.0248, -0.0334,  0.1013,  0.0531],\n",
      "          [-0.0008, -0.0636,  0.0248, -0.0394, -0.0282],\n",
      "          [ 0.1024,  0.0172,  0.0456, -0.0545,  0.0182],\n",
      "          [-0.0197,  0.1342,  0.0421,  0.0906,  0.0427]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0875,  0.0322,  0.0375,  0.0408,  0.0054],\n",
      "          [-0.0460, -0.0633, -0.0649,  0.0760, -0.0567],\n",
      "          [ 0.0322, -0.0105, -0.0606, -0.0797, -0.0679],\n",
      "          [-0.0232, -0.0553, -0.0724,  0.0120, -0.0809],\n",
      "          [ 0.0408, -0.0291, -0.0568, -0.0558, -0.0341]],\n",
      "\n",
      "         [[-0.0568, -0.0631,  0.0572, -0.0491, -0.0536],\n",
      "          [-0.0138,  0.0440,  0.0787,  0.0738,  0.0220],\n",
      "          [-0.0163,  0.0168, -0.0073,  0.0200, -0.0652],\n",
      "          [ 0.0009,  0.0010, -0.0487, -0.0715,  0.0072],\n",
      "          [-0.0719, -0.0316, -0.0134, -0.0032,  0.0724]],\n",
      "\n",
      "         [[ 0.0582, -0.0085,  0.0132, -0.0703,  0.0159],\n",
      "          [ 0.0671, -0.0448,  0.0393, -0.0356,  0.0394],\n",
      "          [ 0.0450,  0.0304, -0.0662,  0.0135,  0.0431],\n",
      "          [-0.0309,  0.0268, -0.0411, -0.0587,  0.0662],\n",
      "          [ 0.0126,  0.0711, -0.0226, -0.0170,  0.0568]],\n",
      "\n",
      "         [[ 0.0282, -0.0763, -0.0282, -0.0218, -0.0370],\n",
      "          [ 0.0586, -0.0726, -0.0211, -0.0571, -0.0420],\n",
      "          [ 0.0335,  0.0127,  0.0681,  0.0412,  0.0192],\n",
      "          [-0.0766, -0.0016, -0.0073,  0.0633, -0.0200],\n",
      "          [-0.0027, -0.0093,  0.0077, -0.0436,  0.0106]],\n",
      "\n",
      "         [[-0.0392,  0.0598, -0.0669,  0.0659, -0.0636],\n",
      "          [-0.0772, -0.0788, -0.0499, -0.0290,  0.0244],\n",
      "          [-0.0204, -0.0283,  0.0083, -0.0568,  0.0490],\n",
      "          [ 0.0234, -0.0123, -0.0521,  0.0399, -0.0175],\n",
      "          [ 0.0072, -0.0435, -0.0295, -0.0564, -0.0306]],\n",
      "\n",
      "         [[ 0.0560, -0.0579, -0.0484,  0.0134,  0.0548],\n",
      "          [-0.0322,  0.0032,  0.0593, -0.0421, -0.0552],\n",
      "          [ 0.0751,  0.0288, -0.0811, -0.0192, -0.0289],\n",
      "          [-0.0103,  0.0337, -0.0256, -0.0466,  0.0394],\n",
      "          [ 0.0175,  0.0412, -0.0659, -0.0206,  0.0141]]],\n",
      "\n",
      "\n",
      "        [[[-0.0340,  0.0957,  0.0862, -0.0030,  0.0326],\n",
      "          [ 0.0625,  0.1338,  0.0669, -0.0977,  0.0272],\n",
      "          [ 0.1258,  0.2758,  0.0864, -0.1109, -0.1041],\n",
      "          [ 0.1510,  0.1942,  0.0006, -0.1443, -0.1476],\n",
      "          [ 0.1227,  0.0747, -0.0599, -0.0265, -0.0703]],\n",
      "\n",
      "         [[ 0.0696,  0.0604,  0.0966,  0.0341, -0.0003],\n",
      "          [ 0.2600,  0.1970,  0.0654, -0.0413,  0.0700],\n",
      "          [ 0.2760,  0.1238,  0.0613,  0.0552, -0.0365],\n",
      "          [ 0.2264,  0.0426,  0.0530, -0.0057,  0.0397],\n",
      "          [ 0.0955,  0.0771,  0.0420, -0.0585, -0.0408]],\n",
      "\n",
      "         [[-0.0805, -0.0571,  0.0686,  0.0679,  0.0019],\n",
      "          [ 0.0002, -0.0732,  0.0858,  0.0114, -0.0765],\n",
      "          [-0.0982,  0.0699,  0.1299,  0.0603, -0.0301],\n",
      "          [-0.0205,  0.0617,  0.0674,  0.0328,  0.0286],\n",
      "          [-0.0963,  0.0384,  0.1049,  0.1011,  0.0627]],\n",
      "\n",
      "         [[ 0.0357,  0.0340,  0.0522,  0.0495,  0.0708],\n",
      "          [-0.0845, -0.0224, -0.0304, -0.0551, -0.0190],\n",
      "          [-0.0668,  0.0409, -0.0619, -0.0562,  0.0009],\n",
      "          [ 0.0180, -0.0264,  0.0483,  0.0653,  0.0173],\n",
      "          [ 0.0295,  0.0553,  0.0585, -0.0805,  0.0243]],\n",
      "\n",
      "         [[ 0.1076, -0.0023, -0.0163, -0.0140,  0.0564],\n",
      "          [ 0.0750,  0.0792, -0.0273,  0.0257, -0.0842],\n",
      "          [ 0.0222,  0.0533, -0.0139, -0.0419, -0.0244],\n",
      "          [ 0.0319,  0.0712,  0.0382,  0.0173,  0.0096],\n",
      "          [-0.0934,  0.0405,  0.1524,  0.0470,  0.0904]],\n",
      "\n",
      "         [[-0.0850,  0.0575,  0.0297,  0.0397,  0.0481],\n",
      "          [-0.0801, -0.0908, -0.0910, -0.0494,  0.0574],\n",
      "          [ 0.1137, -0.0567, -0.1489, -0.0140,  0.0657],\n",
      "          [ 0.0604, -0.0574, -0.0979,  0.0109,  0.0994],\n",
      "          [ 0.0521, -0.0905,  0.0108,  0.0659,  0.0968]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1651,  0.1899,  0.1213,  0.0844,  0.0381],\n",
      "          [ 0.0872,  0.0726,  0.1388,  0.1072,  0.0381],\n",
      "          [-0.0822, -0.0235, -0.0253,  0.0575,  0.0126],\n",
      "          [-0.1143, -0.0686,  0.0064,  0.0676,  0.0519],\n",
      "          [-0.0414, -0.0143, -0.0119,  0.0260,  0.0315]],\n",
      "\n",
      "         [[-0.0832, -0.0186,  0.0401, -0.0030,  0.0215],\n",
      "          [-0.0418,  0.0453,  0.0292,  0.0065,  0.0488],\n",
      "          [ 0.0127, -0.1047,  0.0074,  0.0770,  0.0699],\n",
      "          [-0.1040,  0.0111, -0.0547,  0.0259,  0.0403],\n",
      "          [-0.0534, -0.0387, -0.0023,  0.0301, -0.0905]],\n",
      "\n",
      "         [[ 0.0518,  0.1405,  0.1145,  0.0954, -0.0037],\n",
      "          [-0.0601,  0.0425, -0.0251,  0.0921, -0.0411],\n",
      "          [-0.0104, -0.0991, -0.0232, -0.0040,  0.0175],\n",
      "          [ 0.0217, -0.0569, -0.0210, -0.0877,  0.0530],\n",
      "          [ 0.0366, -0.0513,  0.0025, -0.0891,  0.0799]],\n",
      "\n",
      "         [[ 0.0528,  0.0358, -0.0843,  0.0293,  0.0443],\n",
      "          [ 0.0218,  0.0180, -0.0699, -0.0587,  0.0115],\n",
      "          [ 0.0040,  0.0050,  0.0047,  0.0408,  0.0669],\n",
      "          [ 0.0741, -0.0620,  0.0226,  0.0472,  0.0682],\n",
      "          [ 0.0717,  0.0853, -0.0000, -0.0112, -0.0270]],\n",
      "\n",
      "         [[ 0.1038,  0.1426,  0.0998,  0.0320,  0.1111],\n",
      "          [-0.1177, -0.0672,  0.0677,  0.1034, -0.0451],\n",
      "          [-0.0871, -0.1239, -0.0099, -0.0290, -0.0613],\n",
      "          [-0.0878, -0.0596, -0.0144, -0.0210,  0.0641],\n",
      "          [-0.0289,  0.0519, -0.0234,  0.0174,  0.0056]],\n",
      "\n",
      "         [[-0.0465,  0.0461,  0.0285,  0.0367,  0.0337],\n",
      "          [ 0.0520, -0.0826, -0.0852, -0.0947, -0.1000],\n",
      "          [ 0.0594,  0.0626,  0.0371,  0.0097, -0.0623],\n",
      "          [ 0.0788, -0.0128,  0.0158, -0.0668, -0.0158],\n",
      "          [-0.0014,  0.0584, -0.0293, -0.0480, -0.0613]]]]) \n",
      "\n",
      "\n",
      "4   torch.Size([16]) \n",
      "  Parameter containing:\n",
      "tensor([ 0.0730,  0.0296,  0.0032,  0.0657,  0.0553,  0.0152, -0.0441, -0.0667,\n",
      "         0.0277,  0.0222, -0.0358,  0.0246,  0.0430, -0.0688, -0.0241,  0.0027]) \n",
      "\n",
      "\n",
      "5   torch.Size([33, 256]) \n",
      "  Parameter containing:\n",
      "tensor([[ 0.0101, -0.1054, -0.0498,  ..., -0.0097, -0.2686,  0.0424],\n",
      "        [ 0.1355, -0.0744, -0.0082,  ...,  0.0155, -0.0346, -0.0129],\n",
      "        [-0.0790, -0.0108, -0.1358,  ...,  0.1276,  0.0675,  0.1328],\n",
      "        ...,\n",
      "        [ 0.0559, -0.1349, -0.0938,  ...,  0.1422,  0.1060,  0.0821],\n",
      "        [-0.1792, -0.1332, -0.1304,  ..., -0.0397,  0.1009,  0.1302],\n",
      "        [-0.0050,  0.1827,  0.1914,  ..., -0.2027, -0.0973, -0.0621]],\n",
      "       requires_grad=True) \n",
      "\n",
      "\n",
      "6   torch.Size([33]) \n",
      "  Parameter containing:\n",
      "tensor([-0.1829, -0.0449, -0.0429,  0.2026, -0.0504,  0.0956, -0.1792,  0.1103,\n",
      "         0.1771,  0.0486, -0.1344,  0.0606,  0.1417,  0.1555, -0.1257,  0.1325,\n",
      "        -0.2179,  0.0957, -0.1296, -0.0555, -0.0202,  0.0022,  0.0233, -0.0547,\n",
      "        -0.0791,  0.1378,  0.0493,  0.1245,  0.0686,  0.0763,  0.1027, -0.0778,\n",
      "        -0.1851], requires_grad=True) \n",
      "\n",
      "\n",
      "7   torch.Size([10, 33]) \n",
      "  Parameter containing:\n",
      "tensor([[ 0.0096,  0.0140, -0.0179,  0.0609,  0.0136,  0.0336, -0.0089,  0.0134,\n",
      "          0.0087,  0.0230, -0.0269,  0.0566, -0.0261,  0.0374,  0.0391,  0.0285,\n",
      "          0.0652,  0.0054,  0.0357,  0.0220,  0.0279,  0.0185, -0.0687,  0.0514,\n",
      "          0.0233, -0.0207, -0.0102, -0.0039,  0.0396, -0.0098, -0.0511, -0.0278,\n",
      "         -0.0051],\n",
      "        [ 0.0037, -0.0601, -0.0254,  0.0038, -0.0351, -0.0157, -0.0358,  0.0401,\n",
      "          0.0240,  0.0607, -0.0467,  0.0197, -0.0100,  0.0037,  0.0474,  0.0257,\n",
      "          0.0700, -0.0030, -0.0043, -0.0158,  0.0495,  0.0306, -0.0006, -0.0406,\n",
      "          0.1426,  0.0650, -0.0431, -0.0112,  0.0014,  0.0669, -0.0038,  0.0084,\n",
      "          0.0173],\n",
      "        [ 0.0309, -0.0020, -0.0488, -0.0493,  0.0624,  0.0217,  0.0388,  0.0738,\n",
      "          0.0548,  0.0722,  0.0498,  0.0292,  0.0729, -0.0134,  0.0151,  0.0214,\n",
      "          0.0418,  0.0457, -0.0019,  0.0353, -0.0037, -0.0360,  0.0009,  0.0327,\n",
      "          0.0284,  0.0349,  0.0370, -0.0203, -0.0090, -0.0426,  0.0283, -0.0044,\n",
      "          0.0097],\n",
      "        [ 0.0532,  0.0224, -0.0060, -0.0143,  0.0078, -0.0482,  0.0436,  0.0466,\n",
      "         -0.0264,  0.0276,  0.0308, -0.0013,  0.0370, -0.0118,  0.0079,  0.0006,\n",
      "          0.0014,  0.0695, -0.0185,  0.0630, -0.0275, -0.0233,  0.0458,  0.0360,\n",
      "          0.0459, -0.0586,  0.0160,  0.0436,  0.0659, -0.0215, -0.0317, -0.0375,\n",
      "         -0.0392],\n",
      "        [ 0.0140,  0.0057, -0.0995,  0.0013,  0.0395,  0.0148,  0.0295,  0.0175,\n",
      "         -0.0348,  0.0924,  0.0105,  0.0056,  0.0179,  0.0463, -0.0538, -0.0525,\n",
      "          0.0414,  0.0522,  0.0451, -0.0246,  0.0316,  0.0407, -0.0816,  0.0475,\n",
      "         -0.0078, -0.0616, -0.0318, -0.0674, -0.0193, -0.0209,  0.0361, -0.0425,\n",
      "         -0.0318],\n",
      "        [ 0.0619,  0.0199,  0.0223,  0.0638,  0.0227,  0.0433,  0.0006, -0.0062,\n",
      "         -0.0125,  0.0411, -0.0053, -0.0383, -0.0183,  0.0299,  0.0649,  0.0105,\n",
      "         -0.0642, -0.0137, -0.0168, -0.0346, -0.0200,  0.0113,  0.0281, -0.0382,\n",
      "          0.0546, -0.0136,  0.0138,  0.0274, -0.0191,  0.0018,  0.0098,  0.0186,\n",
      "          0.0665],\n",
      "        [ 0.0999,  0.0361,  0.0173, -0.0420, -0.0570, -0.0244,  0.1074,  0.0253,\n",
      "          0.0127, -0.0230,  0.0134, -0.0252,  0.0331,  0.0510, -0.0316,  0.0325,\n",
      "          0.0295, -0.0341,  0.1076,  0.0314,  0.0585,  0.0154,  0.1108, -0.0384,\n",
      "         -0.0197, -0.0404,  0.1167, -0.0046,  0.0607,  0.0489,  0.0206, -0.0058,\n",
      "          0.0615],\n",
      "        [ 0.0614,  0.0042,  0.0293,  0.0528, -0.0326,  0.0471,  0.0115,  0.0266,\n",
      "          0.0704,  0.0047, -0.0342,  0.0318, -0.0087,  0.0068, -0.0320,  0.0093,\n",
      "          0.0910,  0.0048, -0.0498,  0.0435,  0.0576, -0.0313, -0.0296,  0.0585,\n",
      "          0.0257, -0.0104,  0.0158, -0.0474, -0.0209, -0.0005, -0.0210, -0.0018,\n",
      "          0.0237],\n",
      "        [ 0.0604, -0.0107, -0.0036,  0.0024, -0.0224,  0.0351,  0.0300,  0.0841,\n",
      "          0.0101,  0.0069,  0.0455,  0.0225, -0.0236,  0.0300, -0.0059,  0.0473,\n",
      "          0.0136,  0.0048, -0.0312,  0.0386, -0.0082,  0.0004,  0.0450,  0.0276,\n",
      "          0.0953, -0.0277,  0.0317,  0.0757,  0.0338,  0.0258,  0.0059, -0.0553,\n",
      "         -0.0194],\n",
      "        [-0.0460,  0.0112, -0.0238, -0.0445, -0.0296,  0.0405,  0.0617, -0.0705,\n",
      "          0.0043,  0.0640,  0.0287, -0.0134,  0.0264, -0.0010,  0.0485,  0.0145,\n",
      "         -0.0050,  0.0352,  0.0184, -0.0122,  0.0221, -0.0525, -0.0053, -0.0246,\n",
      "         -0.0069, -0.0092,  0.0117, -0.0418,  0.0063, -0.0121, -0.0223,  0.0104,\n",
      "         -0.0720]], requires_grad=True) \n",
      "\n",
      "\n",
      "8   torch.Size([10]) \n",
      "  Parameter containing:\n",
      "tensor([-0.1196, -0.0370, -0.1034,  0.0167,  0.0766,  0.2233,  0.0697, -0.0316,\n",
      "         0.0786,  0.1085], requires_grad=True) \n",
      "\n",
      "\n",
      "9   torch.Size([10, 10]) \n",
      "  Parameter containing:\n",
      "tensor([[-0.0063,  0.0462,  0.0178, -0.0179,  0.0313,  0.0175, -0.0478, -0.0187,\n",
      "         -0.0292, -0.0298],\n",
      "        [ 0.0246, -0.0529, -0.0289, -0.0449, -0.0113, -0.0262,  0.0965,  0.0260,\n",
      "         -0.0300, -0.0001],\n",
      "        [-0.0321, -0.0179,  0.0063, -0.0061,  0.0065, -0.0314,  0.0454, -0.0081,\n",
      "          0.0048, -0.0010],\n",
      "        [-0.0028,  0.0113, -0.0039,  0.0182, -0.0031, -0.0349, -0.0375, -0.0629,\n",
      "          0.0005,  0.0437],\n",
      "        [ 0.0291, -0.0651,  0.0537, -0.0133,  0.0212,  0.0191, -0.0146,  0.0167,\n",
      "         -0.0558,  0.0089],\n",
      "        [-0.0042, -0.0078, -0.0041,  0.0667, -0.0389,  0.0407,  0.0143, -0.0056,\n",
      "          0.0521, -0.0482],\n",
      "        [-0.0212, -0.0199, -0.0171, -0.0305, -0.0256,  0.0503, -0.0420,  0.0262,\n",
      "         -0.0041,  0.0026],\n",
      "        [ 0.0267, -0.0249, -0.0353,  0.0233, -0.0041, -0.0159, -0.0183, -0.0351,\n",
      "         -0.0043,  0.0210],\n",
      "        [-0.0215, -0.0134,  0.0128,  0.0189,  0.0186, -0.0523,  0.0055, -0.0102,\n",
      "          0.0024,  0.0029],\n",
      "        [ 0.0248,  0.0624, -0.0032,  0.0132,  0.0445, -0.0079, -0.0214,  0.0129,\n",
      "         -0.0647,  0.0034]], requires_grad=True) \n",
      "\n",
      "\n",
      "10   torch.Size([10]) \n",
      "  Parameter containing:\n",
      "tensor([-0.0838,  0.0204, -0.0172,  0.0138,  0.0053, -0.0699,  0.0305,  0.0152,\n",
      "        -0.0514, -0.0417], requires_grad=True) \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for parameter in net.parameters():\n",
    "    i+=1\n",
    "    print(i,\" \",parameter.shape,\"\\n \",parameter,\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 20] loss: 0.02111035257577896\n",
      "[1, 40] loss: 0.01765345734357834\n",
      "[1, 60] loss: 0.01332759016752243\n",
      "[1, 80] loss: 0.00910641872882843\n",
      "[1, 100] loss: 0.006505764305591583\n",
      "[1, 120] loss: 0.005376414209604263\n",
      "[1, 140] loss: 0.004357194900512696\n",
      "[1, 160] loss: 0.003873894229531288\n",
      "[1, 180] loss: 0.00324937804043293\n",
      "[1, 200] loss: 0.0032976980432868003\n",
      "[1, 220] loss: 0.003017231874167919\n",
      "[1, 240] loss: 0.002886640377342701\n",
      "[1, 260] loss: 0.0027742383256554605\n",
      "[1, 280] loss: 0.0028253718465566634\n",
      "[1, 300] loss: 0.002437099814414978\n",
      "[2, 20] loss: 0.002532775089144707\n",
      "[2, 40] loss: 0.0024492948204278948\n",
      "[2, 60] loss: 0.0024136525243520736\n",
      "[2, 80] loss: 0.002091617837548256\n",
      "[2, 100] loss: 0.0022038123682141305\n",
      "[2, 120] loss: 0.0022178729102015496\n",
      "[2, 140] loss: 0.00223090211302042\n",
      "[2, 160] loss: 0.00219000069051981\n",
      "[2, 180] loss: 0.0021972253397107124\n",
      "[2, 200] loss: 0.0020923154205083846\n",
      "[2, 220] loss: 0.0019175458401441575\n",
      "[2, 240] loss: 0.001981714367866516\n",
      "[2, 260] loss: 0.0020355234518647193\n",
      "[2, 280] loss: 0.001960651431232691\n",
      "[2, 300] loss: 0.0016726778745651245\n",
      "[3, 20] loss: 0.0019555684104561807\n",
      "[3, 40] loss: 0.0017649928219616413\n",
      "[3, 60] loss: 0.001888693258166313\n",
      "[3, 80] loss: 0.0017741306461393834\n",
      "[3, 100] loss: 0.0016477084904909134\n",
      "[3, 120] loss: 0.0016776547767221929\n",
      "[3, 140] loss: 0.0016863357201218605\n",
      "[3, 160] loss: 0.001707362025976181\n",
      "[3, 180] loss: 0.001582914348691702\n",
      "[3, 200] loss: 0.0016628276556730271\n",
      "[3, 220] loss: 0.0015419450551271438\n",
      "[3, 240] loss: 0.0016247949525713921\n",
      "[3, 260] loss: 0.0017139113023877143\n",
      "[3, 280] loss: 0.001581183098256588\n",
      "[3, 300] loss: 0.0016221659667789935\n",
      "[4, 20] loss: 0.0015737314857542516\n",
      "[4, 40] loss: 0.0015600143559277057\n",
      "[4, 60] loss: 0.0014944292195141315\n",
      "[4, 80] loss: 0.0016179212555289268\n",
      "[4, 100] loss: 0.001441463440656662\n",
      "[4, 120] loss: 0.0015757696777582168\n",
      "[4, 140] loss: 0.0014015522599220276\n",
      "[4, 160] loss: 0.0014717897847294807\n",
      "[4, 180] loss: 0.0015596339032053947\n",
      "[4, 200] loss: 0.0014412684291601181\n",
      "[4, 220] loss: 0.001360722366720438\n",
      "[4, 240] loss: 0.001683480467647314\n",
      "[4, 260] loss: 0.0012124020867049694\n",
      "[4, 280] loss: 0.0014042995646595955\n",
      "[4, 300] loss: 0.001303948912769556\n",
      "[5, 20] loss: 0.0012740623280405997\n",
      "[5, 40] loss: 0.0013847677260637283\n",
      "[5, 60] loss: 0.0012741632014513016\n",
      "[5, 80] loss: 0.001303844228386879\n",
      "[5, 100] loss: 0.0013639677911996841\n",
      "[5, 120] loss: 0.0013527329266071319\n",
      "[5, 140] loss: 0.0012438816726207734\n",
      "[5, 160] loss: 0.0014592794887721538\n",
      "[5, 180] loss: 0.0013472094237804413\n",
      "[5, 200] loss: 0.001268796555697918\n",
      "[5, 220] loss: 0.001300000224262476\n",
      "[5, 240] loss: 0.0013732143938541411\n",
      "[5, 260] loss: 0.0013800248689949512\n",
      "[5, 280] loss: 0.0014004384912550448\n",
      "[5, 300] loss: 0.0012104623578488827\n",
      "[6, 20] loss: 0.0012573867551982402\n",
      "[6, 40] loss: 0.0013156594857573508\n",
      "[6, 60] loss: 0.00120773221924901\n",
      "[6, 80] loss: 0.0012957251686602832\n",
      "[6, 100] loss: 0.0013452979065477848\n",
      "[6, 120] loss: 0.0012125597558915616\n",
      "[6, 140] loss: 0.0012337055690586566\n",
      "[6, 160] loss: 0.0011092927008867265\n",
      "[6, 180] loss: 0.0012818832769989968\n",
      "[6, 200] loss: 0.0013663774654269218\n",
      "[6, 220] loss: 0.0012920644544065\n",
      "[6, 240] loss: 0.0011773344837129117\n",
      "[6, 260] loss: 0.0011780900973826648\n",
      "[6, 280] loss: 0.0010746777467429637\n",
      "[6, 300] loss: 0.00115789745002985\n",
      "[7, 20] loss: 0.001266907222568989\n",
      "[7, 40] loss: 0.001176670640707016\n",
      "[7, 60] loss: 0.0011047075130045413\n",
      "[7, 80] loss: 0.0011366456858813764\n",
      "[7, 100] loss: 0.0011591656301170588\n",
      "[7, 120] loss: 0.0010808570720255374\n",
      "[7, 140] loss: 0.001080034540966153\n",
      "[7, 160] loss: 0.0013181882053613662\n",
      "[7, 180] loss: 0.001171771142631769\n",
      "[7, 200] loss: 0.0010677318796515464\n",
      "[7, 220] loss: 0.0010621688701212405\n",
      "[7, 240] loss: 0.001115591123700142\n",
      "[7, 260] loss: 0.0013184744715690612\n",
      "[7, 280] loss: 0.0011038543544709682\n",
      "[7, 300] loss: 0.0011415353547781705\n",
      "[8, 20] loss: 0.0010781958159059286\n",
      "[8, 40] loss: 0.0011121728867292404\n",
      "[8, 60] loss: 0.0011308136768639087\n",
      "[8, 80] loss: 0.0011268604937940837\n",
      "[8, 100] loss: 0.001100183919072151\n",
      "[8, 120] loss: 0.001193839715793729\n",
      "[8, 140] loss: 0.0012137790806591511\n",
      "[8, 160] loss: 0.0012093562446534633\n",
      "[8, 180] loss: 0.0011792350802570582\n",
      "[8, 200] loss: 0.001144998025149107\n",
      "[8, 220] loss: 0.001046725096181035\n",
      "[8, 240] loss: 0.000982607688754797\n",
      "[8, 260] loss: 0.0010183140486478806\n",
      "[8, 280] loss: 0.0010572426691651344\n",
      "[8, 300] loss: 0.0010146432854235173\n",
      "[9, 20] loss: 0.0008715886063873768\n",
      "[9, 40] loss: 0.0010519918855279684\n",
      "[9, 60] loss: 0.0009471450876444578\n",
      "[9, 80] loss: 0.0008995360247790814\n",
      "[9, 100] loss: 0.0011540664043277501\n",
      "[9, 120] loss: 0.0010812247693538666\n",
      "[9, 140] loss: 0.001068313593044877\n",
      "[9, 160] loss: 0.0010215314440429211\n",
      "[9, 180] loss: 0.0011120721586048603\n",
      "[9, 200] loss: 0.001182617835700512\n",
      "[9, 220] loss: 0.0010044428538531064\n",
      "[9, 240] loss: 0.0011169322021305562\n",
      "[9, 260] loss: 0.0009725352190434933\n",
      "[9, 280] loss: 0.0009871271327137948\n",
      "[9, 300] loss: 0.001166889050975442\n",
      "[10, 20] loss: 0.0009868056178092956\n",
      "[10, 40] loss: 0.0009945870656520128\n",
      "[10, 60] loss: 0.0010047852396965027\n",
      "[10, 80] loss: 0.000946022754535079\n",
      "[10, 100] loss: 0.000995058411732316\n",
      "[10, 120] loss: 0.0009524337947368622\n",
      "[10, 140] loss: 0.0010818553641438484\n",
      "[10, 160] loss: 0.0009188020154833794\n",
      "[10, 180] loss: 0.0010291585754603147\n",
      "[10, 200] loss: 0.000987025786191225\n",
      "[10, 220] loss: 0.0010064034834504128\n",
      "[10, 240] loss: 0.00108298534527421\n",
      "[10, 260] loss: 0.0010098024448379874\n",
      "[10, 280] loss: 0.000995297282934189\n",
      "[10, 300] loss: 0.0009501033984124661\n",
      "[11, 20] loss: 0.0010778327398002147\n",
      "[11, 40] loss: 0.0009575260747224092\n",
      "[11, 60] loss: 0.0008845880050212145\n",
      "[11, 80] loss: 0.0010457171332091094\n",
      "[11, 100] loss: 0.0009652031511068344\n",
      "[11, 120] loss: 0.0010322573073208332\n",
      "[11, 140] loss: 0.0009235884062945843\n",
      "[11, 160] loss: 0.001009389165788889\n",
      "[11, 180] loss: 0.0009199191620573401\n",
      "[11, 200] loss: 0.0008677002619951964\n",
      "[11, 220] loss: 0.0008946345336735248\n",
      "[11, 240] loss: 0.0009450286040082574\n",
      "[11, 260] loss: 0.0010269800312817097\n",
      "[11, 280] loss: 0.0008882481958717108\n",
      "[11, 300] loss: 0.0010186428520828484\n",
      "[12, 20] loss: 0.0009367483826354146\n",
      "[12, 40] loss: 0.0009367316421121359\n",
      "[12, 60] loss: 0.0008627418484538794\n",
      "[12, 80] loss: 0.0010087312236428262\n",
      "[12, 100] loss: 0.0009515994228422642\n",
      "[12, 120] loss: 0.0007623565457761288\n",
      "[12, 140] loss: 0.0009435955714434386\n",
      "[12, 160] loss: 0.0010691812131553887\n",
      "[12, 180] loss: 0.0008513856511563063\n",
      "[12, 200] loss: 0.0009332892000675202\n",
      "[12, 220] loss: 0.0009189076516777277\n",
      "[12, 240] loss: 0.0008849495854228735\n",
      "[12, 260] loss: 0.0008752958960831166\n",
      "[12, 280] loss: 0.0008603340312838554\n",
      "[12, 300] loss: 0.0011603417228907347\n",
      "[13, 20] loss: 0.000910055361688137\n",
      "[13, 40] loss: 0.0009716932810842991\n",
      "[13, 60] loss: 0.0008467653235420585\n",
      "[13, 80] loss: 0.0009352136813104153\n",
      "[13, 100] loss: 0.0007614722978323698\n",
      "[13, 120] loss: 0.0009337942432612181\n",
      "[13, 140] loss: 0.0007940955981612205\n",
      "[13, 160] loss: 0.0008419047938659787\n",
      "[13, 180] loss: 0.0007980327047407627\n",
      "[13, 200] loss: 0.0010226640179753304\n",
      "[13, 220] loss: 0.0010859214700758458\n",
      "[13, 240] loss: 0.0008144215568900108\n",
      "[13, 260] loss: 0.0008966559823602438\n",
      "[13, 280] loss: 0.0009726794324815273\n",
      "[13, 300] loss: 0.0009230420049279928\n",
      "[14, 20] loss: 0.0007846807502210141\n",
      "[14, 40] loss: 0.0010299517307430506\n",
      "[14, 60] loss: 0.0008884092643857002\n",
      "[14, 80] loss: 0.0007057993281632662\n",
      "[14, 100] loss: 0.001000113233923912\n",
      "[14, 120] loss: 0.0009000615477561951\n",
      "[14, 140] loss: 0.0010257424861192703\n",
      "[14, 160] loss: 0.0009270459096878767\n",
      "[14, 180] loss: 0.0009404068030416966\n",
      "[14, 200] loss: 0.00090751001983881\n",
      "[14, 220] loss: 0.0008629140015691519\n",
      "[14, 240] loss: 0.0009047176837921143\n",
      "[14, 260] loss: 0.000814496161416173\n",
      "[14, 280] loss: 0.0008238651044666768\n",
      "[14, 300] loss: 0.0008330760821700096\n",
      "[15, 20] loss: 0.0008665223270654678\n",
      "[15, 40] loss: 0.0008184697553515434\n",
      "[15, 60] loss: 0.0007763911578804255\n",
      "[15, 80] loss: 0.0007402612622827292\n",
      "[15, 100] loss: 0.000780194640159607\n",
      "[15, 120] loss: 0.0007977324891835451\n",
      "[15, 140] loss: 0.0008421269524842501\n",
      "[15, 160] loss: 0.0008331940174102783\n",
      "[15, 180] loss: 0.0008664457704871893\n",
      "[15, 200] loss: 0.0009513250663876533\n",
      "[15, 220] loss: 0.0008337323199957609\n",
      "[15, 240] loss: 0.0007835627365857363\n",
      "[15, 260] loss: 0.00102790436334908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 280] loss: 0.0008656068667769432\n",
      "[15, 300] loss: 0.0010516254231333732\n",
      "[16, 20] loss: 0.0009148861858993769\n",
      "[16, 40] loss: 0.0007764286641031504\n",
      "[16, 60] loss: 0.0008616620618849993\n",
      "[16, 80] loss: 0.0007786728534847498\n",
      "[16, 100] loss: 0.0008143650777637959\n",
      "[16, 120] loss: 0.0007886112052947283\n",
      "[16, 140] loss: 0.0007674254085868597\n",
      "[16, 160] loss: 0.0008323190528899432\n",
      "[16, 180] loss: 0.0009015319459140301\n",
      "[16, 200] loss: 0.0008308227434754372\n",
      "[16, 220] loss: 0.0008444973174482584\n",
      "[16, 240] loss: 0.0008768977168947458\n",
      "[16, 260] loss: 0.000857983616180718\n",
      "[16, 280] loss: 0.000892079801298678\n",
      "[16, 300] loss: 0.000915202203206718\n",
      "[17, 20] loss: 0.0007309652213007212\n",
      "[17, 40] loss: 0.0008161892825737596\n",
      "[17, 60] loss: 0.000768151767551899\n",
      "[17, 80] loss: 0.0008909199079498648\n",
      "[17, 100] loss: 0.0008758342564105987\n",
      "[17, 120] loss: 0.0008210136871784926\n",
      "[17, 140] loss: 0.0007864550286903977\n",
      "[17, 160] loss: 0.0007867134958505631\n",
      "[17, 180] loss: 0.000834137488156557\n",
      "[17, 200] loss: 0.0008250951375812293\n",
      "[17, 220] loss: 0.0009389538299292326\n",
      "[17, 240] loss: 0.000781635595485568\n",
      "[17, 260] loss: 0.0009307966232299804\n",
      "[17, 280] loss: 0.0008397810021415353\n",
      "[17, 300] loss: 0.0007737675029784441\n",
      "[18, 20] loss: 0.0006176777631044388\n",
      "[18, 40] loss: 0.0007240664474666118\n",
      "[18, 60] loss: 0.0006755067836493254\n",
      "[18, 80] loss: 0.0007864442728459835\n",
      "[18, 100] loss: 0.0008388645816594363\n",
      "[18, 120] loss: 0.0010305019449442625\n",
      "[18, 140] loss: 0.000826947845518589\n",
      "[18, 160] loss: 0.0008110997546464205\n",
      "[18, 180] loss: 0.0008650595555081964\n",
      "[18, 200] loss: 0.000758643725886941\n",
      "[18, 220] loss: 0.0008313205242156983\n",
      "[18, 240] loss: 0.0007911598179489375\n",
      "[18, 260] loss: 0.0008357760943472386\n",
      "[18, 280] loss: 0.0007287821462377906\n",
      "[18, 300] loss: 0.0010087850373238325\n",
      "[19, 20] loss: 0.0007604827797040343\n",
      "[19, 40] loss: 0.0007269815756008029\n",
      "[19, 60] loss: 0.0007665426507592201\n",
      "[19, 80] loss: 0.0008529827091842889\n",
      "[19, 100] loss: 0.0008154308097437024\n",
      "[19, 120] loss: 0.0007981873266398907\n",
      "[19, 140] loss: 0.0009191125687211752\n",
      "[19, 160] loss: 0.000706114562228322\n",
      "[19, 180] loss: 0.0008147540651261806\n",
      "[19, 200] loss: 0.000777146939188242\n",
      "[19, 220] loss: 0.0008179989494383335\n",
      "[19, 240] loss: 0.0008859476959332823\n",
      "[19, 260] loss: 0.0006604567915201187\n",
      "[19, 280] loss: 0.0008093134267255664\n",
      "[19, 300] loss: 0.0007293189056217671\n",
      "[20, 20] loss: 0.0009537768252193927\n",
      "[20, 40] loss: 0.0008124504033476114\n",
      "[20, 60] loss: 0.0006951077803969383\n",
      "[20, 80] loss: 0.0007925114370882511\n",
      "[20, 100] loss: 0.0006360703278332949\n",
      "[20, 120] loss: 0.000790394052863121\n",
      "[20, 140] loss: 0.0008310788013041019\n",
      "[20, 160] loss: 0.0007935825288295746\n",
      "[20, 180] loss: 0.00075372941698879\n",
      "[20, 200] loss: 0.0006266125189140439\n",
      "[20, 220] loss: 0.0007931442987173796\n",
      "[20, 240] loss: 0.0008037181179970503\n",
      "[20, 260] loss: 0.0007406760714948178\n",
      "[20, 280] loss: 0.0007406133450567722\n",
      "[20, 300] loss: 0.0008271580617874861\n",
      "Finished Reraining\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        # print(inputs.shape)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    # print every 2000 mini-batches\n",
    "            print(\"[{}, {}] loss: {}\".format\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Reraining')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"LeNET_x_y_MNIST_Model_random_clustering_Fine_Tuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, len(net.state_dict()[\"fc1.weight\"]))\n",
    "        self.fc2 = nn.Linear(len(net.state_dict()[\"fc1.weight\"]), len(net.state_dict()[\"fc2.weight\"]))\n",
    "        self.fc3 = nn.Linear(len(net.state_dict()[\"fc2.weight\"]), 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(\"LeNET_x_y_MNIST_Model_random_clustering_Fine_Tuned\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 24, 24]             156\n",
      "         MaxPool2d-2            [-1, 6, 12, 12]               0\n",
      "            Conv2d-3             [-1, 16, 8, 8]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 4, 4]               0\n",
      "            Linear-5                   [-1, 33]           8,481\n",
      "            Linear-6                   [-1, 10]             340\n",
      "            Linear-7                   [-1, 10]             110\n",
      "================================================================\n",
      "Total params: 11,503\n",
      "Trainable params: 11,503\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 0.04\n",
      "Estimated Total Size (MB): 0.09\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "device=torch.device(\"cpu\")\n",
    "model=Net().to(device)\n",
    "summary(model, input_size=(1, 28, 28), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 97.450000 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources:\n",
    "[https://towardsdatascience.com/how-to-cluster-in-high-dimensions-4ef693bacc6] [1/11/2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
